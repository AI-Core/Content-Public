{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Workloads\n",
    "\n",
    "In the world of Kubernetes, the term \"workload\" refers to the heart of your application: the components that you want to run, manage, and scale within the Kubernetes cluster. These workloads could be web servers, databases, microservices, or any other software that you need to deploy and maintain efficiently.\n",
    "\n",
    "Workloads can be divided into pods and workload resources.\n",
    "\n",
    "## Pods Overview\n",
    "\n",
    "- A Kubernetes Pod is the smallest deployable unit, and it serves as the fundamental building block for your workloads. A Pod can contain one or more containers that run together as a single unit.\n",
    "\n",
    "- It's essential to understand that Pods are designed to be ephemeral. If a Pod fails, Kubernetes can easily recreate it on another node in the cluster. This ephemeral nature ensures resilience and reliability in your applications.\n",
    "\n",
    "- Kubernetes takes the responsibility of managing and rescheduling Pods in the case of node failures or Pod failures. Cluster administrators typically focus on monitoring and ensuring the overall health of the cluster.\n",
    "\n",
    "## Workload Resources Overview\n",
    "\n",
    "In Kubernetes, managing individual Pods manually can be inefficient and error-prone. This is where *Workload Resources* come into play. \n",
    "\n",
    "> **Workload Resources** are higher-level abstractions that simplify the deployment, scaling, and lifecycle management of Pods. They provide a declarative approach to managing your application, where you specify what you want, and Kubernetes takes care of the rest.\n",
    "\n",
    "Here are some common workload resources:\n",
    "\n",
    "- *Deployment*: Use **Deployments** for deploying stateless applications (applications that do not rely on maintaining persistent, local state or data) that need scaling and rolling updates. Deployments ensure that a specified number of replicas (Pods) are running at all times.\n",
    "\n",
    "- *Stateful Set*: When you have stateful applications with unique identities (e.g., databases), **Stateful Sets** are the go-to choice. They provide stable network identities and persistent storage.\n",
    "\n",
    "- *Daemon Set*: Ideal for tasks that require execution on every node within the cluster, such as running logging agents or monitoring tools. They guarantee that exactly one Pod is scheduled to run on each node, ensuring that these essential tasks are distributed across the entire cluster.\n",
    "\n",
    "- *Job and CronJob*: **Jobs** are used for running batch processes or one-off tasks, while **Cron Jobs** allow you to schedule recurring tasks using a time-based schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pods\n",
    "\n",
    "A Pod in Kubernetes is a fundamental concept and serves as the smallest deployable unit. It's essentially a group of one or more containers that share a common context and a specification for running those containers. Think of Pods as similar to `docker-compose`, allowing you to logically group related containers together.\n",
    "\n",
    "### Shared Context\n",
    "\n",
    "Pods provide a shared context for containers, which includes:\n",
    "\n",
    "- **Shared Storage**: Containers within a Pod can share the same storage volume, making it easy for them to exchange data\n",
    "\n",
    "- **Shared Network Resources**: Containers in a Pod share the same network namespace, often having the same IP address and port space. This allows them to communicate with each other using `localhost`. This sharing of the network namespace is part of how Pods provide network isolation.\n",
    "\n",
    "- **Linux Namespaces for Isolation**: In addition to sharing the network namespace, Pods use Linux namespaces to isolate containers within the same Pod, providing a level of process and network isolation. These namespaces help ensure that while containers can communicate with each other using `localhost`, they are still effectively isolated from other Pods and resources in the cluster.\n",
    "\n",
    "Importantly, even within a Pod, individual applications can be further isolated as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle and Pod Phases\n",
    "\n",
    "Pods in Kubernetes follow a distinct lifecycle, and they have different phases indicating their status and progress. Unlike some container orchestration platforms, Kubernetes Pods are not moved across nodes; instead, they are recreated if necessary. Here are key aspects of the Pod lifecycle:\n",
    "\n",
    "- **Pod Placement**: Pods remain on the node where they are initially scheduled until they are terminated (either due to a restart policy in case of failures or manual deletion)\n",
    "\n",
    "- **Pod Recreation**: In Kubernetes, Pods are never moved to different nodes; they are recreated on the same or different nodes if required\n",
    "\n",
    "- **Self-Healing**: Pods cannot initiate self-healing; they don't attempt to restart themselves. The responsibility for restarting Pods lies with the appropriate Workload Resources (like Deployments or Stateful Sets) or the cluster administrator.\n",
    "\n",
    "- **Automatic Restart**: Kubernetes relies on the `kubelet` component to automatically restart failed containers within Pods when issues are detected\n",
    "\n",
    "A Pod can be in one of several phases, each indicating its current status:\n",
    "\n",
    "- **Pending**: The Pod has been accepted by the Kubernetes cluster, but one or more containers may not have started yet, or the Pod is waiting for node scheduling\n",
    "\n",
    "- **Running**: At least one container within the Pod is running or being restarted\n",
    "\n",
    "- **Succeeded**: All containers in the Pod have completed their tasks successfully, and no restart is required\n",
    "\n",
    "- **Failed**: At least one container has failed and was terminated\n",
    "\n",
    "- **Unknown**: The state of the Pod cannot be determined, typically due to communication errors with the Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container states\n",
    "\n",
    "Kubernetes also monitors the state of individual containers within each Pod.\n",
    "\n",
    "Containers can be in one of three states:\n",
    "\n",
    "- **Waiting**: This state indicates that the container is waiting for something to happen. It's often seen when a container is downloading its image or pulling secrets required for its operation. \n",
    "\n",
    "- **Running**: This state means the container is actively executing its tasks and is in a healthy operational state\n",
    "\n",
    "- **Terminated**: Containers can be in this state for various reasons. It may be due to a successful termination of the container's task, or it might indicate a failure. When a container terminates, Kubernetes provides the reason for termination and an exit code, which can be invaluable for monitoring and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Container Pods\n",
    "\n",
    "Typically, Pods run with a single container, and a Pod can be seen as a wrapper for that container. Examples include:\n",
    "\n",
    "- A `FastAPI` server receiving requests and saving data to a shared database\n",
    "- A Docker container that receives image classification requests and forwards them to a classification service\n",
    "\n",
    "### Multiple-Container Pods\n",
    "\n",
    "Multi-container Pods are used in more complex scenarios where multiple tightly coupled containers work together as a cohesive unit. \n",
    "\n",
    "<p align=center><img src=images/pod.svg width=350></p>\n",
    "\n",
    "This setup is ideal for scenarios like:\n",
    "\n",
    "- Training multiple machine learning models, where containers perform tasks like data transformation, model training, model deployment, and serving\n",
    "- Implementing a public data-serving container alongside an internal data-writing container with shared storage\n",
    "\n",
    "> Multi-container Pods are scheduled on the same \"logical host\" due to their tight coupling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pods\n",
    "\n",
    "In Kubernetes, you can define Pods imperatively (step by step) or declaratively using `.yaml` files. However, specifying bare Pods directly is generally discouraged because it leaves them without the necessary mechanisms for self-recovery and management. Instead, it's recommended to use higher-level abstractions like Deployments or Replica Sets to manage Pods and ensure their availability.\n",
    "\n",
    "While it's possible to specify a bare Pod directly, it's important to understand that doing so may not be suitable for most production scenarios. Below is an example of specifying a bare Pod for reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: pod1\n",
    "  labels:\n",
    "    tier: frontend\n",
    "spec:\n",
    "  containers:\n",
    "  - name: hello1\n",
    "    image: gcr.io/google-samples/hello-app:2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we've defined a Pod named `pod1` with a single container called `hello1` using a specific Docker image. However, without higher-level controllers like Deployments or Replica Sets, this Pod won't have the ability to recover from failures or scale automatically.\n",
    "\n",
    "In practice, for robust and scalable application deployments, it's recommended to use the appropriate Workload Resources, which we'll explore in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to try running some `kubectl` commands yourself. Follow the instructions to run some important Pods commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h13m\n",
      "ubuntu-pod   1/1     Running   0          3h6m\n"
     ]
    }
   ],
   "source": [
    "# Observe the pods in the default namespace\n",
    "!kubectl ###Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/pod1 created\n"
     ]
    }
   ],
   "source": [
    "# Spin up the pod corresponding to the single-pod configuration above\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h14m\n",
      "pod1         1/1     Running   0          17s\n",
      "ubuntu-pod   1/1     Running   0          3h6m\n"
     ]
    }
   ],
   "source": [
    "# Observe the pods in the default namespace again\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"pod1\" deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the pod created above\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h15m\n",
      "ubuntu-pod   1/1     Running   0          3h7m\n"
     ]
    }
   ],
   "source": [
    "# observe the resources in the default namespace again \n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the case in the last notebook, the pod disappears here. This is because, contrary to the case in the last notebook, no instructions were provided here to keep the pod alive. The pod is 'bare', without any resource to keep it running after it fails. \n",
    "\n",
    "Keeping it 'alive' is one of the desired states that can be specified in the config file, and it can be achieved with Deployment or Replica Set. We will look at more options in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workload Resources\n",
    "\n",
    "Before diving into specific Workload Resources, let's cover some important concepts that apply to all of them:\n",
    "\n",
    "- Each Workload Resource uses the `.spec.template` field to specify how to create a Pod\n",
    "\n",
    "- The template for a Workload Resource is essentially the same as a Pod configuration, except for the `kind` and `apiVersion` fields\n",
    "\n",
    "- Workload Resources also have a `.spec.selector` field, which specifies which Pods are managed by the Workload Resource\n",
    "\n",
    "- The `.spec.selector` can employ matches on defined labels, allowing the Workload Resource to manage Pods even if they are defined in a separate configuration file\n",
    "\n",
    "Workload Resources can be implemented using different controllers, including `ReplicaSets`, `Deployment`, `DaemonSet`, and `Jobs`. In a future lesson, we will explore another type of Workload Resource called *`StatefulSets`*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replica Sets\n",
    "\n",
    ">  A `ReplicaSet` is a controller designed to maintain a consistent set of replicated Pods running within a Kubernetes cluster. It ensures that a specified number of identical Pod replicas is continuously available.\n",
    "\n",
    "#### Acquiring Pods\n",
    "\n",
    "`ReplicaSet` acquires Pods using the `metadata.ownerReferences` field and matching the `.spec.selector` field. Here's how it works:\n",
    "\n",
    "- Each Pod has an`metadata.ownerReferences` field that is automatically added by Kubernetes. This field specifies who manages the Pod, which can be another controller.\n",
    "\n",
    "- If a Pod has no 'owner' (e.g., it's a bare Pod) or its owner is not another controller, and the `.spec.selector` fields match, then the Pod is acquired by the `ReplicaSet`.\n",
    "\n",
    "For instance, consider a `ReplicaSet` with the following selector in its `.spec.selector`:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: example-app\n",
    "```\n",
    "If there is a Pod with the label `app: example-app`, and that Pod does not have another controller owning it, the `ReplicaSet` will acquire and manage that Pod because it matches the specified label selector.\n",
    "\n",
    "> This acquisition process is similar for other Workload Resources.\n",
    "\n",
    "#### Using Replica Sets\n",
    "\n",
    "It is generally recommended to use higher-level controllers like Deployments for managing Pods and Replica Sets. Deployments provide a declarative way to define and manage the desired state of your application, which may involve multiple Replica Sets and Pods. \n",
    "\n",
    "Deployments simplify the process of rolling out updates to your application by managing the creation and scaling of Replica Sets, which in turn manage the underlying Pods. However, Replica Sets may be employed when:\n",
    "- Custom update orchestration is required\n",
    "- The configuration file will not be updated\n",
    "\n",
    "For more detailed information on Replica Sets, check [here](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "> A Deployment is a controller in Kubernetes that offers declarative updates for managing Pods and Replica Sets.\n",
    "\n",
    "Deployments operate on the principle of declarative updates. Instead of specifying the step-by-step process of how to modify an application, you define the desired state, and Kubernetes takes care of the how. They are primarily responsible for controlling the number of replica Pods and the corresponding Replica Sets. They ensure that the desired number of Pods is continuously available while replacing or scaling them as needed.\n",
    "\n",
    "Key features of Deployments include: \n",
    "\n",
    "- **Rolling Updates**: Deployments allow for seamless rolling updates. When you make changes to the desired state (e.g., updating the container image), Deployments gradually replace existing Pods with new ones. This process ensures zero downtime during updates.\n",
    "\n",
    "- **Rollback Capabilities**: In case of issues during an update, Deployments can easily roll back to a previous version. This feature promotes application reliability.\n",
    "\n",
    "- **Scaling**: Deployments support both manual and automatic scaling. You can adjust the number of replicas to meet changing demand.\n",
    "\n",
    "- **Self-Healing**: If a Pod within a Deployment fails, the Deployment controller automatically replaces it to maintain the desired number of replicas\n",
    "\n",
    "Consider the example config below, and attempt to decipher the meaning of each field:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "  labels:\n",
    "    app: nginx\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.14.2\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we instruct the resource to ensure that at least three Pods are running at all times. These Pods are identified using the `selector.matchLabels`, which searches the template for the label with the key `app` and value `nginx`.\n",
    "\n",
    "The `spec` section defines the desired state for the Deployment:\n",
    "\n",
    "  - `replicas: 3`: This line specifies that we want to ensure that there are always three replica Pods running for this Deployment. If the actual number of Pods deviates from this, Kubernetes will automatically take corrective actions to meet this desired state.\n",
    "  - `selector`: The selector field determines which Pods are managed by this Deployment. In this example, the Pods are selected based on the label `app: nginx`, and this label must match the label defined in the `template`.\n",
    "  - `template`: The `template` section defines the Pod template for the Deployment. This template defines the structure of the Pods, including labels, containers, and other specifications:\n",
    "\n",
    "    - `metadata`: It provides metadata for the Pods created by this Deployment. Here, we apply the label `app: nginx` to the Pods, matching the label in the `selector`.\n",
    "    - `spec`: This section describes the Pod's specification, including its containers:\n",
    "      - `containers`: We define a single container named `nginx` using the official Nginx image (version 1.14.2). This container listens on port 80.\n",
    "\n",
    "#### Hands-On\n",
    "\n",
    "1. Create a `.yaml` file with the provided configuration\n",
    "2. Use the appropriate `kubectl` command to apply the `.yaml` file\n",
    "3. Observe the number of Pods created\n",
    "4. Delete one of the Pods\n",
    "5. Observe the number of Pods again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/nginx-deployment created\n"
     ]
    }
   ],
   "source": [
    "# Run the .yaml file\n",
    "!kubectl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS              RESTARTS   AGE\n",
      "nginx-deployment-66b6c48dd5-7qpvr   0/1     ContainerCreating   0          17s\n",
      "nginx-deployment-66b6c48dd5-gc7z7   0/1     ContainerCreating   0          17s\n",
      "nginx-deployment-66b6c48dd5-vzsx2   0/1     ContainerCreating   0          17s\n"
     ]
    }
   ],
   "source": [
    "# Observe how many pods you have\n",
    "!kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"nginx-deployment-66b6c48dd5-vzsx2\" deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete one of the pods\n",
    "!kubectl delete pod nginx-deployment-66b6c48dd5-vzsx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS    RESTARTS        AGE\n",
      "nginx-deployment-66b6c48dd5-7qpvr   1/1     Running   1 (8m15s ago)   8h\n",
      "nginx-deployment-66b6c48dd5-fsck5   1/1     Running   0               40s\n",
      "nginx-deployment-66b6c48dd5-gc7z7   1/1     Running   1 (8m15s ago)   8h\n"
     ]
    }
   ],
   "source": [
    "# Observe how many pods you have again\n",
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting a Pod, you should see that a new Pod has been created by the Deployment to maintain the desired number of replicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daemon Sets\n",
    "\n",
    "> A `DaemonSet` is a controller that ensures a Pod is deployed on all Nodes in the cluster. Each Node gets one instance of the Pod.\n",
    "\n",
    "In the examples thus far, we had one pod per node; therefore, if a node is removed, the number of pods will decrease.\n",
    "\n",
    "#### Node Selection in Daemon Sets\n",
    "\n",
    "One distinctive feature of Daemon Sets is that they automatically ensure one pod runs on each node in the cluster. The `replicas` field, commonly used in Deployments, is not present in Daemon Set configurations because there is always one pod per node.\n",
    "\n",
    "However, there are cases specific to Daemon Sets where you might want to influence the process of node selection:\n",
    "\n",
    "- Ensuring that a Daemon Set pod runs on a node with specific hardware characteristics (e.g., a node with SSD storage).\n",
    "- Co-locating Daemon Set pods from different services on the same node if they frequently communicate.\n",
    "\n",
    "Kubernetes provides a mechanism for node selection through the use of labels and node selectors. Nodes can be labeled with various attributes, and then, in the Daemon Set configuration, you can specify `nodeSelector` rules to determine which nodes receive the Daemon Set pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example `DaemonSet` configuration `YAML`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml \n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  name: fluentd-elasticsearch\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      name: fluentd-elasticsearch\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        name: fluentd-elasticsearch\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: fluentd-elasticsearch\n",
    "        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n",
    "        resources:\n",
    "          limits:\n",
    "            memory: 200Mi\n",
    "          requests:\n",
    "            cpu: 100m\n",
    "            memory: 200Mi\n",
    "      terminationGracePeriodSeconds: 30\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a Daemon Set named `fluentd-elasticsearch` ensures that a pod running the specified container image, `quay.io/fluentd_elasticsearch/fluentd:v2.5.2`, is deployed to every node in the cluster.\n",
    "\n",
    "Before proceeding, let's briefly go over memory resource management in Kubernetes. In the provided Daemon Set configuration, you'll notice a new field within the `template.spec.container` section called `resources`. This field allows you to set resource limits and requests for the container:\n",
    "\n",
    "- `limits`: These values represent the maximum resource capacities that are allotted to a pod. If a process within the pod consumes more than the specified limit (e.g., exceeding 200MB of RAM), Kubernetes will take action, potentially restarting the pod to enforce resource limits.\n",
    "\n",
    "- `requests`: These values represent the minimum resource capacities that are guaranteed to be available to the pod. In the example configuration, the pod is guaranteed a minimum of 200MB of RAM and 100 milicores (1/1000th of a core). Kubernetes uses these requests for scheduling and placement decisions.\n",
    "\n",
    "For more detailed information on container resource management, you can refer to the [official Kubernetes documentation on managing container resources](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs\n",
    "\n",
    "> **Jobs** are a versatile resource designed to create one or more Pods to perform a task and ensure the successful completion of that task. \n",
    "\n",
    "Jobs are ideal for orchestrating and executing tasks, which could be one-time or batch processes, within a Kubernetes cluster. The tasks are encapsulated within Pods. They monitor the success of their tasks. They repeatedly attempt to execute Pods until a specified number of them successfully complete the assigned task, ensuring that the job is done correctly. You can specify a *termination policy* for Jobs, which dictates under what conditions a Job is considered successful and can be marked as complete\n",
    "\n",
    "Jobs enable parallel execution of the same task multiple times. This is especially useful when you want to process a large number of items concurrently, such as data processing, data transformations, or parallel batch jobs.\n",
    "\n",
    "Here's an example of a Job workload that calculates the value of Ï€:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: pi\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: pi\n",
    "        image: perl\n",
    "        command: [\"perl\",  \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n",
    "      restartPolicy: Never\n",
    "  backoffLimit: 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jobs Specification\n",
    "\n",
    "For Jobs in addition to the standard fields the following fields can also be used: \n",
    "\n",
    "- `.spec.restartPolicy`: Can be either `Never` or `OnFailure` (default). It specifies what should happen when a Pod completes its task.\n",
    "\n",
    "- .`spec.completions`: The number of Pods that should successfully complete before the Job is considered successful\n",
    "\n",
    "- `.spec.parallelism`: The number of Pods to run simultaneously. This allows you to control parallelism in different ways.\n",
    "\n",
    "Using the combination of `.spec.completions` and `.spec.parallelism`, you can construct different levels of parallelism:\n",
    "\n",
    "- **Non-parallel**: If you specify `.spec.completions=1`, only one Job will be created at a time, and a new one will only start after the previous one fails\n",
    "\n",
    "- **Parallel with a fixed completion count**: By setting `.spec.completions=N`, you can run at most N parallel Jobs at any given time. If a Pod or Job fails, the controller will reschedule it to maintain the desired count.\n",
    "\n",
    "- **Parallel with a work queue**: This configuration is achieved by specifying `.spec.completions=1` and `.spec.parallelism=N`. In this mode, N Pods will run concurrently, but the execution of additional Pods continues until all tasks are completed. This approach is useful when you want Pods to communicate directly with each other for improved efficiency.\n",
    "\n",
    "> It's important to note that the default mode is non-parallel, and the default values for `.spec.completions` and `.spec.parallelism `are both set to 1.\n",
    "\n",
    "Additionally, you can specify the [completion mode](https://kubernetes.io/docs/concepts/workloads/controllers/job/#completion-mode), which allows you to modify the behavior of the Pods upon termination.\n",
    "\n",
    "Here are some key points to keep in mind:\n",
    "\n",
    "- Depending on the settings, if `.spec.completions=N` is achieved, the Job is considered successful\n",
    "\n",
    "- Until that point, Kubernetes will attempt to recreate Pods associated with the Job N times, as specified by `.spec.completions`\n",
    "\n",
    "- Exponential back-off delay is applied in case of failures, starting with a retry after 10 seconds, then 20 seconds, and doubling each time, capped at a maximum back-off period of 6 minutes\n",
    "\n",
    "- `.spec.activeDeadlineSeconds`: This field defines the maximum duration (in seconds) that the entire Job is allowed to run. Once this duration is reached, all Pods associated with the Job are terminated, regardless of their completion status.\n",
    "    \n",
    "#### Cleaning Up\n",
    "\n",
    "By default, completed Jobs are not automatically removed from the cluster. This is because you may need to check logs or the status of completed Jobs.\n",
    "\n",
    "However, to manage resources effectively, you can use *TTL (time to live)* to specify when the Job and its associated Pods should be removed from the cluster. TTL can be set using the `.spec.ttlSecondsAfterFinished` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, Jobs will terminate when they successfully execute a number of Pods. To repeat that operation, you would need to `apply` a Kubernetes object to re-run the job. Fortunately, there is an easier approach to generate Jobs periodically with the desired frequency, namely *`CronJobs`*.\n",
    "\n",
    "### Cron Jobs\n",
    "\n",
    "`CronJobs` create `Jobs` on a recurring schedule. You can specify the schedule in the `spec.schedule` field, similar to a Cron expression.\n",
    "\n",
    "``` yaml\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: hello\n",
    "spec:\n",
    "  schedule: \"*/1 * * * *\"\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: hello\n",
    "            image: busybox\n",
    "            imagePullPolicy: IfNotPresent\n",
    "            command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "            - date; echo Hello from the Kubernetes cluster\n",
    "          restartPolicy: OnFailure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Cron Job is scheduled to run according to the specified Cron schedule, `*/1 * * * *`.\n",
    "\n",
    "This schedule means that the `CronJob` runs every minute, as indicated by the `*/1 `in the first field, which represents minutes. The `*` in the other fields means \"every\" for hours, days of the month, months, and days of the week, respectively.\n",
    "\n",
    "> A `CronJob` specifies its schedule using the Cron syntax, which consists of five fields: minute, hour, day of the month, month, and day of the week. You can use wildcards (`*`) and ranges to define flexible schedules. For example, a `CronJob` that runs every day at midnight would have the schedule `0 0 * * *`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Before wrapping up this lesson, let's make sure we clean up all the resources we have been provisioning this lesson. Run the following commands to make sure everything we provision is deleted (you should delete the two `YAML`s you have created, one for the Pod and one for the `nginx` Deployment) using this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f <your-yaml-file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Kubernetes Workloads refer to applications and services running on a Kubernetes cluster. They can be categorized into two main components: Pods and Workload Resources.\n",
    "- Pods are the smallest deployable units in Kubernetes. They group one or more containers, sharing a common context.\n",
    "- Workload Resources are higher-level abstractions for managing Pods' lifecycle. They include Replica Sets, Deployments, Daemon Sets, Jobs, and Cron Jobs. Workload Resources simplify the management of Pods, enabling declarative updates and scaling.\n",
    "- Replica Sets maintain a specified number of replicated Pods. They create and delete Pods based on the desired replica count.\n",
    "- Deployments provide declarative updates for Pods and Replica Sets. They enable rolling updates and rollbacks, ensuring application availability during changes.\n",
    "- Daemon Sets ensure that a Pod runs on every node in the cluster. They are suitable for monitoring or managing services on each node.\n",
    "- Jobs create one or more Pods to complete a task. They can run in parallel, and their completion behavior can be customized.\n",
    "- Cron Jobs automate the creation of Jobs on a schedule. They allow recurring tasks to be executed at specified intervals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
