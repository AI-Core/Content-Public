{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Workloads\n",
    "\n",
    "In the world of Kubernetes, the term \"workload\" refers to the heart of your application - the components that you want to run, manage, and scale within the Kubernetes cluster. These workloads could be web servers, databases, microservices, or any other software that you need to deploy and maintain efficiently.\n",
    "\n",
    "Workloads can be divided into pods and workload resources.\n",
    "\n",
    "## Pods Overview\n",
    "\n",
    "- A Kubernetes Pod is the smallest deployable unit, and it serves as the fundamental building block for your workloads. A Pod can contain one or more containers that run together as a single unit.\n",
    "\n",
    "- It's essential to understand that Pods are designed to be ephemeral. If a Pod fails, Kubernetes can easily recreate it on another node in the cluster. This ephemeral nature ensures resilience and reliability in your applications.\n",
    "\n",
    "- Kubernetes takes the responsibility of managing and rescheduling Pods in the case of node failures or Pod failures. Cluster administrators typically focus on monitoring and ensuring the overall health of the cluster.\n",
    "\n",
    "## Workload Resources Overview\n",
    "\n",
    "In Kubernetes, managing individual Pods manually can be inefficient and error-prone. This is where *Workload Resources* come into play. \n",
    "\n",
    "> Workload Resources are higher-level abstractions that simplify the deployment, scaling, and lifecycle management of Pods. They provide a declarative approach to managing your application, where you specify what you want, and Kubernetes takes care of the rest.\n",
    "\n",
    "Here are some common Workload Resources:\n",
    "\n",
    "- *Deployment*: Use Deployments for deploying stateless applications that need scaling and rolling updates. Deployments ensure that a specified number of replicas (Pods) are running at all times.\n",
    "\n",
    "- *StatefulSet*: When you have stateful applications with unique identities (e.g., databases), StatefulSets are the go-to choice. They provide stable network identities and persistent storage.\n",
    "\n",
    "- *DaemonSet*: For tasks that need to run on every node in the cluster (e.g., logging agents or monitoring tools), DaemonSets ensure that one Pod runs on each node.\n",
    "\n",
    "- *Job and CronJob*: Jobs are used for running batch processes or one-off tasks, while CronJobs allow you to schedule recurring tasks in a cron-like fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pods\n",
    "\n",
    "A Pod in Kubernetes is a fundamental concept and serves as the smallest deployable unit. It's essentially a group of one or more containers that share a common context and a specification for running those containers. Think of Pods as similar to `docker-compose`, allowing you to logically group related containers together.\n",
    "\n",
    "### Shared Context\n",
    "\n",
    "Pods provide a shared context for containers, which includes:\n",
    "\n",
    "- **Shared Storage**: Containers within a Pod can share the same storage volume, making it easy for them to exchange data\n",
    "\n",
    "- **Shared Network Resources**: Containers in a Pod share the same network namespace, often having the same IP address and port space. This allows them to communicate with each other using `localhost`.\n",
    "\n",
    "- **Linux Namespaces**: Pods use Linux namespaces to isolate containers within the same Pod, providing a level of process and network isolation.\n",
    "\n",
    "Importantly, even within a Pod, individual applications can be further isolated as needed.\n",
    "\n",
    "> A Pod is the minimal deployment unit in Kubernetes, which means containers cannot be deployed on their own. They always reside within a Pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle\n",
    "\n",
    "Pods remain on the node where they are scheduled until they are terminated (according to the restart policy in case of failures) or deleted. \n",
    "\n",
    "> Unlike some other container orchestration platforms, Kubernetes Pods are never moved across nodes; instead, they are recreated if needed.\n",
    "\n",
    "Key features include:\n",
    "\n",
    "- Pods cannot initiate self-healing, meaning they don't attempt to restart themselves. The responsibility for restarting Pods lies with the appropriate Workload Resources or the cluster administrator.\n",
    "\n",
    "- Kubernetes uses `kubelet` to automatically restart failed containers within Pods\n",
    "\n",
    "- When a Pod is terminated, related resources like volumes are also deleted, unless specified otherwise\n",
    "\n",
    "#### Pod Phases\n",
    "\n",
    "A Pod can be in one of several phases:\n",
    "\n",
    "- **Pending**: The Pod has been accepted by the Kubernetes cluster, but one or more containers may not have started yet, or the Pod is waiting for node scheduling.\n",
    "\n",
    "- **Running**: At least one container within the Pod is running or being restarted\n",
    "\n",
    "- **Succeeded**: All containers in the Pod have completed their tasks successfully, and no restart is required\n",
    "\n",
    "- **Failed**: At least one container has failed and was terminated\n",
    "\n",
    "- **Unknown**: The state of the Pod cannot be determined, typically due to communication errors with the Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container states\n",
    "\n",
    "Kubernetes also monitors the state of individual containers within each Pod.\n",
    "\n",
    "Containers can be in one of three states:\n",
    "\n",
    "- **Waiting**: This state indicates that the container is waiting for something to happen. It's often seen when a container is downloading its image or pulling secrets required for its operation. The reason for this state is provided for monitoring purposes.\n",
    "\n",
    "- **Running**: This state means the container is actively executing its tasks and is in a healthy operational state\n",
    "\n",
    "- **Terminated**: Containers can be in this state for various reasons. It may be due to a successful termination of the container's task, or it might indicate a failure. When a container terminates, Kubernetes provides the reason for termination and an exit code, which can be invaluable for monitoring and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Container Pods\n",
    "\n",
    "Typically, Pods run with a single container, and a Pod can be seen as a wrapper for that container. Examples include:\n",
    "\n",
    "- A FastAPI server receiving requests and saving data to a shared database\n",
    "- A Docker container that receives image classification requests and forwards them to a classification service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple-Container Pods\n",
    "\n",
    "Multi-container Pods are used in more complex scenarios where multiple tightly coupled containers work together as a cohesive unit. \n",
    "\n",
    "<p align=center><img src=images/pod.svg width=350></p>\n",
    "\n",
    "This setup is ideal for scenarios like:\n",
    "\n",
    "- Training multiple machine learning models, where containers perform tasks like data transformation, model training, model deployment, and serving\n",
    "- Implementing a public data-serving container alongside an internal data-writing container with shared storage\n",
    "\n",
    "> Multi-container Pods are scheduled on the same \"logical host\" due to their tight coupling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view Pods in your cluster, you can use the `kubectl get pod` command. By default, it shows Pods only in the default namespace. To see all Pods in the cluster, add the `-A` flag.\n",
    "\n",
    "If you haven't done so already, you can create a local cluster with `minikube start`. This section will demonstrate how to deploy Pods in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE              NAME                                         READY   STATUS      RESTARTS         AGE\n",
      "default                hello-pod                                    1/1     Running     0                3h10m\n",
      "default                ubuntu-pod                                   1/1     Running     0                3h2m\n",
      "ingress-nginx          ingress-nginx-admission-create-dv2nn         0/1     Completed   0                21h\n",
      "ingress-nginx          ingress-nginx-admission-patch-hxjtf          0/1     Completed   1                21h\n",
      "ingress-nginx          ingress-nginx-controller-7799c6795f-b7zkl    1/1     Running     1 (4h1m ago)     21h\n",
      "kube-system            coredns-5d78c9869d-4nqdp                     1/1     Running     7 (4h1m ago)     2d2h\n",
      "kube-system            etcd-minikube                                1/1     Running     7 (4h1m ago)     2d2h\n",
      "kube-system            kube-apiserver-minikube                      1/1     Running     7 (4h1m ago)     2d2h\n",
      "kube-system            kube-controller-manager-minikube             1/1     Running     8 (20h ago)      2d2h\n",
      "kube-system            kube-proxy-6jdt4                             1/1     Running     7 (4h1m ago)     2d2h\n",
      "kube-system            kube-scheduler-minikube                      1/1     Running     7 (4h1m ago)     2d2h\n",
      "kube-system            storage-provisioner                          1/1     Running     17               2d2h\n",
      "kubernetes-dashboard   dashboard-metrics-scraper-5dd9cbfd69-w66nz   1/1     Running     6 (4h1m ago)     2d2h\n",
      "kubernetes-dashboard   kubernetes-dashboard-5c5cfc8747-6q6ft        1/1     Running     10 (3h59m ago)   2d2h\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod -A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we already have some Pods. This is because `minikube` deploys some Pods by default. In the next section, we will look at how to deploy Pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pods\n",
    "\n",
    "In Kubernetes, you can define Pods imperatively (step by step) or declaratively using `.yaml` files. However, specifying bare Pods directly is generally discouraged because it leaves them without the necessary mechanisms for self-recovery and management. Instead, it's recommended to use higher-level abstractions like Deployments or ReplicaSets to manage Pods and ensure their availability.\n",
    "\n",
    "While it's possible to specify a bare Pod directly, it's important to understand that doing so may not be suitable for most production scenarios. Below is an example of specifying a bare Pod for reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: pod1\n",
    "  labels:\n",
    "    tier: frontend\n",
    "spec:\n",
    "  containers:\n",
    "  - name: hello1\n",
    "    image: gcr.io/google-samples/hello-app:2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we've defined a Pod named `pod1` with a single container called `hello1` using a specific Docker image. However, without higher-level controllers like Deployments or ReplicaSets, this Pod won't have the ability to recover from failures or scale automatically.\n",
    "\n",
    "In practice, for robust and scalable application deployments, it's recommended to use the appropriate Workload Resources, which we'll explore in the next section, to manage Pods effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to try running some `kubectl` commands yourself. Follow the instructions to run some important Pods commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h13m\n",
      "ubuntu-pod   1/1     Running   0          3h6m\n"
     ]
    }
   ],
   "source": [
    "# Observe the pods in the default namespace\n",
    "!kubectl ###Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/pod1 created\n"
     ]
    }
   ],
   "source": [
    "# Spin up the pod corresponding to the single-pod configuration above\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h14m\n",
      "pod1         1/1     Running   0          17s\n",
      "ubuntu-pod   1/1     Running   0          3h6m\n"
     ]
    }
   ],
   "source": [
    "# Observe the pods in the default namespace again\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"pod1\" deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the pod created above\n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         READY   STATUS    RESTARTS   AGE\n",
      "hello-pod    1/1     Running   0          3h15m\n",
      "ubuntu-pod   1/1     Running   0          3h7m\n"
     ]
    }
   ],
   "source": [
    "# observe the resources in the default namespace again \n",
    "!kubectl ##Your command here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the case in the last notebook, the pod disappears here. This is because, contrary to the case in the last notebook, no instructions were provided here to keep the pod alive. The pod is 'bare', without any resource to keep it running after it fails. \n",
    "\n",
    "Keeping it 'alive' is one of the desired states that can be specified in the config file, and it can be achieved with Deployment or Replica Set. We will look at more options in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workload Resources\n",
    "\n",
    "Before diving into specific Workload Resources, let's cover some important concepts that apply to all of them:\n",
    "\n",
    "- Each Workload Resource uses the `.spec.template` field to specify how to create a Pod\n",
    "\n",
    "- The template for a Workload Resource is essentially the same as a Pod configuration, except for the `kind` and `apiVersion` fields\n",
    "\n",
    "- Workload Resources also have a `.spec.selector` field, which specifies which Pods are managed by the Workload Resource\n",
    "\n",
    "- The `.spec.selector` can employ matches on defined labels, allowing the Workload Resource to manage Pods even if they are defined in a separate configuration file\n",
    "\n",
    "Workload Resources can be implemented using different controllers, including **ReplicaSets**, **Deployment**, **DaemonSet**, and **Jobs**. In a future lesson, we will explore another type of Workload Resource called *StatefulSets*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReplicaSet\n",
    "\n",
    ">  ReplicaSet is a controller that ensures a stable set of replicated Pods running at any given time. It maintains a specified number of replicas of Pods.\n",
    "\n",
    "#### Acquiring Pods\n",
    "\n",
    "ReplicaSet acquires Pods using the `metadata.ownerReferences` field and matching the .`spec.selector`. Here's how it works:\n",
    "\n",
    "- Each Pod has an `metadata.ownerReferences` field that is automatically added by Kubernetes. This field specifies who manages the Pod, which can be another controller.\n",
    "\n",
    "- If a Pod has no 'owner' (e.g., it's a bare Pod) or its owner is not another controller, and the `.spec.selector` fields match, then the Pod is acquired by the ReplicaSet.\n",
    "\n",
    "> This acquisition process is similar for other Workload Resources.\n",
    "\n",
    "#### Using ReplicaSets\n",
    "\n",
    "In general, it's recommended to use higher-level controllers like Deployments for managing Pods and ReplicaSets. Deployments manage ReplicaSets and provide declarative updates to Pods.\n",
    "\n",
    "ReplicaSets may be employed when:\n",
    "\n",
    "- Custom update orchestration is required\n",
    "- The configuration file will not be updated\n",
    "\n",
    "However, it's worth noting that Deployments offer a higher level of abstraction and ease of use.\n",
    "\n",
    "For more detailed information on ReplicaSets, check [here](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "> Deployment is a controller that provides declarative updates for Pods and ReplicaSets.\n",
    "\n",
    "Consider the example config below, and attempt to decipher the meaning of each field:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "  labels:\n",
    "    app: nginx\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.14.2\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we instruct the resource to ensure that at least three Pods are running at all times. These Pods are identified using the `selector.matchLabels`, which searches the template for the label with the key `app` and value `nginx`.\n",
    "\n",
    "#### Hands-On\n",
    "\n",
    "1. Create a `.yaml` file with the provided configuration\n",
    "2. Use the appropriate `kubectl` command to apply the `.yaml` file\n",
    "3. Observe the number of Pods created\n",
    "4. Delete one of the Pods\n",
    "5. Observe the number of Pods again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/nginx-deployment created\n"
     ]
    }
   ],
   "source": [
    "# run the .yaml file\n",
    "!kubectl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS              RESTARTS   AGE\n",
      "nginx-deployment-66b6c48dd5-7qpvr   0/1     ContainerCreating   0          17s\n",
      "nginx-deployment-66b6c48dd5-gc7z7   0/1     ContainerCreating   0          17s\n",
      "nginx-deployment-66b6c48dd5-vzsx2   0/1     ContainerCreating   0          17s\n"
     ]
    }
   ],
   "source": [
    "# Observe how many pods you have\n",
    "!kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"nginx-deployment-66b6c48dd5-vzsx2\" deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete one of the pods\n",
    "!kubectl delete pod nginx-deployment-66b6c48dd5-vzsx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS    RESTARTS        AGE\n",
      "nginx-deployment-66b6c48dd5-7qpvr   1/1     Running   1 (8m15s ago)   8h\n",
      "nginx-deployment-66b6c48dd5-fsck5   1/1     Running   0               40s\n",
      "nginx-deployment-66b6c48dd5-gc7z7   1/1     Running   1 (8m15s ago)   8h\n"
     ]
    }
   ],
   "source": [
    "# Observe how many pods you have again\n",
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting a Pod, you should see that a new Pod has been created by the Deployment to maintain the desired number of replicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DaemonSet\n",
    "\n",
    "> DaemonSet is a controller that ensures a Pod is deployed on all Nodes in the cluster. Each Node gets one instance of the Pod.\n",
    "\n",
    "In the examples thus far, we had one pod per node; therefore, if a node is removed, the number of pods will decrease.\n",
    "\n",
    "#### Node Selection in DaemonSets\n",
    "\n",
    "One distinctive feature of DaemonSets is that they ensure a single pod runs on each node in the cluster. The `replicas` field, commonly used in Deployments, is not present in DaemonSet configurations because there is always one pod per node.\n",
    "\n",
    "Generally, Kubernetes automatically handles the assignment of pods to nodes. However, there are cases where you might want to influence this process:\n",
    "\n",
    "- Ensuring that a pod runs on a node with specific hardware characteristics (e.g., a node with SSD storage)\n",
    "- Co-locating pods from different services on the same node if they frequently communicate\n",
    "\n",
    "Kubernetes provides a mechanism for node selection through the use of labels and node selectors. Nodes can be labeled with various attributes, and then, in the DaemonSet configuration, you can specify `nodeSelector` rules to determine which nodes receive the DaemonSet pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example DaemonSet configuration `YAML`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml \n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  name: fluentd-elasticsearch\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      name: fluentd-elasticsearch\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        name: fluentd-elasticsearch\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: fluentd-elasticsearch\n",
    "        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n",
    "        resources:\n",
    "          limits:\n",
    "            memory: 200Mi\n",
    "          requests:\n",
    "            cpu: 100m\n",
    "            memory: 200Mi\n",
    "      terminationGracePeriodSeconds: 30\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a DaemonSet named `fluentd-elasticsearch` ensures that a pod running the specified container image (`quay.io/fluentd_elasticsearch/fluentd:v2.5.2`) is deployed to every node in the cluster.\n",
    "\n",
    "Before proceeding, let's briefly go over memory resource management in Kubernetes. In the provided DaemonSet configuration, you'll notice a new field within the `template.spec.container` section called `resources`. This field allows you to set resource limits and requests for the container.\n",
    "\n",
    "- `limits`: These values represent the maximum resource capacities that are allotted to a pod. If a process within the pod consumes more than the specified limit (e.g., exceeding 200MB of RAM), Kubernetes will take action, potentially restarting the pod to enforce resource limits.\n",
    "\n",
    "- `requests`: These values represent the minimum resource capacities that are guaranteed to be available to the pod. In the example configuration, the pod is guaranteed a minimum of 200MB of RAM and 100 milicores (1/1000th of a core). Kubernetes uses these requests for scheduling and placement decisions.\n",
    "\n",
    "For more detailed information on container resource management, you can refer to the [official Kubernetes documentation on managing container resources](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs\n",
    "\n",
    "Jobs create one or more Pods and repeatedly attempt to execute them until a specified number successfully terminates. Jobs are useful when you need to ensure the successful execution of a task or when you want to run the same task in parallel multiple times.\n",
    "\n",
    "Here's an example of a Job workload that calculates the value of Ï€:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: pi\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: pi\n",
    "        image: perl\n",
    "        command: [\"perl\",  \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n",
    "      restartPolicy: Never\n",
    "  backoffLimit: 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specification\n",
    "\n",
    "For Jobs, the standard fields are necessary, in addition to the following fields:\n",
    "\n",
    "- `.spec.restartPolicy`: Can be either `Never` or `OnFailure` (default). It specifies what should happen when a Pod completes its task.\n",
    "\n",
    "- .`spec.completions`: The number of Pods that should successfully complete before the Job is considered successful\n",
    "\n",
    "- `.spec.parallelism`: The number of Pods to run simultaneously. This allows you to control parallelism in different ways.\n",
    "\n",
    "Using the combination of `.spec.completions` and `.spec.parallelism`, you can construct different levels of parallelism:\n",
    "\n",
    "- **Non-parallel**: If you specify `.spec.completions=1`, only one Job will be created at a time, and a new one will only start after the previous one fails\n",
    "\n",
    "- **Parallel with a fixed completion count**: By setting `.spec.completions=N`, you can run at most N parallel Jobs at any given time. If a Pod or Job fails, the controller will reschedule it to maintain the desired count.\n",
    "\n",
    "- **Parallel with a work queue**: This configuration is achieved by specifying `.spec.completions=1` and `.spec.parallelism=N`. In this mode, N Pods will run concurrently, but the execution of additional Pods continues until all tasks are completed. This approach is useful when you want Pods to communicate directly with each other for improved efficiency.\n",
    "\n",
    "> It's important to note that the default mode is non-parallel, and the default values for `.spec.completions` and `.spec.parallelism `are both set to 1.\n",
    "\n",
    "Additionally, you can specify the [completion mode](https://kubernetes.io/docs/concepts/workloads/controllers/job/#completion-mode), which allows you to modify the behaviour of the Pods upon termination.\n",
    "\n",
    "Here are some key points to keep in mind:\n",
    "\n",
    "- Depending on the settings, if `.spec.completions=N` is achieved, the Job is considered successful\n",
    "\n",
    "- Until that point, Kubernetes will attempt to recreate Pods associated with the Job N times, as specified by `.spec.completions`\n",
    "\n",
    "- Exponential back-off delay is applied in case of failures, starting with a retry after 10 seconds, then 20 seconds, and doubling each time, capped at a maximum backoff period of 6 minutes.\n",
    "\n",
    "- `.spec.activeDeadlineSeconds`: This field defines the maximum duration (in seconds) that the entire Job is allowed to run. Once this duration is reached, all Pods associated with the Job are terminated, regardless of their completion status.\n",
    "    \n",
    "#### Cleaning Up\n",
    "\n",
    "By default, completed Jobs are not automatically removed from the cluster. This is because you may need to check logs or the status of completed Jobs.\n",
    "\n",
    "However, to manage resources effectively, you can use TTL (time to live) to specify when the Job and its associated Pods should be removed from the cluster. TTL can be set using the `.spec.ttlSecondsAfterFinished` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, Jobs will terminate when they successfully execute a number of Pods. To repeat that operation, you would need to `apply` a Kubernetes object to re-run the job. Fortunately, there is an easier approach to generate Jobs periodically with the desired frequency, namely *Cronjobs*.\n",
    "\n",
    "### CronJobs\n",
    "\n",
    "CronJobs create Jobs on a recurring schedule. You can specify the schedule in the `spec.schedule` field, similar to a cron expression.\n",
    "\n",
    "``` yaml\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: hello\n",
    "spec:\n",
    "  schedule: \"*/1 * * * *\"\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: hello\n",
    "            image: busybox\n",
    "            imagePullPolicy: IfNotPresent\n",
    "            command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "            - date; echo Hello from the Kubernetes cluster\n",
    "          restartPolicy: OnFailure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CronJob is scheduled to run according to the specified cron schedule, `*/1 * * * *`.\n",
    "\n",
    "This schedule means that the CronJob runs every minute, as indicated by the `*/1 `in the first field, which represents minutes. The `*` in the other fields means \"every\" for hours, days of the month, months, and days of the week, respectively.\n",
    "\n",
    "> A CronJob specifies its schedule using the cron syntax, which consists of five fields: minute, hour, day of the month, month, and day of the week. You can use wildcards (`*`) and ranges to define flexible schedules. For example, a CronJob that runs every day at midnight would have the schedule `0 0 * * *`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Before wrapping up this lesson, let's make sure we clean up all the resources we have been provisioning this lesson. Run the following commands to make sure everything we provision is deleted (you should delete the two  `YAML`s you have created, one for the Pod and one for the `nginx` Deployment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f <your-yaml-file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Kubernetes workloads refer to applications and services running on a Kubernetes cluster. They can be categorized into two main components: Pods and Workload Resources.\n",
    "- Pods are the smallest deployable units in Kubernetes. They group one or more containers, sharing a common context.\n",
    "- Workload Resources are higher-level abstractions for managing Pods' lifecycles. They include ReplicaSets, Deployments, DaemonSets, Jobs, and CronJobs. Workload Resources simplify the management of Pods, enabling declarative updates and scaling.\n",
    "- ReplicaSets maintain a specified number of replicated Pods. They create and delete Pods based on the desired replica count.\n",
    "- Deployments provide declarative updates for Pods and ReplicaSets. They enable rolling updates and rollbacks, ensuring application availability during changes.\n",
    "- DaemonSets ensure that a Pod runs on every node in the cluster. They are suitable for monitoring or managing services on each node.\n",
    "- Jobs create one or more Pods to complete a task. They can run in parallel, and their completion behavior can be customized.\n",
    "- CronJobs automate the creation of Jobs on a schedule. They allow recurring tasks to be executed at specified intervals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
