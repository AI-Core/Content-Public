{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Deployment Strategies\n",
    "\n",
    "Deployment strategies play a pivotal role in Kubernetes. They are essential for ensuring the seamless rollout of updates, minimizing downtime, and maintaining application reliability in dynamic, containerized environments.\n",
    "\n",
    "Kubernetes orchestrates the deployment and scaling of containerized applications within a Kubernetes cluster. However, the process of updating those applications without causing disruptions or errors is a complex challenge within this distributed environment. Deployment strategies provide a structured approach to address this challenge by defining how new versions of an application are released, monitored, and, if necessary, rolled back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Deployment Strategies\n",
    "\n",
    "The choice of deployment strategy directly impacts application reliability, availability, and user experience. Here's how:\n",
    "\n",
    "- **Minimizing Downtime**: Deployment strategies like *rolling updates*, *blue-green deployments*, and *canary deployments* enable organizations to update their applications with minimal to no downtime. This is crucial for businesses that operate 24/7 and can't afford disruptions.\n",
    "\n",
    "- **Rollback Capabilities**: A well-designed deployment strategy provides the ability to quickly and safely roll back to a previous version in case of unforeseen issues or bugs. This ensures that the application can maintain reliability even in the face of problems.\n",
    "\n",
    "- **Risk Mitigation**: Deployment strategies, such as canary deployments and *A/B testing*, allow organizations to test new features or changes on a subset of users before deploying them to the entire user base. This helps mitigate the risk of introducing harmful changes.\n",
    "\n",
    "- **Scalability**: Some deployment strategies, like blue-green deployments, enable the parallel deployment of multiple versions of an application. This can be advantageous for load testing and scaling purposes, contributing to reliability under heavy traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Deployment Strategies \n",
    "\n",
    "### Rolling Updates\n",
    "\n",
    "> **Rolling updates** are a Kubernetes deployment strategy used to update an application by gradually replacing old instances of the application with new ones. This approach ensures minimal or no downtime during the update process and maintains the availability and reliability of the application.\n",
    "\n",
    "#### Characteristics of Rolling Updates\n",
    "\n",
    "- **Gradual Replacement**: Rolling updates replace old instances of an application with new ones one at a time, ensuring a smooth transition\n",
    "\n",
    "- **Continuous Availability**: The application remains accessible to users throughout the update process\n",
    "\n",
    "- **Controlled Rollout**: Rolling updates allow operators to control the rate at which instances are updated, making it possible to monitor and pause the update if issues arise\n",
    "\n",
    "- **Built-in Health Checks**: Kubernetes automatically performs health checks to ensure that the new instances are healthy before proceeding with the update\n",
    "\n",
    "#### How Rolling Updates Work in Kubernetes\n",
    "\n",
    "1. Replica Sets: Rolling updates are typically managed using Kubernetes Replica Sets. A `ReplicaSet` ensures that a specified number of pod replicas are running at all times.\n",
    "\n",
    "2. **Updating the Pod Template**: To initiate a rolling update, you update the pod template of the `ReplicaSet` to specify the new version of the application container.\n",
    "\n",
    "3. **Pod Replacement**: Kubernetes gradually replaces old pods with new ones, following a controlled strategy:\n",
    "\n",
    "   - Kubernetes creates new pods with the updated configuration, one at a time\n",
    "   - It ensures that the new pods are healthy and ready before terminating an old pod\n",
    "   - This process continues until all old pods have been replaced with new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hands-On: Kubernetes `YAML` for Rolling Updates\n",
    "\n",
    "##### Step 1: Create the Deployment `YAML`(v1)\n",
    "\n",
    "Create a `YAML` file for the initial deployment (v1). Save this as `nginx-deployment-v1.yaml`.\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.13.1\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "\n",
    "```\n",
    "\n",
    "Apply the deployment to create the initial version of the application:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f nginx-deployment-v1.yaml\n",
    "```\n",
    "\n",
    "##### Step 2: Verify the Initial Deployment\n",
    "\n",
    "Check the status of the deployment and pods to ensure the initial version is running:\n",
    "\n",
    "```bash\n",
    "kubectl get deployment nginx-deployment\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "When you run the first command you should see an output similar to the following:\n",
    "\n",
    "```css\n",
    "NAME              READY   UP-TO-DATE   AVAILABLE   AGE\n",
    "nginx-deployment  3/3     3            3           <time>\n",
    "```\n",
    "\n",
    "If the `READY`, `UP-TO-DATE`, and `AVAILABLE` columns all show numbers matching your desired number of replicas (in this case, 3), it indicates that the initial deployment is running without issues.\n",
    "\n",
    "When running the second command you should see an output similar to the following:\n",
    "\n",
    "```php\n",
    "NAME                               READY   STATUS    RESTARTS   AGE\n",
    "nginx-deployment-<pod-id-1>        1/1     Running   0          <time>\n",
    "nginx-deployment-<pod-id-2>        1/1     Running   0          <time>\n",
    "nginx-deployment-<pod-id-3>        1/1     Running   0          <time>\n",
    "```\n",
    "\n",
    "If you see output like this for each of your replicas, it indicates that the pods are running as expected. This means the initial deployment has been successfully created, and the pods are running without issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Create the Updated Deployment `YAML` (v2)\n",
    "\n",
    "Next, create a `YAML` file for the updated deployment (v2). Save this as `nginx-deployment-v2.yaml`:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.14.2\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 1\n",
    "      maxUnavailable: 1\n",
    "```\n",
    "\n",
    "In the above example:\n",
    "\n",
    "- `type: RollingUpdate`: This specifies the type of deployment strategy, which is **Rolling Update**. In a Rolling Update, pods are updated incrementally, minimizing downtime by replacing a specified number of pods at a time.\n",
    "\n",
    "- `rollingUpdate`:\n",
    "\n",
    "  - `maxSurge: 1`: This parameter controls how many additional pods can be created above the desired number of replicas during an update. In this example, it allows one additional pod to be created while maintaining the total number of replicas.\n",
    "  \n",
    "  - `maxUnavailable: 1`: This parameter defines how many pods can be unavailable (i.e., terminated) at a time during an update. In this example, it allows one pod to be unavailable while others are updated, ensuring continuous availability.\n",
    "\n",
    "> Updates don't necessarily have to be reflected in the Deployment manifest, but they can also be changes to your application code that triggers the re-deployment. We will cover this case scenario in more detail in a later lesson, when we learn about Azure DevOps Pipelines.\n",
    "\n",
    "##### Step 4: Perform the Rolling Update\n",
    "\n",
    "Apply the updated deployment to initiate the rolling update:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f nginx-deployment-v2.yaml\n",
    "```\n",
    "\n",
    "Kubernetes will automatically manage the rolling update, gradually replacing pods running the old version (NGINX 1.13.1) with pods running the new version (NGINX 1.14.2).\n",
    "\n",
    "##### Step 5: Monitor the Rolling Update\n",
    "\n",
    "You can monitor the progress of the rolling update by checking the deployment's status and the pods:\n",
    "\n",
    "```bash\n",
    "kubectl get deployment nginx-deployment\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Kubernetes ensures that the new pods are healthy and ready before terminating the old ones. It manages the update with minimal disruption to your application.\n",
    "\n",
    "When you run the first command you should see an output similar to the following:\n",
    "\n",
    "```css\n",
    "NAME              READY   UP-TO-DATE   AVAILABLE   AGE\n",
    "nginx-deployment  3/3     3            3           <time>\n",
    "```\n",
    "\n",
    "During a rolling update, you should observe that the `READY`, `UP-TO-DATE`, and `AVAILABLE` columns continue to show numbers matching your desired number of replicas (in this case, 3). It indicates that the rolling update is maintaining the desired availability of your application.\n",
    "\n",
    "When running the second command you should see an output similar to the following:\n",
    "\n",
    "```php\n",
    "NAME                               READY   STATUS        RESTARTS   AGE\n",
    "nginx-deployment-<pod-id-1>        1/1     Running       0          <time>\n",
    "nginx-deployment-<pod-id-2>        1/1     Terminating   0          <time>\n",
    "nginx-deployment-<pod-id-3>        1/1     Running       0          <time>\n",
    "```\n",
    "\n",
    "In a rolling update, Kubernetes will gradually replace old pods with new ones. You should observe that some pods may briefly enter a `Terminating` state, but if the process happens rapidly and efficiently, you might not see this transition. Instead, you may directly observe that new pods are in a `Running` state. This situation indicates that the rolling update is proceeding as expected and is efficiently replacing old pods with new ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6: Deployment Verification\n",
    "\n",
    "Once the rolling update is complete, verify that all pods are running the new version:\n",
    "\n",
    "```bash\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "The key point to note is that the pod IDs (`<pod-id-X>`) might be the same as the previous step if the rolling update happened very quickly. However, they should be entirely different from the pod IDs of the initial deployment (v1). This change in pod IDs confirms that the rolling update has been successful, and you are indeed observing pods running the updated version (v2) of your application.\n",
    "\n",
    "##### Step 7: Clean Up Resources\n",
    "\n",
    "After you have successfully completed your rolling update and verified the updated deployment, it's good practice to clean up the resources to avoid unnecessary consumption of cluster resources. \n",
    "\n",
    "Delete the updated `Deployment`:\n",
    "\n",
    "```bash\n",
    "kubectl delete deployment nginx-deployment\n",
    "```\n",
    "\n",
    "Verify that the `Deployment` has been deleted:\n",
    "\n",
    "```bash\n",
    "kubectl get deployment nginx-deployment\n",
    "```\n",
    "\n",
    "You should see a message indicating that the `Deployment` does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate Deployments\n",
    "\n",
    "> *Recreate Deployments* in Kubernetes involve replacing all existing pods with new ones simultaneously. \n",
    "\n",
    "#### When to Use Recreate Deployments\n",
    "\n",
    "- **Major Version Updates**: If you are making significant changes, such as updating the core software version (e.g., database engine, application framework) or modifying the application's fundamental architecture, a Recreate Deployment may be preferred. In such cases, it's simpler to start fresh with new pods.\n",
    "\n",
    "- **Immutable Infrastructure**: If you follow the principle of immutable infrastructure, where you create new instances instead of modifying existing ones, Recreate Deployments align well with this approach\n",
    "\n",
    "- **Ensuring Clean State**: When you want to ensure that no remnants of the old version exist and that the new version starts with a clean state, a Recreate Deployment provides this guarantee\n",
    "\n",
    "#### Rolling Updates vs Recreate Deployments\n",
    "\n",
    "1. **Termination and Creation**: In a Rolling Update, pods are replaced incrementally, meaning some pods are running the new version while others are still running the old version. This minimizes downtime but results in coexistence of old and new pods during the update process. For example:\n",
    "\n",
    "```css\n",
    "NAME                        READY   STATUS        RESTARTS   AGE\n",
    "nginx-deployment-1          1/1     Running       0          <time>\n",
    "nginx-deployment-2          1/1     Terminating   0          <time>\n",
    "nginx-deployment-3          1/1     Running       0          <time>\n",
    "```\n",
    "In a Recreate Deployment, all existing pods are terminated before new pods are created. This results in a brief period of unavailability during the update, but it ensures that the new version starts with a clean slate. For example:\n",
    "\n",
    "```css\n",
    "NAME                        READY   STATUS        RESTARTS   AGE\n",
    "nginx-recreate-1            0/1     Terminating   0          <time>\n",
    "nginx-recreate-2            0/1     Terminating   0          <time>\n",
    "nginx-recreate-3            0/1     Terminating   0          <time>\n",
    "```\n",
    "\n",
    "2. **Resource Control**: Rolling Updates provide fine-grained control over how many pods can be updated simultaneously (controlled by `maxSurge`) and how many can be unavailable (controlled by `maxUnavailable`) during an update. Recreate Deployments are simpler to implement and understand, as they do not require complex update strategies.\n",
    "\n",
    "3. **Complexity**: The `YAML` configuration for Rolling Updates includes additional parameters in the `strategy` field\n",
    "\n",
    "When creating a Recreate Deployment in Kubernetes, ensure that you include the `strategy` field with the type set to `Recreate` to explicitly define the deployment strategy. This how the deployment `YAML` configuration in the hands-on above should look like to use Recreate Deployments as the deployment strategy:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.14.2\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "  strategy:\n",
    "    type: Recreate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blue-Green Deployments\n",
    "\n",
    "> **Blue-Green Deployments** are a deployment strategy that involves maintaining two separate environments: one for the current production version (Blue) and another for the new version (Green). Blue-Green Deployments offer benefits such as zero-downtime updates, easy rollback, and the ability to thoroughly test new versions before making them live.\n",
    "\n",
    "Blue-Green Deployments are an excellent choice when you need uninterrupted updates for mission-critical applications, frequently deploy new versions, have a large user base, require rigorous testing, or need effective risk mitigation for high-stakes deployments.\n",
    "\n",
    "#### Steps to Set Up a Blue-Green Deployment\n",
    "\n",
    "1. **Create Two Environments**: First, create two identical environments, one for the current production version (Blue) and one for the new version (Green). These environments should include all the necessary resources such as pods, services, etc.\n",
    "\n",
    "2. **Deploy the New Version**: Deploy the new version of your application into the Green environment. Ensure that it is fully configured and ready for testing.\n",
    "\n",
    "3. **Test the Green Environment**: Thoroughly test the Green environment to validate the new version's functionality and performance. This testing phase can include various testing methods, such as automated tests, user acceptance testing, and performance testing.\n",
    "\n",
    "4. **Switch Traffic to Green**: Once testing is successful, switch traffic from the Blue environment to the Green environment. This can be achieved by updating the service or ingress configuration to route traffic to the Green environment.\n",
    "\n",
    "5. **Monitor and Validate**: Continuously monitor the Green environment to ensure it is performing as expected in the production environment. Monitor metrics, logs, and user feedback to validate the new version's stability.\n",
    "\n",
    "6. **Rollback** (if necessary): If issues arise in the Green environment, you can quickly switch traffic back to the Blue environment to minimize the impact on users. Investigate and resolve any issues in the Green environment before reattempting the update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traffic Redirection in Blue-Green Deployments\n",
    "\n",
    "In a Blue-Green Deployment, redirecting traffic from the Blue (current production) environment to the Green (new version) environment is a crucial step. Here are different methods to achieve traffic redirection, each with its own approach:\n",
    "\n",
    "1. **Ingress Controllers**:\n",
    "\n",
    "    - In Kubernetes, an ingress controller can be configured to manage external access to services in the cluster. In a Blue-Green Deployment, you can use ingress controllers to control traffic redirection based on specific rules.\n",
    "\n",
    "    - Ingress controllers examine incoming requests and route them to the appropriate backend service based on factors like hostnames, paths, or other criteria defined in the ingress resource\n",
    "\n",
    "    - Example: You can define an ingress resource that specifies which hostnames or paths should be routed to the Green environment's service. The ingress controller then handles the redirection based on these rules.\n",
    "\n",
    "2. **Service Labels and Selectors**:\n",
    "\n",
    "    - Kubernetes services can be configured with labels and selectors. You can leverage these labels and selectors to route traffic between services.\n",
    "\n",
    "    - When defining services, you can set labels on pods and specify a selector in the service definition. The service routes traffic to pods that match the selector label.\n",
    "\n",
    "    - Example: By configuring the service to select pods with a specific label (e.g., `app: my-app-green`), you can ensure that traffic is directed to the Green environment's pods\n",
    "\n",
    "3. **Node Port Services**:\n",
    "\n",
    "    - Kubernetes allows you to create Node Port services, which expose a specific port on all nodes in the cluster. While not ideal for production use, Node Port services can be used for simple traffic redirection.\n",
    "\n",
    "    - Node Port services bind a port on each node to the service. Incoming traffic on that node's IP address and port is redirected to the service's pods\n",
    "\n",
    "4. **Load Balancers**:\n",
    "\n",
    "    - In cloud environments, you can configure cloud-based load balancers to distribute traffic among a set of pods. Many cloud providers offer load balancer services that integrate with Kubernetes.\n",
    "\n",
    "    - Load balancers distribute incoming traffic across multiple pods to achieve load balancing and high availability\n",
    "\n",
    "    - Example: Configure a cloud load balancer to target the service associated with the Green environment's pods. The load balancer will distribute traffic to those pods.\n",
    "\n",
    "5. **DNS Switchover**:\n",
    "\n",
    "    - DNS, short for Domain Name System, is critical component of internet traffic routing acting like the internet's phone book. It's a crucial component that helps computers and devices find each other on the internet.\n",
    "\n",
    "    - Update DNS records to point to the IP addresses associated with the Green environment's service. Clients accessing your application will resolve the DNS name to the new IP addresses.\n",
    "\n",
    "    - Example: In the DNS provider's settings, modify the DNS records to associate the application's domain or subdomain with the new IP addresses of the Green environment's service.\n",
    "\n",
    "Each of these methods provides a way to redirect traffic from the Blue to the Green environment during a Blue-Green Deployment. The choice of method depends on your specific infrastructure, requirements, and constraints. It's important to plan and test the chosen method to ensure a smooth transition of traffic to the new version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Blue-Green Deployment `YAML` Configuration\n",
    "\n",
    "Below is a simplified example of a Blue-Green Deployment `YAML` configuration in Kubernetes. In practice, your configuration may include additional resources and settings:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: my-app-green\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-app-green\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: my-app-green\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: my-app-container\n",
    "        image: my-app:2.0  # New version (Green)\n",
    "\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: my-app-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: my-app-green  # Route traffic to the Green environment\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 8080\n",
    "\n",
    "# Ingress configuration for routing traffic based on hostnames\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: Ingress\n",
    "metadata:\n",
    "  name: my-app-ingress\n",
    "spec:\n",
    "  rules:\n",
    "    - host: my-app.example.com\n",
    "      http:\n",
    "        paths:\n",
    "        - path: /\n",
    "          pathType: Prefix\n",
    "          backend:\n",
    "            service:\n",
    "              name: my-app-service\n",
    "              port:\n",
    "                number: 80\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- There are two environments: Blue and Green\n",
    "\n",
    "- The Green environment (`my-app-green`) contains the new version of the application\n",
    "\n",
    "- The service (`my-app-service`) acts as an internal load balancer within your Kubernetes cluster. It directs traffic from within the cluster to the pods managed by the Deployment (`my-app-green`) based on the label selector. In this case, it routes traffic to the Green environment (`my-app-green`) by selecting pods with the label `app: my-app-green`.\n",
    "\n",
    "- The ingress (`my-app-ingress`) is used for routing external traffic into your Kubernetes cluster. It enables you to expose your application to the internet or to other networks. In this example, the Ingress is configured to route traffic based on the hostname (`my-app.example.com`) and path (`/`). The Ingress is directing external traffic to the Service (`my-app-service`), which in turn routes it to the Green environment (`my-app-green`). This is needed for applications that need to be exposed externally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canary Deployments\n",
    "\n",
    "> **Canary Deployments** are a deployment strategy that involves releasing a new version of an application to a subset of users or traffic before exposing it to the entire user base. The term \"canary\" is inspired by the practice of using canaries in coal mines to detect toxic gases. In software, canary deployments act as early warning systems, allowing you to detect and address issues before they affect all users.\n",
    "\n",
    "The primary purpose of canary deployments is to minimize risk and gain confidence in the new version of an application. Key objectives include:\n",
    "\n",
    "- **Risk Mitigation**: Canary deployments reduce the risk of deploying a flawed or unstable version to all users. By exposing a small subset of users to the update, you can quickly detect and address issues.\n",
    "\n",
    "- **Gradual Rollout**: Canary deployments enable a gradual rollout of new features or updates. This allows you to assess the impact on real users and gather feedback before a full release.\n",
    "\n",
    "- **Performance Validation**: Canary deployments provide an opportunity to validate the performance and behavior of a new version in a production environment under real-world conditions\n",
    "\n",
    "While both Canary and Blue-Green Deployments aim to reduce risk during updates, they differ in their approach. Canary Deployments gradually release a new version to a subset of users or traffic. The percentage of users exposed to the update increases over time as confidence grows. Meanwhile, Blue-Green Deployments maintain two separate environments (Blue for the current version and Green for the new version), and then switch all user traffic from Blue to Green once the new version is deemed ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Canary Deployments\n",
    "\n",
    "Canary Deployments allow for a controlled and gradual transition to a new version by directing only a fraction of user traffic to the canary group. This controlled transition is crucial for minimizing risk and ensuring that the new version performs well in a production environment.\n",
    "\n",
    "There are two primary approaches for achieving gradual updates in Canary Deployments:\n",
    "\n",
    "- **Traffic Splitting**: Gradually direct user traffic between the existing production version and the canary version. This is typically done by adjusting the percentage of traffic allocated to each group. For example, you might start with 90% of users on the old version and 10% on the canary. As you gain confidence in the canary version's stability, you can increase the percentage of traffic directed to it.\n",
    "\n",
    "- **Feature Flags**: Implement feature flags within the application to selectively enable or disable specific features for the canary group. This approach allows you to test new functionality with a subset of users while keeping the rest of the application unchanged.\n",
    "\n",
    "> Effective Canary Deployments rely on metrics and observability to ensure the performance and health of the canary group. \n",
    "\n",
    "Key practices include:\n",
    "\n",
    "- **Instrumentation**: Implement comprehensive monitoring, logging, and tracing in your application to collect data on performance, errors, and user behavior. Tools like Prometheus, Grafana, and ELK Stack can help with this.\n",
    "\n",
    "- **Service Level Objectives (SLOs)**: Define Service Level Objectives that establish acceptable performance thresholds for your application. Monitor these SLOs during the canary deployment to ensure they are met. For instance, you might set SLOs for response times or error rates.\n",
    "\n",
    "- **Error Rate Analysis**: Keep a close eye on error rates in the canary group. An increase in errors can be an early indicator of issues that need attention.\n",
    "\n",
    "- **User Feedback**: Gather feedback from the canary group of users to understand their experience with the new version. This feedback can help you identify issues, validate new features, and address any concerns.\n",
    "\n",
    "In Kubernetes, you can configure tools such as Prometheus and Grafana to collect and visualize metrics from your canary and production deployments. These metrics can include response times, error rates, and resource utilization. By monitoring these metrics, you can detect performance issues or anomalies early and take corrective action.\n",
    "\n",
    "Let's look at an example of employing Canary Deployments with gradual traffic splitting using Kubernetes. Here are the steps:\n",
    "\n",
    "1. Ensure that the application code is ready for the canary deployment. You should have two versions of the application: the current production version, often referred to as the baseline, and the new version, the \"canary\".\n",
    "\n",
    "2. The next step is creating a `YAML` file for the canary deployment. This file should specify the desired number of replicas for the canary version and any necessary labels. This would be like any other normal deployment `YAML`, just pointing to the canary version of your application. After creating the deployment, you will have to apply it.\n",
    "\n",
    "3. Start monitoring metrics and error rates from both the canary and production versions. You can set up Prometheus, Grafana, or other monitoring tools to collect and visualize data on response times, error rates, and resource utilization.\n",
    "\n",
    "4. Monitor the performance of the canary version and gradually adjust the traffic split based on your observations. You can do this by increasing or decreasing the number of replicas in the canary deployment `YAML`. For example, if you started with three replicas, you might increase it to six to direct more traffic to the canary. Alternatively, you can scale down the canary if issues are detected.\n",
    "\n",
    "5. Collect feedback from the subset of users who are using the canary version. Their feedback can be invaluable in identifying issues and understanding their experience with the new features or changes.\n",
    "\n",
    "6. Make data-driven decisions about whether to proceed with the canary deployment, roll back to the baseline, or make further adjustments. Use the metrics and user feedback to assess the canary version's performance and stability.\n",
    "\n",
    "7. Depending on the outcomes, you can complete the canary deployment by directing all traffic to the canary version or roll back to the baseline if issues persist. Repeat these steps iteratively until you are confident that the canary version is stable and performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B Testing Deployments\n",
    "\n",
    "> **A/B Testing Deployments** involve the simultaneous release of multiple versions or variations (A and B) of an application to different user groups. This strategy plays a vital role in software testing and allows organizations to make data-driven decisions about feature implementations, design changes, and overall user experience.\n",
    "\n",
    "A/B Testing Deployments serve several important roles in software testing and development:\n",
    "\n",
    "- **Feature Validation**: A/B tests help validate new features or changes before a full rollout. By comparing the performance and user response to both versions (A and B), organizations can determine which variant provides the best user experience and meets business goals.\n",
    "\n",
    "- **Usability Testing**: A/B tests provide insights into how users interact with different designs, user interfaces, or content. This information guides design decisions to optimize usability and enhance user engagement.\n",
    "\n",
    "- **Performance Evaluation**: Organizations use A/B testing to assess the performance of variations, such as load times, response rates, and conversion rates. This data aids in optimizing application performance.\n",
    "\n",
    "A/B testing relies on collecting and analyzing user data and feedback. This data-driven approach ensures that changes are based on actual user preferences and behaviors, rather than assumptions. Effective A/B testing deployments require strategies for collecting user feedback and metrics:\n",
    "\n",
    "- **User Surveys**: Implement surveys to collect qualitative feedback from users. Ask questions about their experience, preferences, and any issues they encountered.\n",
    "\n",
    "- **User Behavior Tracking**: Use analytics tools to track user behavior, such as page views, clicks, and conversion rates. Compare the performance of variations based on these metrics.\n",
    "\n",
    "- **Conversion Funnel Analysis**: Analyze user journeys through conversion funnels. Identify where users drop off or engage the most to pinpoint areas for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Setting Up A/B Testing in Kubernetes\n",
    "\n",
    "To set up A/B testing in Kubernetes, you can create multiple deployments, each representing a different version or variation of your application. For instance:\n",
    "\n",
    "```yaml\n",
    "# Deployment for Version A\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: my-app-version-a\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-app-version-a\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: my-app-version-a\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: my-app-container\n",
    "        image: my-app:2.0  # Version A\n",
    "\n",
    "# Deployment for Version B\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: my-app-version-b\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-app-version-b\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: my-app-version-b\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: my-app-container\n",
    "        image: my-app:2.1  # Version B\n",
    "```\n",
    "\n",
    "You can then use Kubernetes services or ingress controllers to route users to the respective versions based on criteria such as cookies, headers, or URL paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis of Development Strategies\n",
    "\n",
    "1. **Rolling Updates**\n",
    "\n",
    "    - Rolling updates are designed for minimizing downtime during updates by gradually replacing old instances with new ones\n",
    "    - Advantages: Minimal service disruption, easy to implement, suitable for stateful applications, a type of application that maintains and remembers the current state or data of a user's interaction\n",
    "    - Disadvantages: Limited rollback options for stateful applications, a type of application that does not retain any information about a user's previous interactions\n",
    "    - Ideal for application where minimal downtime is acceptable, such as content websites or small-scale services. Use cases include updating blog platforms, e-commerce websites, or news portals. <br><br>\n",
    "\n",
    "2. **Recreate Deployments**\n",
    "\n",
    "    - Recreate deployments involve creating a new set of instances while terminating the old ones\n",
    "    - Advantages: Clean slate for deployments, suitable for stateful applications, full control over the process.\n",
    "    - Disadvantages: Downtime during recreation, complex rollback procedures\n",
    "    - Suitable for stateful applications like databases or legacy systems that require precise control over the update process. Use cases include database schema changes or legacy application updates. <br><br>\n",
    "\n",
    "3. **Blue-Green Deployments**\n",
    "\n",
    "    - Blue-Green deployments maintain two separate environments (Blue and Green) for seamless updates\n",
    "    - Advantages: Zero-downtime updates, easy rollback, thorough testing in a production-like environment\n",
    "    - Disadvantages: Requires extra infrastructure and resources\n",
    "    - Highly recommended for mission-critical applications like e-commerce platforms, financial services, and healthcare systems. It ensures zero-downtime updates and easy rollbacks. <br><br>\n",
    "\n",
    "4. **Canary Deployments**\n",
    "\n",
    "    - Canary deployments release new versions to a subset of users or traffic to minimize risk\n",
    "    - Advantages: Risk mitigation, feature testing, performance validation, gradual rollout\n",
    "    - Disadvantages: Complex configuration, limited testing scope\n",
    "    - Effective for applications with a large user base, where gradual exposure to updates is essential. Social media platforms and mobile apps often use Canary Deployments to test new features. <br><br>\n",
    "\n",
    "5. **A/B Testing Deployments**\n",
    "\n",
    "    - A/B testing deployments involve simultaneous testing of multiple variations to make data-driven decisions\n",
    "    - Advantages: Data-driven decision-making, feature validation, usability testing\n",
    "    - Disadvantages: Requires significant data collection and analysis\n",
    "    - Commonly used in web applications, mobile apps, and e-commerce platforms to assess changes in user interface, content, and features. Organizations seeking data-driven decision-making opt for A/B testing.\n",
    "\n",
    "### Factors Influencing Choice of Deployment Strategy\n",
    "\n",
    "There are several factors that influence the choice of a deployment strategy, with some of the most important being:\n",
    "\n",
    "- **Application Requirements**: The nature of the application, whether it's stateless or stateful, and its specific requirements (e.g., zero downtime, rollback options) play a crucial role in selecting the appropriate strategy\n",
    "\n",
    "- **Risk Tolerance**: Organizations with low risk tolerance may opt for strategies like Canary Deployments or A/B Testing to minimize the impact of updates, while those with high risk tolerance may prefer Blue-Green Deployments for faster releases\n",
    "\n",
    "- **Infrastructure**: The existing infrastructure and resource availability can determine the feasibility of certain strategies. Blue-Green Deployments, for example, require redundant environments\n",
    "\n",
    "- **Release Frequency**: Frequent updates may benefit from Canary or A/B Testing strategies, while less frequent releases may lean towards Blue-Green Deployments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Deployment strategies are essential for managing updates, minimizing downtime, and maintaining application reliability within Kubernetes clusters\n",
    "- Kubernetes orchestrates the deployment and scaling of containerized applications within clusters of worker nodes, making deployment strategies crucial for effective application management\n",
    "- There are several deployment strategies in Kubernetes, each tailored to specific use cases:\n",
    "  - Rolling Updates: Gradually replace old instances with new ones to minimize disruptions\n",
    "  - Recreate Deployments: Create a new set of instances while terminating the old ones, offering precise control\n",
    "  - Blue-Green Deployments: Maintain separate environments for current and new versions, allowing zero-downtime updates and easy rollbacks\n",
    "  - Canary Deployments: Gradually release new versions to a subset of users or traffic to minimize risk\n",
    "  - A/B Testing Deployments: Simultaneously test multiple variations to make data-driven decisions\n",
    "- The choice of deployment strategy depends on factors like application requirements, risk tolerance, infrastructure, and release frequency\n",
    "- Each deployment strategy has its ideal use cases. Consider:\n",
    "  - Rolling Updates for small-scale services\n",
    "  - Recreate Deployments for stateful applications and databases\n",
    "  - Blue-Green Deployments for mission-critical applications\n",
    "  - Canary Deployments for large user bases\n",
    "  - A/B Testing Deployments for data-driven decision-making\n",
    "- Metrics, observability, and user feedback are crucial for monitoring and ensuring the success of deployment strategies"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
