{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Recovery in Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disaster recovery* is a critical aspect of any organization's data strategy. It refers to the set of processes and tools implemented to safeguard data, applications, and systems, enabling rapid recovery and continuity of operations in the face of disruptive events. By having a robust disaster recovery plan, businesses can minimize downtime, ensure data integrity, and maintain their ability to serve customers without significant interruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Disasters can strike unexpectedly, causing data loss, system downtime, and business interruptions. In today's technology-driven world, organizations heavily rely on data and applications to function efficiently and serve customers. The consequences of such incidents can be catastrophic, leading to financial losses, damage to reputation, and a loss of customer trust.\n",
    "\n",
    "Disaster recovery is essential for business continuity and mitigating the impact of unforeseen events. By having a robust disaster recovery plan, organizations can:\n",
    "\n",
    "- **Minimize Downtime**: Rapidly restore critical systems to reduce downtime and maintain operations\n",
    "\n",
    "- **Protect Data**: Implement backup and replication mechanisms to safeguard valuable data\n",
    "\n",
    "- **Ensure Compliance**: Adhere to regulatory requirements for data protection and business continuity\n",
    "\n",
    "- **Safeguard Reputation**: Maintain high availability to retain customer confidence and loyalty\n",
    "\n",
    "- **Adapt to Threats**: Mitigate the impact of cyber attacks and secure critical systems and information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure's Disaster Recovery Capabilities\n",
    "\n",
    "Microsoft's cloud computing platform, Azure, offers a wide range of disaster recovery capabilities designed to protect data, applications, and services running on the platform. Some key features include:\n",
    "\n",
    "- **Azure Backup**: Azure Backup allows you to regularly back up your Azure SQL Databases, virtual machines, and other resources. It provides an automated and scalable solution for data protection.\n",
    "\n",
    "- **Geo-Replication for Azure SQL Database**: Geo-replication enables you to asynchronously replicate your Azure SQL Database to a secondary region, providing data redundancy and disaster recovery options\n",
    "\n",
    "- **Azure Site Recovery**: Azure Site Recovery (ASR) is a comprehensive disaster recovery solution that replicates and orchestrates the failover of on-premises and virtual machine workloads to Azure or between Azure regions\n",
    "\n",
    "- **Azure Virtual Machine Scale Sets**: Virtual Machine Scale Sets allow you to deploy and manage a group of identical, load-balanced VMs to ensure high availability and automatic scaling\n",
    "\n",
    "> In this lesson we will focus on different disaster recovery scenarios for Azure SQL Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Backups in Azure SQL Database\n",
    "\n",
    "In Azure SQL Database, various backup options are available to meet different data protection needs. Understanding these backup types allows you to make informed decisions about which approach best suits your organization's requirements. Let's explore the three primary types of backups in Azure SQL Database:\n",
    "\n",
    "### 1. Automated Backups\n",
    "\n",
    "*Automated backups* are managed by Azure SQL Database and are enabled by default for all databases. These backups are taken regularly. The frequency of automated backups depends on the service tier of your database:\n",
    "\n",
    "- For the Basic and Standard service tiers, automated backups are taken every week\n",
    "- For the Premium and Business Critical service tiers, automated backups are taken every five minutes.\n",
    "\n",
    "#### Advantages of Automated Backups\n",
    "\n",
    "- Simple and hassle-free setup, as Azure SQL Database handles the backup process\n",
    "- Regular and frequent backups ensure minimal data loss in case of a disaster\n",
    "- No additional cost for automated backups, as they are included in the service tier pricing\n",
    "\n",
    "#### Limitations of Automated Backups\n",
    "\n",
    "- Limited retention period: Basic and Standard service tiers retain automated backups for up to 7 days, while Premium and Business Critical retain backups for up to 35 days\n",
    "- Lack of flexibility in scheduling: You cannot customize the timing or frequency of automated backups\n",
    "\n",
    "### 2. Manual Backups\n",
    "\n",
    "In contrast to automated backups, *manual backups* provide more control over the backup process. With manual backups, you initiate the backup operations and choose when and where to store the backup files. This approach is particularly useful when you need to perform on-demand backups at specific intervals.\n",
    "\n",
    "#### Advantages of Manual Backups\n",
    "\n",
    "- Customizable backup schedule: You can decide when to take backups based on your organization's needs\n",
    "- Longer retention periods: You can retain manual backups for an extended duration, depending on your storage capacity\n",
    "- Flexibility in storage location: Manual backups can be stored in Azure Blob Storage or locally\n",
    "\n",
    "####  Limitations of Manual Backups\n",
    "\n",
    "- Manual setup and management: The responsibility for initiating and managing backups lies with the user\n",
    "- Potential data loss risk: If you forget to schedule or perform backups regularly, there is a higher risk of data loss in case of a disaster\n",
    "\n",
    "### 3. Long-Term Retention Backups\n",
    "\n",
    "Long-term retention backups allow you to keep historical backups for an extended period, beyond the standard retention period provided by automated backups. This feature is useful for compliance requirements or when you need to retain backups for a more extended duration.\n",
    "\n",
    "#### Advantages of Long-Term Retention Backups\n",
    "\n",
    "- Compliance support: Long-term retention helps organizations meet regulatory, and compliance requirements\n",
    "- Extended backup history: You can keep backups for up to 10 years, depending on the storage capacity\n",
    "\n",
    "#### Limitations of Long-Term Retention Backups\n",
    "\n",
    "- Additional cost: Long-term retention backups incur additional storage costs\n",
    "- Limited to specific service tiers: Long-term retention is available only for the Premium and Business Critical service tiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimicking Data Loss in a Production Environment\n",
    "\n",
    "Disaster recovery procedures are crucial for ensuring business continuity and data protection in the event of unforeseen incidents. However, relying solely on theoretical plans without testing them in a controlled environment can be risky. Testing disaster recovery procedures allows organizations to:\n",
    "\n",
    "- Validate recovery strategies and identify weaknesses\n",
    "- Build confidence in the effectiveness of the plan\n",
    "- Reduce downtime by practicing efficient recovery\n",
    "- Identify gaps and continuously improve the process\n",
    "- Comply with regulations and industry standards\n",
    "\n",
    "### Methods to Mimic Data Loss in Azure SQL Database\n",
    "\n",
    "Azure SQL Database provides various methods to mimic data loss scenarios in a controlled environment. Here are some common techniques:\n",
    "\n",
    "- **Intentional Deletion of Data**: You can simulate data loss by intentionally deleting critical data from the database. This could be individual records, entire tables, or specific data ranges.\n",
    "\n",
    "- **Data Corruption**: Introduce data corruption into the database by modifying specific records or fields, either directly in the database or through application transactions\n",
    "\n",
    "- **Accidental Updates**: Introduce erroneous updates to the data, either through direct manipulation or by running faulty scripts\n",
    "\n",
    "- **Service Outages**: Simulate service outages or connectivity issues to the database to test failover and disaster recovery readiness\n",
    "\n",
    "- **Simulated Regional Outages**: If you have implemented georeplication, simulate regional outages in the primary region to trigger the failover to the secondary region. We will discuss more about this scenario in a later section.\n",
    "\n",
    "### Precautions When Mimicking Data Loss\n",
    "\n",
    "When mimicking data loss scenarios, exercise caution to avoid unintended consequences. Follow these precautions:\n",
    "\n",
    "- **Use Non-Production Environments**: Perform data loss testing in non-production environments to prevent any impact on live data and operations\n",
    "\n",
    "- **Backup the Database**: Take a backup of the database before initiating any data loss scenarios, ensuring you can revert to a known good state if needed\n",
    "\n",
    "- **Involve Stakeholders**: Inform relevant stakeholders about the testing process to avoid misunderstandings and maintain transparency\n",
    "\n",
    "- **Document the Process**: Record the steps followed and the outcomes during testing for documentation and analysis\n",
    "\n",
    "By mimicking data loss in a controlled environment and testing disaster recovery procedures regularly, organizations can ensure that they are well-prepared to handle real-life incidents and minimize the impact on critical business operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-On: Mimicking Data Loss in a Production Azure SQL Database\n",
    "\n",
    "Before continuing with this hands-on, first make sure you have followed the necessary hands-on from the previous lessons in this pathway. If you had, you should have a production Windows VM which was Azure Data Studio installed. This should have a connection establish to a production Azure SQL Database, which hosts the `sales_database`.\n",
    "\n",
    "To mimic data loss in the `sales_database` Azure SQL Database follow these steps:\n",
    "\n",
    "- Open Azure Data Studio on the production VM and identify previously created connection to the Azure SQL Database\n",
    "\n",
    "- Open a query window by right-clicking on the production database and selecting **New Query**. Let's examine the data before proceeding with the mimicking data loss. For example, let's select all the entries in the `dbo.dim_users` table. Once you wrote the query just press **Run** to execute it.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/FirstQuery.png\" height=\"600\" width=\"1000\"/>\n",
    "</p>\n",
    "\n",
    "- Scroll all the way down in the **Results** pane to observe the number of entries in the table. In this example I can see there are 1000 entries in the `dbo.dim_users` table.\n",
    "\n",
    "- Write and execute SQL queries to intentionally delete or corrupt specific data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Intentional Deletion\n",
    "DELETE TOP (100)\n",
    "FROM dbo.dim_products;\n",
    "\n",
    "-- Data Corruption\n",
    "UPDATE TOP (100) dbo.dim_products\n",
    "SET product_price = NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verify the data loss by querying the affected table to ensure that the data has been intentionally deleted or corrupted. For example if you used the query that deletes the first 100 rows in the `dbo.dim_products` table, you should only see 900 entries in the table now.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/CorruptedData.png\" height=\"600\" width=\"1000\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Restoring a Database from an Azure SQL Database Backup\n",
    "\n",
    "In this section we will provide step-by-step instructions on how to restore a database from a backup after experiencing data loss. Follow these instructions to restore a database from an Azure SQL Database backup. For this example, we will use our recently corrupted `sales_database` Azure SQL Database:\n",
    "\n",
    "- Navigate to the Azure portal and from the Azure SQL Database dashboard, locate and select the target database that needs restoration\n",
    "\n",
    "- From the SQL Database Home Page select the **Restore** option at the top bar on the page\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/RestoreOption.png\" height=\"450\" width=\"950\"/>\n",
    "</p>\n",
    "\n",
    "- This will open a **Restore database** window. Here you will first need to select the **Restore point**. Choose the restore point that represents the point in time before the data loss occurred. For example, I will select a restore point on the same day two hours before the data loss has occurred. This is because I know no data has been added to the database since then, however if this is an active database that gets updated real-time you would have to choose the closest point in time before data loss has occurred for minimal data loss.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/RestorePoint.png\" height=\"450\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "- Next, I will choose the new **Database name**, which in this example will be the same as the production database name with `-restored` added to it. After that you are ready to restore your production database so just click **Review + create** and finally click **Create**. Azure will begin restoring the selected backup to the specified destination. This will take a couple of minutes to complete.\n",
    "\n",
    "- Once the new database has been deployment we will be able to see it under the resource list in Azure SQL Database page. To verify the database has been restored to a correct point in time, before the data loss has occurred, we will establish a connection to it using Azure Data Studio.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/RestoredDatabase.png\" height=\"500\" width=\"1000\"/>\n",
    "</p>\n",
    "\n",
    "And we can see that our restored database now has the correct number of entries (1000) for the `dbo.dim_products` table, indicating that our point in time restoration worked as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo-Replication in Azure SQL Database\n",
    "\n",
    "*Geo-Replication* is a disaster recovery feature in Azure SQL Database that provides data redundancy and high availability by asynchronously replicating your primary database to a secondary region. This secondary region is often in a different geographic location, ensuring data durability in case of a regional outage or disaster.\n",
    "\n",
    "### How Geo-Replication Works in Azure SQL Database\n",
    "\n",
    "- **Primary Database**: The primary database is the original database that serves your application and handles read and write operations\n",
    "\n",
    "- **Secondary Database**: The secondary database is a read-only copy of the primary database located in a different Azure region. It is synchronized asynchronously with the primary database to minimize any performance impact on the primary.\n",
    "\n",
    "- **Data Replication**: As data changes occur in the primary database, these changes are asynchronously replicated to the secondary database through Azure's reliable infrastructure\n",
    "\n",
    "- **Automatic Failover**: In the event of a regional outage or planned maintenance, you can manually initiate a failover or rely on Azure's automatic failover mechanism, which promotes the secondary database to the primary role to minimize downtime\n",
    "\n",
    "### Configuring and Setting up Geo-Replication\n",
    "\n",
    "Follow these steps to configure and set up georeplication for your Azure SQL Database:\n",
    "\n",
    "- Navigate to the Azure portal and from the Azure SQL Database dashboard, select the primary database you want to replicate. We will use the previously restored production database here. \n",
    "\n",
    "- In the left-hand menu of the primary database blade, click on **Replicas** under **Data Management**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ReplicationBlade.png\" height=\"600\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "- Click on **Create replica** to begin the setup process. In the **Geo Replica** menu we will first have to create a new SQL Server using the **Create new** button under the **Server** pane. This server will should be located in a region geographically distant from the primary region to ensure data redundancy. This will represent the secondary region where the database will be replicated.\n",
    "\n",
    "- In this example, we are creating a new server called `my-replication-server` that is located in **(US) East US**. We will select **Use SQL authentication** as the authentication method and provision the SQL log in credentials for this server.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ReplicationServer.png\" height=\"600\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "- Press **OK** to create the new SQL Server. This will redirect us back to the **Geo Replica** window where now we should have the new server details under the **Server** field in the **Database details** pane.\n",
    "\n",
    "- Click **Review + create** and then click on **Create** to initiate the replication process. Azure will start the initial data synchronization between the primary and secondary databases. This might take a couple of minutes to complete.\n",
    "\n",
    "Once the resource has been provisioned to go the resource page, and you should be able to see the following information:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/GeoReplicaDatabase.png\" height=\"350\" width=\"650\"/>\n",
    "</p>\n",
    "\n",
    "Indicating that this database is a replica (as we can see under the **Replica type** field) with the primary database being `production-database-restored`. Congratulations you have successfully created a georeplica of your primary database!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Failover and Tailback\n",
    "\n",
    "> *Failover* is the process of switching the workload from the primary region to the secondary region in a georeplicated environment\n",
    "\n",
    "It is typically performed during planned maintenance or in response to a disaster in the primary region. Failover ensures high availability and business continuity by allowing applications to continue running from the secondary region.\n",
    "\n",
    "> *Tailback* is the process of reverting the workload back to the primary region after a successful failover. \n",
    "\n",
    "Once the primary region is restored, the workload is switched back from the secondary region to the primary region, ensuring that the original production environment is reinstated.\n",
    "\n",
    "### Initiating a Test Failover to the Secondary Region\n",
    "\n",
    "A test failover is a non-disruptive way to verify the functionality of the failover environment without impacting the production workload. Follow these steps to initiate a test failover to the secondary region:\n",
    "\n",
    "- Navigate to the Azure portal and from the Azure SQL Database dashboard, select the SQL server associated with the primary database that you want to failover (in the example above that will be our primary database `production-database-restored` that is located in the UK region, not the US one which is the georeplica)\n",
    "\n",
    "- Select **Failover groups** under the **Data management** pane, and then select **Add group** to create a new failover group\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/AddFailoverGroup.png\" height=\"550\" width=\"1000\"/>\n",
    "</p>\n",
    "\n",
    "- On the **Failover group** page enter a name for the failover group. Then for the **Server** select your secondary server, not the server on which the primary database resides in. For example this could be the replication server created earlier. Leave the rest of the settings as default and click **Create**.\n",
    "\n",
    "- Now navigate to the Azure SQL Server in which your secondary/replication database resides in. In this example that will be `my-replication-server`.\n",
    "\n",
    "- Here under **Failover groups** you should see the newly created failover group\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/FailoverGroup.png\" height=\"350\" width=\"950\"/>\n",
    "</p>\n",
    "\n",
    "- Access the failover group page, you should be able to see the following page, which indicates the two servers in the failover group and which is the primary and the secondary one:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/BeforeFailover.png\" height=\"450\" width=\"950\"/>\n",
    "</p>\n",
    "\n",
    "- To initiate a planned failover (without data loss), select **Failover** from the task pane to fail over your failover group containing your database. You will likely receive a warning about switching the secondary database to a primary role click **Yes** to continue here.\n",
    "\n",
    "- Wait for the failover to complete and review which server is now primary and which server is secondary. If failover succeeded, the two servers should have swapped roles. Here, you can also use the connection details of the secondary server to connect to the new primary database, and run tests to validate the database's functionality in the secondary region, ensuring that it is working as expected.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/AfterFailover.png\" height=\"500\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "- Select **Failover** again to fail the servers back to their original roles\n",
    "\n",
    "By following these steps, you can safely perform a test failover to verify your disaster recovery environment's functionality and then perform a tailback to revert to the primary region. Testing these processes regularly ensures the readiness of your disaster recovery plan and boosts confidence in your organization's ability to handle unexpected incidents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing a Planned Failover to a Secondary Region\n",
    "\n",
    "A *planned failover* is typically executed when you need to perform maintenance or planned downtime in the primary region. It allows you to proactively move your workload to the secondary region, ensuring minimal disruption to your applications and users during the maintenance window. Some common circumstances requiring a planned failover include:\n",
    "\n",
    "- **Planned Maintenance**: When you need to apply updates, patches, or configuration changes to the primary region's infrastructure or services\n",
    "\n",
    "- **Disaster Recovery Drills**: To validate the effectiveness of your disaster recovery strategy and ensure the secondary region can effectively handle the workload\n",
    "\n",
    "- **Geographic Load Balancing**: For load balancing purposes, you might decide to temporarily move the workload to the secondary region to distribute traffic evenly\n",
    "\n",
    "Performing a planned failover requires careful planning and consideration to minimize any impact on applications and users. Here are some important considerations:\n",
    "\n",
    "- **Downtime Window**: Plan the failover during a scheduled maintenance window or during periods of low user activity to minimize disruptions\n",
    "\n",
    "- **Application Awareness**: Ensure that your applications are designed to handle failover scenarios, and any necessary configuration changes are made to point to the secondary region after the planned failover\n",
    "\n",
    "- **Data Synchronization**: Depending on the data replication lag, there may be some data loss during the failover. Make sure you understand the replication lag and potential data loss implications.\n",
    "\n",
    "- **Read-Only Access**: The secondary region, after the planned failover, will be in a read-write state. Adjust application behavior accordingly to avoid unintended write operations.\n",
    "\n",
    "- **Reverse Failover Plan**: Plan for a reverse failover (tailback) to bring the workload back to the primary region after the maintenance is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Disaster recovery is essential for business continuity, and Azure offers various capabilities to ensure high availability and data protection\n",
    "- Azure SQL Database provides automated, manual, and long-term retention backups to cater to different data protection needs\n",
    "- Testing disaster recovery procedures in a controlled environment allows you to prepare for real data loss scenarios, such as intentional deletions or data corruption\n",
    "- Setting up georeplication in Azure SQL Database ensures data redundancy and high availability by replicating the primary database to a secondary region\n",
    "- Performing test failovers and tailbacks helps validate the effectiveness of disaster recovery strategies and ensures a smooth transition between regions\n",
    "- A planned failover is performed during maintenance or planned downtime and allows you to proactively move the workload to the secondary region"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
