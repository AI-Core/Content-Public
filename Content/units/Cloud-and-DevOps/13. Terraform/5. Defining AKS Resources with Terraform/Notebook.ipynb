{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining AKS Resources with Terraform\n",
    "\n",
    "In this lesson, we'll look in more detail at Azure Kubernetes Service (AKS) and Terraform, focusing on how to combine these powerful technologies to efficiently manage and orchestrate Kubernetes clusters on Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Development Environment\n",
    "\n",
    "Before we start defining Azure Kubernetes Service (AKS) resources with Terraform, we need to ensure that your development environment is properly configured.\n",
    "\n",
    "To create a robust and fully functional AKS cluster, we need to consider various components that make up the infrastructure. These components include:\n",
    "\n",
    "- **Virtual Network (VNet)**: The networking foundation for your AKS cluster, which includes subnets for worker nodes, control plane nodes, and any additional network resources\n",
    "- **Subnets**: Specific network segments within the VNet, including those for worker nodes and control plane nodes\n",
    "- **Network Security Groups (NSGs)**: Security rules to control inbound and outbound traffic to resources in the subnets\n",
    "\n",
    "These components are essential for configuring the network infrastructure to support the AKS cluster. Thus, this Terraform project will not only need to contain a module for defining the AKS cluster resource itself, but an additional networking module that will focus on creating the VNet, subnets, and NSGs required for your AKS environment.\n",
    "\n",
    "Start by creating a dedicated directory for your Terraform project. This directory will contain all your Terraform configuration files.\n",
    "\n",
    "```shell\n",
    "mkdir aks-terraform\n",
    "cd aks-terraform\n",
    "```\n",
    "\n",
    "Inside this directory, create two subdirectories: `networking-module` and `aks-cluster-module` to represent the networking services and the AKS cluster configuration, respectively.\n",
    "\n",
    "```shell\n",
    "mkdir networking-module\n",
    "mkdir aks-cluster-module\n",
    "```\n",
    "\n",
    "By creating these directories, we are preparing to organize our Terraform modules in a structured manner. Now let's move on to the next sections, where we will define the necessary modules in detail and incorporate them into the main Terraform configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networking Services Module Configuration\n",
    "\n",
    "> For the networking setup, please refer to the configuration details from the previous lesson, as we will reuse the module setup in the `networking-module` directory of this project. However, there are some key differences in this setup compared to the previous example:\n",
    "\n",
    "- For the AKS setup, you need to create two separate subnets, rather than a single one (by creating two different `azurerm_subnet` blocks):\n",
    "    - Control Plane Subnet: Dedicated to the Kubernetes control plane nodes\n",
    "    - Worker Nodes Subnet: Dedicated to the Kubernetes worker nodes\n",
    "- The AKS setup requires specific NSG rules tailored to the needs of the Kubernetes cluster. The earlier setup included NSG rules for HTTP, HTTPS and a range of node ports. For AKS setup you will need to define the following:\n",
    "    - `kube-apiserver` Port (TCP/443): Allows secure communication with the Kubernetes API server, which is essential for managing the cluster\n",
    "    - SSH Port (TCP/22) (Optional): This rule allows SSH access to the nodes if you need to perform administrative tasks or troubleshooting. It is optional and should only be added if necessary for your use case.\n",
    "\n",
    "In summary, the key differences are the addition of multiple subnets for better segregation of control plane and worker nodes, and the introduction of specific NSG rules that cater to the operational requirements of the AKS cluster, as opposed to more general network access rules.\n",
    "\n",
    "The NSG rules should look like this:\n",
    "\n",
    "```hcl\n",
    "# Allow inbound traffic to kube-apiserver (TCP/443) from your public IP address\n",
    "resource \"azurerm_network_security_rule\" \"kube_apiserver\" {\n",
    "  name                        = \"\"<your_nsg_rule1_name>\"\n",
    "  priority                    = 1001\n",
    "  direction                   = \"Inbound\"\n",
    "  access                      = \"Allow\"\n",
    "  protocol                    = \"Tcp\"\n",
    "  source_port_range           = \"*\"\n",
    "  destination_port_range      = \"443\"\n",
    "  source_address_prefix       = \"*\"  \n",
    "  destination_address_prefix  = \"*\"\n",
    "  resource_group_name         = azurerm_resource_group.networking.name\n",
    "  network_security_group_name = azurerm_network_security_group.aks_nsg.name\n",
    "}\n",
    "\n",
    "# Allow inbound traffic for SSH (TCP/22) - Optional\n",
    "resource \"azurerm_network_security_rule\" \"ssh\" {\n",
    "  name                        = \"<your_nsg_rule2_name>\"\n",
    "  priority                    = 1002\n",
    "  direction                   = \"Inbound\"\n",
    "  access                      = \"Allow\"\n",
    "  protocol                    = \"Tcp\"\n",
    "  source_port_range           = \"*\"\n",
    "  destination_port_range      = \"22\"\n",
    "  source_address_prefix       = \"*\"  \n",
    "  destination_address_prefix  = \"*\"\n",
    "  resource_group_name         = azurerm_resource_group.networking.name\n",
    "  network_security_group_name = azurerm_network_security_group.aks_nsg.name\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Additionally, we will define a `outputs.tf` file for our new networking module, allowing us to make available the ouputs of this module to the AKS cluster module.\n",
    "\n",
    "Here's an example of how you can define output variables:\n",
    "\n",
    "```hcl\n",
    "# networking-module/outputs.tf\n",
    "\n",
    "output \"vnet_id\" {\n",
    "  description = \"ID of the Virtual Network (VNet).\"\n",
    "  value       = <vnet-resource-type>.<vnet-resource-identifier>.id\n",
    "}\n",
    "\n",
    "output \"control_plane_subnet_id\" {\n",
    "  description = \"ID of the control plane subnet.\"\n",
    "  value       = <subnet-resource-type>.<control-plane-subnet-identifier>.id\n",
    "}\n",
    "\n",
    "output \"worker_node_subnet_id\" {\n",
    "  description = \"ID of the worker node subnet.\"\n",
    "  value       = <subnet-resource-type>.<worker-node-subnet-identifier>.id\n",
    "}\n",
    "\n",
    "# Define more output variables as needed...\n",
    "```\n",
    "\n",
    "> Within the `value` argument of each `output` block you will have to replace the `<resource-type>` and `<resource-identifier>` with the correct resource type and identifier for each resource. You can find these values in the previously created `main.tf` where you provisioned your resources.\n",
    "\n",
    "Let's look at an example, for the VNet resource:\n",
    "\n",
    "```hcl\n",
    "# Define the Virtual Network (VNet) for the AKS cluster\n",
    "resource \"azurerm_virtual_network\" \"aks_vnet\" {\n",
    "  name                = \"<your_vnet_name>\"\n",
    "  address_space       = var.vnet_address_space\n",
    "  location            = azurerm_resource_group.networking.location\n",
    "  resource_group_name = azurerm_resource_group.networking.name\n",
    "}\n",
    "```\n",
    "\n",
    "The `output` block should look like this:\n",
    "\n",
    "```hcl\n",
    "output \"vnet_id\" {\n",
    "  description = \"ID of the Virtual Network (VNet).\"\n",
    "  value       = azurerm_virtual_network.aks_vnet.id\n",
    "}\n",
    "```\n",
    "In this case `<resource-type>` corresponds to `azurerm_virtual_network` and `<resource-identifier>` corresponds to `aks_vnet` as we can see from the VNet `resource` block.\n",
    "\n",
    "The `vnet_id` output variable provides the ID of the VNet created by the networking module. This output variable can then be used in the AKS cluster module to specify the VNet in which the AKS cluster should be created. \n",
    "\n",
    "The `control_plane_subnet_id` output variables provides the ID of the control plane subnet within the VNet. The control plane subnet is where the control plane components of the AKS cluster, such as the `kube-apiserver`, are deployed. You can use this output variable to configure the AKS cluster to use the specified subnet for its control plane. \n",
    "\n",
    "The `worker_node_subnet_id` output variables provides the ID of the worker node subnet within the VNet. The worker node subnet is where the AKS cluster's worker nodes are deployed. You can use this output variable to configure the AKS cluster to use the specified subnets for its worker nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "Run `terraform init` to set up the Terraform workspace and download the necessary provider plugins and modules. \n",
    "\n",
    "We will proceed with defining the AKS cluster module's configuration in the next section, and then we will apply both modules together, from the main project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AKS Cluster Module Resources\n",
    "\n",
    "In this section, we will define the Terraform configuration for creating an AKS cluster. Before we start defining the AKS cluster configuration, navigate to the module directory for your AKS resources `aks-cluster-module`. \n",
    "\n",
    "Inside the AKS module directory, create the following files:\n",
    "\n",
    "- `variables.tf`: This file will define the input variables that allow customization of the AKS cluster\n",
    "- `terraform.tfvars`: In this file, you will manage sensitive information such as credentials\n",
    "- `outputs.tf`: In this file, you can specify any output values that you want to retrieve after provisioning the AKS cluster\n",
    "- `main.tf`: The main configuration file where we will define the actual AKS cluster resources\n",
    "\n",
    "### Define Input Variables (`variables.tf`) \n",
    "\n",
    "To create a flexible and customizable AKS cluster configuration, we will define input variables that can be customized when using this module. Here are the input variables for this module:\n",
    "\n",
    "```hcl\n",
    "# aks-cluster/variables.tf\n",
    "\n",
    "variable \"aks_cluster_name\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"location\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"service_principal_client_id\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"service_principal_client_secret\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "# Input variables from the networking module\n",
    "variable \"resource_group_name\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"vnet_id\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "...\n",
    "```\n",
    "> Inside the `variables.tf` file of this module, you should make sure to include all the output variables from the networking module. As an example `resource_group_name` and `vnet_id` have already been included. Make sure to add the rest of them including `control_plane_subnet_id`, `worker_node_subnet_id` and `aks_nsg_id`.\n",
    "\n",
    "Here's an explanation of the new input variables defined in the AKS cluster module configuration. Later, you will use the output values from networking module as input variables in the AKS cluster module. This allows you to pass data and share information between modules in a structured and controlled manner.\n",
    "\n",
    "- The `aks_cluster_name` variable specifies the name of the AKS cluster that will be created\n",
    "- The `location` defines the Azure region where the AKS cluster will be created\n",
    "- The `service_principal_client_id` is the Client ID of the service principal used for authenticating and managing the AKS cluster\n",
    "- The `service_principal_client_secret` specifies the Client Secret associated with the service principal used for AKS cluster authentication\n",
    "\n",
    "We will use these input variables to configure and create the AKS cluster resources in the `main.tf` file.\n",
    "\n",
    "> IMPORTANT: When working with the AiCore-generated Azure credentials for the specialisation project, you will use a *Managed Identity* instead of a Service Principal to create the AKS cluster. Managed Identity is a feature that provides an identity for Azure services to use when connecting to resources that support Entra ID authentication. Unlike a Service Principal, which required explicit management of credentials, a Managed Identity is automatically managed by Azure and eliminates the need for storing secrets.\n",
    "\n",
    "This means for the project, you will need to replace the `service_principal_client_id` and `service_principal_client_secret` variables with a `managed_identity_id` variable. Here's how you would adjust the `variables.tf`:\n",
    "\n",
    "```hcl\n",
    "variable \"managed_identity_id\" {\n",
    "  description = \"The Managed Identity ID used for the AKS cluster.\"\n",
    "  type        = string\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Configuration Values (`terraform.tfvars`)\n",
    "\n",
    "To provide the sensitive values for the input variables defined in `variables.tf`, you will use a `terraform.tfvars` file. This file allows you to specify concrete values for variables that Terraform will use during planning and application of your configuration.\n",
    "\n",
    "In this example, where you are using a Service Principal for authentication, the `terraform.tfvars` might look like this:\n",
    "\n",
    "```hcl\n",
    "service_principal_client_id = \"your-service-principal-client-id\"\n",
    "service_principal_client_secret = \"your-service-principal-client-secret\"\n",
    "```\n",
    "\n",
    "> For the specialisation project, when you will be using a Managed Identity instead, the `terraform.tfvars` will look slight different:\n",
    "\n",
    "```hcl\n",
    "managed_identity_id = \"your-managed-identity-id\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AKS Cluster Module\n",
    "\n",
    "In the `main.tf`, you can now define the configuration for the AKS cluster module.\n",
    "\n",
    "```hcl\n",
    "# aks-cluster/main.tf\n",
    "# Create the AKS cluster\n",
    "resource \"azurerm_kubernetes_cluster\" \"aks_cluster\" {\n",
    "  name                = var.aks_cluster_name\n",
    "  location            = var.cluster_location\n",
    "  resource_group_name = var.resource_group_name\n",
    "  dns_prefix          = \"example\"\n",
    "\n",
    "  default_node_pool {\n",
    "    name       = \"default\"\n",
    "    node_count = 1\n",
    "    vm_size    = \"Standard_DS2_v2\"\n",
    "    enable_auto_scaling = true\n",
    "    min_count = 1\n",
    "    max_count = 2\n",
    "  }\n",
    "\n",
    "  service_principal {\n",
    "    client_id     = var.service_principal_client_id\n",
    "    client_secret = var.service_principal_client_secret\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "Let's break down the configuration block for creating the AKS cluster:\n",
    "\n",
    "```# Create the AKS cluster\n",
    "resource \"azurerm_kubernetes_cluster\" \"aks_cluster\" {\n",
    "  name                = var.aks_cluster_name\n",
    "  location            = var.cluster_location\n",
    "  resource_group_name = var.resource_group_name\n",
    "```\n",
    "\n",
    "This block specifies the information we already explained in detail when defining the `variables.tf` for this module.\n",
    "\n",
    "```hcl\n",
    "  default_node_pool {\n",
    "    name       = \"default\"\n",
    "    node_count = 1\n",
    "    vm_size    = \"Standard_DS2_v2\"\n",
    "    enable_auto_scaling = true\n",
    "    min_count = 1\n",
    "    max_count = 2\n",
    "  }\n",
    "```\n",
    "\n",
    "The `default_node_pool` block defines the default node pool for the cluster:\n",
    "\n",
    "- `name`: Specifies the name of the default node pool, which is `default` in this case\n",
    "- `node_count`: Sets the initial number of nodes in the node pool to 1\n",
    "- `vm_size`: Specifies the virtual machine size for the nodes in the pool, which is `Standard_DS2_v2` in this example\n",
    "- `enable_auto_scaling`: Enables auto-scaling for the node pool\n",
    "- `min_count`: Sets the minimum number of nodes to 1\n",
    "- `max_count`: Sets the maximum number of nodes to 2\n",
    "\n",
    "```hcl\n",
    "  service_principal {\n",
    "    client_id     = var.service_principal_client_id\n",
    "    client_secret = var.service_principal_client_secret\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Finally, the `service_principal` blocks provides the authentication details for the AKS cluster. These are the same credentials you use when defining an Azure provider in your configuration. You should have access to this if you have provisioned a Service Principal in the previous lessons.\n",
    "\n",
    "> For the specialisation project you will need to replace the `service_principal` block with an `identity` block in your `main.tf` file:\n",
    "\n",
    "```hcl\n",
    "  identity {\n",
    "      type = \"UserAssigned\"\n",
    "      identity_ids = [\n",
    "        var.managed_identity_id\n",
    "      ]\n",
    "    }\n",
    "```\n",
    "\n",
    "The `identity` block is used to configure Managed Identity for the AKS cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Variables (`outputs.tf`) \n",
    "\n",
    "In the `outputs.tf` define the output variables for the AKS cluster module:\n",
    "\n",
    "```hcl\n",
    "output \"aks_cluster_name\" {\n",
    "  description = \"Name of the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.name\n",
    "}\n",
    "\n",
    "output \"aks_cluster_id\" {\n",
    "  description = \"ID of the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.id\n",
    "}\n",
    "\n",
    "output \"aks_kubeconfig\" {\n",
    "  description = \"Kubeconfig file for accessing the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.kube_config_raw\n",
    "}\n",
    "```\n",
    "> Within the `value` argument of each `output` block you will have to replace the `<resource-type>` and `<resource-identifier>` with the correct resource type and identifier for each resource. You can find these values in the previously created `main.tf` where you provisioned your resources.\n",
    "\n",
    "These output variables provide information about the AKS cluster, including its name, ID, and the `kubeconfig` file for accessing the cluster using `kubectl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "Run `terraform init` to set up the Terraform workspace and download the necessary provider plugins and modules. \n",
    "\n",
    "In the next section we will apply both modules together, from the main project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Main Configuration\n",
    "\n",
    "In this section, we will define the main configuration for your project, which will utilize the networking module and the AKS cluster module to provision the necessary Azure resources.\n",
    "\n",
    "Begin by navigating to the project directory `aks-terraform`. Here we will begin defining your project's main configuration file, `main.tf`, by defining the Azure provider block for authentication. This block should be included at the beginning of the configuration file. \n",
    "\n",
    "```hcl\n",
    "terraform {\n",
    "  required_providers {\n",
    "    azurerm = {\n",
    "      source  = \"hashicorp/azurerm\"\n",
    "      version = \"=3.95.0\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "provider \"azurerm\" {\n",
    "  features {}\n",
    "  skip_provider_registration = true\n",
    "  client_id       = var.client_id\n",
    "  client_secret   = var.client_secret\n",
    "  subscription_id = \"your-subscription-id\"\n",
    "  tenant_id       = \"your-tenant-id\"\n",
    "}\n",
    "```\n",
    "This provider block specifies that you will be using Azure as your cloud provider. It uses variables for the `client_id` and `client_secret`, which we will store in environment variables to avoid hardcoding them. First we need to add them to the main configuration's `variables.tf` as follows:\n",
    "\n",
    "```hcl\n",
    "#variables.tf\n",
    "\n",
    "variable \"client_id\" {\n",
    "  description = \"Access key for the provider\"\n",
    "  type        = string\n",
    "  sensitive   = true\n",
    "}\n",
    "\n",
    "variable \"client_secret\" {\n",
    "  description = \"Secret key for the provider\"\n",
    "  type        = string\n",
    "  sensitive   = true\n",
    "}\n",
    "\n",
    "variable \"subscription_id\" {\n",
    "  description = \"Azure subscription ID\"\n",
    "  type        = string\n",
    "}\n",
    "\n",
    "variable \"tenant_id\" {\n",
    "  description = \"Azure tenant ID\"\n",
    "  type        = string\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Create a `terraform.tfvars` file in the main project directory to securely store the values for these variables:\n",
    "\n",
    "```hcl\n",
    "# terraform.tfvars\n",
    "\n",
    "client_id       = \"<your-client-id-here>\"\n",
    "client_secret   = \"<your-client-secret-here>\"\n",
    "subscription_id = \"<your-subscription-id-here>\"\n",
    "tenant_id       = \"<your-tenant-id-here>\"\n",
    "```\n",
    "\n",
    ">IMPORTANT: The `terraform.tfvars` file should not be checked into version control to keep sensitive information secure.  Make sure to add it to your `.gitignore`.\n",
    "\n",
    "\n",
    "### Use the Networking Module\n",
    "\n",
    "Now, let's use the networking module you created to provision the networking resources needed for your AKS cluster. In your `main.tf`, include the following code:\n",
    "\n",
    "```hcl\n",
    "# main.tf\n",
    "\n",
    "module \"networking\" {\n",
    "  source = \"./networking-module\"\n",
    "\n",
    "  # Input variables for the networking module\n",
    "  location           = \"UK South\"\n",
    "  vnet_address_space = [\"10.0.0.0/16\"]\n",
    "\n",
    "  # Define more input variables as needed...\n",
    "}\n",
    "```\n",
    "This code imports the networking module and provides values for the required input variables. If the required variables already have a default value encoded in `variables.tf` and you don't want to overwrite these values, you can simply call the module using the `source` filed, without the additional variable fields.\n",
    "\n",
    "### Use the AKS Cluster Module\n",
    "\n",
    "Next, utilize the AKS cluster module to define and provision your AKS cluster. Add the following code to your `main.tf`:\n",
    "\n",
    "```hcl\n",
    "# main.tf\n",
    "\n",
    "module \"aks_cluster\" {\n",
    "  source = \"./aks-cluster-module\"\n",
    "\n",
    "  # Input variables for the AKS cluster module\n",
    "  aks_cluster_name           = \"terraform-aks-cluster\"\n",
    "  cluster_location           = var.location\n",
    "  service_principal_client_id = var.client_id\n",
    "  service_principal_client_secret = var.client_secret\n",
    "\n",
    "  # Input variables referencing outputs from the networking module\n",
    "  resource_group_name         = module.networking.resource_group_name\n",
    "  vnet_id                     = module.networking.vnet_id\n",
    "  control_plane_subnet_id     = module.networking.control_plane_subnet_id\n",
    "  worker_node_subnet_id       = module.networking.worker_node_subnet_id\n",
    "  aks_nsg_id                  = module.networking.aks_nsg_id\n",
    "\n",
    "  # Define more input variables as needed...\n",
    "}\n",
    "```\n",
    "\n",
    "> IMPORTANT: For the specialisation project, you will need to replace the `service_principal_client_id` and `service_principal_client_secret` with the `managed_identity_id`.\n",
    "\n",
    "In this code, you import the AKS cluster module and provide values for the input variables required by the module. Note you will once again need to add input variables to `variables.tf`, and sensitive variables values to `terraform.tfvars`, for your service principal ID and secret, or managed identity ID for the specialisation project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "**IMPORTANT: DO NOT ACTUALLY RUN THE `terraform apply` COMMAND.**\n",
    "**Provisioning an AKS cluster is a very expensive process. If you are using an Azure Free Tier account it will diminish your free credits very quickly. If you are completing your specialisation project, you can continue with the remaining steps and provision your AKS cluster.**\n",
    "\n",
    "After defining the main configuration file, you can now review the changes and plan the deployment:\n",
    "\n",
    "```shell\n",
    "terraform init\n",
    "terraform plan\n",
    "```\n",
    "\n",
    "If the plan looks satisfactory, you can apply the configuration to create the networking resources and the AKS cluster using `terraform apply`. \n",
    "\n",
    "> If you run into any permissions issues when running `terraform apply` make sure to check your Service Principal has the correct permissions assigned to it. You can do this by navigating to the **Subscriptions** web page, identifying your own subscription. From here access the **Access control (IAM)** page. Under **Role assignments**, you should see your Service Principal with the role **Contributor** assigned to it. Like in the image below:\n",
    "\n",
    "<p align=center><img src=images/IAMRole.png width=950 height=450></p>\n",
    "\n",
    "In the example above, the Service Principal is called `myAppMaya`.\n",
    "\n",
    "> Again, if you are running this as part of the specialisation project the issue above should'nt apply as all the necessary permissions have already been assigned to your AiCore-generated Azure account.\n",
    "\n",
    "With these networking configurations and the AKS cluster in place, your infrastructure will be set up according to your specifications. Be mindful that this might take a couple of minutes. Congratulations on deploying your first AKS cluster using Terraform!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the AKS Cluster\n",
    "\n",
    "Once you've deployed your AKS cluster, you'll need to access it to manage and deploy applications. In this section, we'll guide you on how to retrieve the `kubeconfig` and use `kubectl` to interact with the cluster.\n",
    "\n",
    "### Retrieve `kubeconfig`\n",
    "\n",
    "> Before you retrieve the configuration file, you need to make sure you are logged into the correct Azure account, which for the specialisation project is the account that has been generated for you and for which the credentials have been emailed to you at the beginning of the project.\n",
    "\n",
    "The `kubeconfig` is a configuration file that allows you to connect to your AKS cluster securely. To retrieve the `kubeconfig`, follow these steps:\n",
    "\n",
    "```shell\n",
    "# Use the Azure CLI to get the AKS cluster credentials\n",
    "az aks get-credentials --resource-group <your-resource-group> --name <your-aks-cluster-name>\n",
    "```\n",
    "\n",
    "Replace `<your-resource-group>` and `<your-aks-cluster-name>` with the appropriate values for your AKS cluster.\n",
    "\n",
    "The above command will fetch the `kubeconfig` and automatically merge it into your local `~/.kube/config` file, which is the default location for `kubeconfig`. Ensure that you have Azure CLI installed and configured with the necessary permissions.\n",
    "\n",
    "<p align=center><img src=images/kubeFile.png width=600 height=350></p>\n",
    "\n",
    "After retrieving the `kubeconfig`, you can start using `kubectl` to interact with your AKS cluster. For example check the status of your nodes you can run `kubectl get nodes`.\n",
    "\n",
    "With these steps, you can easily access and manage your AKS cluster using `kubectl`, making it a powerful tool for deploying and managing Kubernetes workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "When you no longer need your AKS cluster and associated resources, it's crucial to clean up to avoid unnecessary costs. Use Terraform's `terraform destroy` command to deprovision AKS and related resources while maintaining infrastructure as code (IaC) principles.\n",
    "\n",
    "Before performing any destructive actions, double-check that you have backups of critical data and configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the process of provisioning, configuring, and managing Azure Kubernetes Service (AKS) clusters using Terraform. By following Infrastructure as Code (IaC) principles, modularization, and best practices, you learned how to efficiently create and maintain AKS clusters to run containerized applications at scale."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
