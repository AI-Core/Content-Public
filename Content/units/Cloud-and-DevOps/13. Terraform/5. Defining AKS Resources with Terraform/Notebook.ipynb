{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining AKS Resources with Terraform\n",
    "\n",
    "In this lesson, we'll look in more detail at Azure Kubernetes Service (AKS) and Terraform, focusing on how to combine these powerful technologies to efficiently manage and orchestrate Kubernetes clusters on Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Objectives\n",
    "\n",
    "- **Setting Up the Development Environment**: We'll start by preparing your development environment, ensuring that you have the necessary tools and access to Azure\n",
    "\n",
    "- **Defining AKS Resources**: You'll learn how to define AKS resources in Terraform, including the creation of Azure Resource Groups and the configuration of AKS clusters to meet your specific requirements\n",
    "\n",
    "- **Authentication and Deployment**: We'll cover the authentication process using the Azure CLI and demonstrate how to deploy your Terraform configuration to create AKS clusters seamlessly\n",
    "\n",
    "- **Accessing the AKS Cluster**: Once your AKS cluster is up and running, we'll show you how to access it using the Kubernetes command-line tool, `kubectl`\n",
    "\n",
    "- **Maintenance and Cleanup**: Managing your AKS cluster doesn't end with its creation. We'll explore various maintenance tasks, including scaling, backup, and upgrades. Additionally, you'll learn how to gracefully clean up and delete resources when they are no longer needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Development Environment\n",
    "\n",
    "Before we start defining Azure Kubernetes Service (AKS) resources with Terraform, we need to ensure that your development environment is properly configured.\n",
    "\n",
    "To create a robust and fully functional AKS cluster, we need to consider various components that make up the infrastructure. These components include:\n",
    "\n",
    "- **Virtual Network (VNet)**: The networking foundation for your AKS cluster, which includes subnets for worker nodes, control plane nodes, and any additional network resources\n",
    "- **Subnets**: Specific network segments within the VNet, including those for worker nodes and control plane nodes\n",
    "- **Network Security Groups (NSGs)**: Security rules to control inbound and outbound traffic to resources in the subnets\n",
    "\n",
    "These components are essential for configuring the network infrastructure to support the AKS cluster. Thus, this Terraform project will not only need to contain a module for defining the AKS cluster resource itself, but an additional networking module that will focus on creating the VNet, subnets, and NSGs required for your AKS environment.\n",
    "\n",
    "Start by creating a dedicated directory for your Terraform project. This directory will contain all your Terraform configuration files.\n",
    "\n",
    "```shell\n",
    "mkdir aks-terraform\n",
    "cd aks-terraform\n",
    "```\n",
    "\n",
    "Inside this directory, create two subdirectories: `networking-module` and `aks-cluster-module` to represent the networking services and the AKS cluster configuration, respectively.\n",
    "\n",
    "```shell\n",
    "mkdir networking-module\n",
    "mkdir aks-cluster-module\n",
    "```\n",
    "\n",
    "By creating these directories, we are preparing to organize our Terraform modules in a structured manner. Now let's move on to the next sections, where we will define the necessary modules in detail and incorporate them into the main Terraform configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networking Services Module Configuration\n",
    "\n",
    "In this section, we will create the Terraform configuration files for the networking module, which provisions the networking components required to support your AKS cluster. The networking module includes the creation of a VNet, subnets, and NSG rules. These resources are important for secure access to your AKS cluster.\n",
    "\n",
    "Start by navigating to the `networking-module` directory, where you will define the networking resources. Inside this directory, create the necessary Terraform configuration files:\n",
    "\n",
    "- `main.tf`: This file defines the networking resources and NSG rules\n",
    "- `variables.tf`: Define input variables \n",
    "- `outputs.tf` (optional): Define output variables \n",
    "\n",
    "### Define Input Variables (`variables.tf`)\n",
    "\n",
    "In the `variables.tf` file, you can define input variables that allow you to customize your networking module's behavior. Input variables make your configuration more flexible and reusable.\n",
    "\n",
    "Here's an example of how you can define input variables:\n",
    "\n",
    "```hcl\n",
    "# networking-module/variables.tf\n",
    "\n",
    "variable \"resource_group_name\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"location\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"vnet_address_space\" {\n",
    "  description = \"Address space for the Virtual Network (VNet).\"\n",
    "  type        = list(string)\n",
    "  default     = [\"10.0.0.0/16\"]\n",
    "}\n",
    "\n",
    "# Define more variables as needed...\n",
    "\n",
    "```\n",
    "\n",
    "The `resource_group_name` variable defines the name of the Azure Resource Group where the networking resources will be created. The `location` variable specifies the Azure region where networking resources, such as the VNet, will be created. The `vnet_address_space` variable defines the address space for the VNet. It is a list of strings representing IP address ranges in CIDR notation. \n",
    "\n",
    "These variables allow users to customize the name of the resource group, the Azure region, and the VNet address space when using the networking module. Users can override the default values by providing their desired values in their Terraform configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSG Rules for Accessing AKS\n",
    "\n",
    "To be able to access your AKS cluster once it's provisioned from your local computer using `kubectl`, you will need to ensure that it has the necessary NSG rules in place. Below are the key NSG rules to consider adding:\n",
    "\n",
    "- `kube-apiserver` Port (TCP/443): The `kube-apiserver` serves the Kubernetes API. We create an NSG rule to allow inbound traffic to port 443 (HTTPS) on the `kube-apiserver`. This port is used for secure communication with the API server.\n",
    "\n",
    "- SSH Port (TCP/22) (Optional): If you need SSH access to the nodes in your AKS cluster for troubleshooting or administrative purposes, you can create an NSG rule to allow inbound traffic to port 22 (SSH). This rule is optional and should only be added if necessary.\n",
    "\n",
    "### Define Networking Resources and NSG Rules\n",
    "\n",
    "In the `main.tf` file within the `networking-module` directory, we will define the networking resources and NSG rules needed for secure access to the AKS cluster.\n",
    "\n",
    "```hcl\n",
    "# networking-module/main.tf\n",
    "\n",
    "# Create the Azure Resource Group for networking resources\n",
    "resource \"azurerm_resource_group\" \"networking\" {\n",
    "  name     = var.resource_group_name\n",
    "  location = var.location\n",
    "}\n",
    "\n",
    "# Define the Virtual Network (VNet) for the AKS cluster\n",
    "resource \"azurerm_virtual_network\" \"aks_vnet\" {\n",
    "  name                = \"<your_vnet_name>\"\n",
    "  address_space       = var.vnet_address_space\n",
    "  location            = azurerm_resource_group.networking.location\n",
    "  resource_group_name = azurerm_resource_group.networking.name\n",
    "}\n",
    "\n",
    "# Define subnets within the VNet for control plane and worker nodes\n",
    "resource \"azurerm_subnet\" \"control_plane_subnet\" {\n",
    "  name                 = \"<your_control_plane_subnet_name>\"\n",
    "  resource_group_name  = azurerm_resource_group.networking.name\n",
    "  virtual_network_name = azurerm_virtual_network.aks_vnet.name\n",
    "  address_prefixes     = [\"10.0.1.0/24\"]\n",
    "}\n",
    "\n",
    "resource \"azurerm_subnet\" \"worker_node_subnet\" {\n",
    "  name                 = \"<your_worker_node_subnet_name>\"\n",
    "  resource_group_name  = azurerm_resource_group.networking.name\n",
    "  virtual_network_name = azurerm_virtual_network.aks_vnet.name\n",
    "  address_prefixes     = [\"10.0.2.0/24\"]\n",
    "}\n",
    "\n",
    "# Define Network Security Group (NSG) for the AKS subnet\n",
    "resource \"azurerm_network_security_group\" \"aks_nsg\" {\n",
    "  name                = \"<your_nsg_name>\"\n",
    "  location            = azurerm_resource_group.networking.location\n",
    "  resource_group_name = azurerm_resource_group.networking.name\n",
    "}\n",
    "\n",
    "# Allow inbound traffic to kube-apiserver (TCP/443) from your public IP address\n",
    "resource \"azurerm_network_security_rule\" \"kube_apiserver\" {\n",
    "  name                        = \"\"<your_nsg_rule1_name>\"\n",
    "  priority                    = 1001\n",
    "  direction                   = \"Inbound\"\n",
    "  access                      = \"Allow\"\n",
    "  protocol                    = \"Tcp\"\n",
    "  source_port_range           = \"*\"\n",
    "  destination_port_range      = \"443\"\n",
    "  source_address_prefix       = \"YOUR_PUBLIC_IP_ADDRESS\"  # Replace with your public IP or IP range\n",
    "  destination_address_prefix  = \"*\"\n",
    "  resource_group_name         = azurerm_resource_group.networking.name\n",
    "  network_security_group_name = azurerm_network_security_group.aks_nsg.name\n",
    "}\n",
    "\n",
    "# Allow inbound traffic for SSH (TCP/22) - Optional\n",
    "resource \"azurerm_network_security_rule\" \"ssh\" {\n",
    "  name                        = \"<your_nsg_rule2_name>\"\n",
    "  priority                    = 1002\n",
    "  direction                   = \"Inbound\"\n",
    "  access                      = \"Allow\"\n",
    "  protocol                    = \"Tcp\"\n",
    "  source_port_range           = \"*\"\n",
    "  destination_port_range      = \"22\"\n",
    "  source_address_prefix       = \"YOUR_PUBLIC_IP_ADDRESS\"  # Replace with your public IP or IP range\n",
    "  destination_address_prefix  = \"*\"\n",
    "  resource_group_name         = azurerm_resource_group.networking.name\n",
    "  network_security_group_name = azurerm_network_security_group.aks_nsg.name\n",
    "}\n",
    "```\n",
    "\n",
    "> Make sure to replace the names in the resource blocks with your desired name for each resource. For example replace `\"<your_nsg_name>\"` with `\"aks-nsg`.\n",
    "\n",
    "In the example above:\n",
    "\n",
    "- The `azurerm_resource_group` block defines the creation of an Azure Resource Group, which is a logical container for grouping related Azure resources. The `name` and `location` parameters are set based on input variables (`var.resource_group_name` and `var.location`) to specify the name and Azure region for the resource group.\n",
    "\n",
    "- The `azurerm_virtual_network` block defines the creation of a Virtual Network (VNet) where your AKS cluster will reside. The `address_space` parameter is set based on the `var.vnet_address_space` input variable, which defines the address space for the VNet in CIDR notation.\n",
    "\n",
    "- The two `azurerm_subnet` subnets are defined within the VNet: `control_plane_subnet` and `worker_node_subnet`. These subnets are used for specific purposes within your AKS cluster. The `control_plane_subnet` is a subnet created within the Azure VNet that is dedicated to hosting the control plane components of an AKS cluster. The `worker_node_subnet` is another subnet created within the Azure VNet, and it serves as the network space for hosting the worker nodes of the AKS cluster.\n",
    "\n",
    "- The `azurerm_network_security_group` block defines the creation of an NSG named `aks-nsg`, which will be associated with the AKS subnet to control inbound and outbound traffic\n",
    "\n",
    "- The two `azurerm_network_security_rule` NSG rules are defined for inbound traffic:\n",
    "\n",
    "  - `kube_apiserver`: This rule allows inbound traffic on TCP port 443 (HTTPS) from a specified public IP address (`YOUR_PUBLIC_IP_ADDRESS`). This is essential for secure communication with the `kube-apiserver` of your AKS cluster.\n",
    "\n",
    "  - `ssh` (Optional): This rule allows inbound traffic on TCP port 22 (SSH) from a specified public IP address (`YOUR_PUBLIC_IP_ADDRESS`). It's optional and should only be added if SSH access to AKS nodes is required for administrative purposes.\n",
    "\n",
    "Overall, this configuration file sets up the networking infrastructure for your AKS cluster. It creates a resource group, a Virtual Network with subnets, and defines NSG rules to control inbound traffic. The NSG rules allow secure access to the Kubernetes API server (`kube-apiserver`) and optionally provide SSH access for administrative tasks.\n",
    "\n",
    "> Remember to replace `YOUR_PUBLIC_IP_ADDRESS` with your actual public IP address or IP range in the NSG rules to restrict access to only authorized IPs. You can run `curl ipinfo.io/ip` to find your IP address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Variables (`outputs.tf`)\n",
    "\n",
    "In the `outputs.tf` file, you can define output variables that provide information about the created networking resources. Output variables are useful for retrieving information from your modules and making it available for use in other parts of your Terraform configuration.\n",
    "\n",
    "Here's an example of how you can define output variables:\n",
    "\n",
    "```hcl\n",
    "# networking-module/outputs.tf\n",
    "\n",
    "output \"vnet_id\" {\n",
    "  description = \"ID of the Virtual Network (VNet).\"\n",
    "  value       = <vnet-resource-type>.<vnet-resource-identifier>.id\n",
    "}\n",
    "\n",
    "output \"control_plane_subnet_id\" {\n",
    "  description = \"ID of the control plane subnet.\"\n",
    "  value       = <subnet-resource-type>.<control-plane-subnet-identifier>.id\n",
    "}\n",
    "\n",
    "output \"worker_node_subnet_id\" {\n",
    "  description = \"ID of the worker node subnet.\"\n",
    "  value       = <subnet-resource-type>.<worker-node-subnet-identifier>.id\n",
    "}\n",
    "\n",
    "output \"resource_group_name\" {\n",
    "  description = \"Name of the Azure Resource Group for networking resources.\"\n",
    "  value       = <resource-group-resource-type>.<resource-group-resource-identifier>.name\n",
    "}\n",
    "\n",
    "# Define more output variables as needed...\n",
    "output \"aks_nsg_id\" {\n",
    "  description = \"ID of the Network Security Group (NSG) for AKS.\"\n",
    "  value       = <nsg-resource-type>.<nsg-resource-identifier>.id\n",
    "}\n",
    "```\n",
    "\n",
    "> Within the `value` argument of each `output` block you will have to replace the `<resource-type>` and `<resource-identifier>` with the correct resource type and identifier for each resource. You can find these values in the previously created `main.tf` where you provisioned your resources.\n",
    "\n",
    "Let's look at an example, for the VNet resource:\n",
    "\n",
    "```hcl\n",
    "# Define the Virtual Network (VNet) for the AKS cluster\n",
    "resource \"azurerm_virtual_network\" \"aks_vnet\" {\n",
    "  name                = \"<your_vnet_name>\"\n",
    "  address_space       = var.vnet_address_space\n",
    "  location            = azurerm_resource_group.networking.location\n",
    "  resource_group_name = azurerm_resource_group.networking.name\n",
    "}\n",
    "```\n",
    "\n",
    "The `output` block should look like this:\n",
    "\n",
    "```hcl\n",
    "output \"vnet_id\" {\n",
    "  description = \"ID of the Virtual Network (VNet).\"\n",
    "  value       = azurerm_virtual_network.aks_vnet.id\n",
    "}\n",
    "```\n",
    "In this case `<resource-type>` corresponds to `azurerm_virtual_network` and `<resource-identifier>` corresponds to `aks_vnet` as we can see from the VNet `resource` block.\n",
    "\n",
    "The `vnet_id` output variable provides the ID of the VNet created by the networking module. This output variable can then be used in the AKS cluster module to specify the VNet in which the AKS cluster should be created. \n",
    "\n",
    "The `control_plane_subnet_id` output variables provides the ID of the control plane subnet within the VNet. The control plane subnet is where the control plane components of the AKS cluster, such as the `kube-apiserver`, are deployed. You can use this output variable to configure the AKS cluster to use the specified subnet for its control plane. \n",
    "\n",
    "The `worker_node_subnet_id` output variables provides the ID of the worker node subnet within the VNet. The worker node subnet is where the AKS cluster's worker nodes are deployed. You can use this output variable to configure the AKS cluster to use the specified subnets for its worker nodes.\n",
    "\n",
    "The `resource_group_name` output variable will be used here as an output variable and will be used as an input variable in the AKS cluster module. This will allow you to pass data and share information between the modules in a structured and controlled manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "Run `terraform init` to set up the Terraform workspace and download the necessary provider plugins and modules. \n",
    "\n",
    "We will proceed with defining the AKS cluster module's configuration in the next section, and then we will apply both modules together, from the main project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AKS Cluster Module Resources\n",
    "\n",
    "In this section, we will define the Terraform configuration for creating an AKS cluster. Before we start defining the AKS cluster configuration, navigate to the module directory for your AKS resources `aks-cluster-module`. \n",
    "\n",
    "Inside the AKS module directory, create the following files:\n",
    "\n",
    "- `variables.tf`: This file will define the input variables that allow customization of the AKS cluster\n",
    "- `outputs.tf`: In this file, you can specify any output values that you want to retrieve after provisioning the AKS cluster\n",
    "- `main.tf`: The main configuration file where we will define the actual AKS cluster resources\n",
    "\n",
    "### Define Input Variables (`variables.tf`) \n",
    "\n",
    "To create a flexible and customizable AKS cluster configuration, we will define input variables that can be customized when using this module. Here are the input variables for this module:\n",
    "\n",
    "```hcl\n",
    "# aks-cluster/variables.tf\n",
    "\n",
    "variable \"aks_cluster_name\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"cluster_location\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"dns_prefix\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"kubernetes_version\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"service_principal_client_id\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"service_principal_client_secret\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "# Input variables from the networking module\n",
    "variable \"resource_group_name\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "variable \"vnet_id\" {\n",
    "  ...\n",
    "}\n",
    "\n",
    "...\n",
    "```\n",
    "> Inside the `variables.tf` file of this module, you should make sure to include all the output variables from the networking module. As an example `resource_group_name` and `vnet_id` have already been included. Make sure to add the rest of them including `control_plane_subnet_id`, `worker_node_subnet_id` and `aks_nsg_id`.\n",
    "\n",
    "Here's an explanation of the new input variables defined in the AKS cluster module configuration, excluding the ones that are output variables from the networking module. Later, you will use the output values from networking module as input variables in the AKS cluster module. This allows you to pass data and share information between modules in a structured and controlled manner.\n",
    "\n",
    "- The `aks_cluster_name` variable specifies the name of the AKS cluster that will be created\n",
    "- The `cluster_location` defines the Azure region where the AKS cluster will be created\n",
    "- The `dn_prefix` sets the DNS prefix for the AKS cluster, which is used to create a unique DNS name for the cluster\n",
    "- The `kubernetes_version` specifies the version of Kubernetes to be used for the AKS cluster\n",
    "- The `service_principal_client_id` is the Client ID of the service principal used for authenticating and managing the AKS cluster\n",
    "- The `service_principal_client_secret` specifies the Client Secret associated with the service principal used for AKS cluster authentication\n",
    "\n",
    "We will use these input variables to configure and create the AKS cluster resources in the `main.tf` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AKS Cluster Module\n",
    "\n",
    "In the `main.tf`, you can now define the configuration for the AKS cluster module.\n",
    "\n",
    "```hcl\n",
    "# aks-cluster/main.tf\n",
    "# Create the AKS cluster\n",
    "resource \"azurerm_kubernetes_cluster\" \"aks_cluster\" {\n",
    "  name                = var.aks_cluster_name\n",
    "  location            = var.cluster_location\n",
    "  resource_group_name = var.resource_group_name\n",
    "  dns_prefix          = var.dns_prefix\n",
    "  kubernetes_version  = var.kubernetes_version\n",
    "\n",
    "  default_node_pool {\n",
    "    name       = \"default\"\n",
    "    node_count = 1\n",
    "    vm_size    = \"Standard_DS2_v2\"\n",
    "    enable_auto_scaling = true\n",
    "    min_count = 1\n",
    "    max_count = 3\n",
    "  }\n",
    "\n",
    "  service_principal {\n",
    "    client_id     = var.service_principal_client_id\n",
    "    client_secret = var.service_principal_client_secret\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "Let's break down the configuration block for creating the AKS cluster:\n",
    "\n",
    "```# Create the AKS cluster\n",
    "resource \"azurerm_kubernetes_cluster\" \"aks_cluster\" {\n",
    "  name                = var.aks_cluster_name\n",
    "  location            = var.cluster_location\n",
    "  resource_group_name = var.resource_group_name\n",
    "  dns_prefix          = var.dns_prefix\n",
    "  kubernetes_version  = var.kubernetes_version\n",
    "```\n",
    "\n",
    "This block specifies the information we already explained in detail when defining the `variables.tf` for this module.\n",
    "\n",
    "```hcl\n",
    "  default_node_pool {\n",
    "    name       = \"default\"\n",
    "    node_count = 1\n",
    "    vm_size    = \"Standard_DS2_v2\"\n",
    "    enable_auto_scaling = true\n",
    "    min_count = 1\n",
    "    max_count = 3\n",
    "  }\n",
    "```\n",
    "\n",
    "The `default_node_pool` block defines the default node pool for the cluster:\n",
    "\n",
    "- `name`: Specifies the name of the default node pool, which is `default` in this case\n",
    "- `node_count`: Sets the initial number of nodes in the node pool to 1\n",
    "- `vm_size`: Specifies the virtual machine size for the nodes in the pool, which is `Standard_DS2_v2` in this example\n",
    "- `enable_auto_scaling`: Enables auto-scaling for the node pool\n",
    "- `min_count`: Sets the minimum number of nodes to 1\n",
    "- `max_count`: Sets the maximum number of nodes to 3\n",
    "\n",
    "```hcl\n",
    "  service_principal {\n",
    "    client_id     = var.service_principal_client_id\n",
    "    client_secret = var.service_principal_client_secret\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Finally, the `service_principal` blocks provides the authentication details for the AKS cluster. These are the same credentials you use when defining an Azure provider in your configuration. You should have access to this if you have provisioned a Service Principal in the previous lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Variables (`outputs.tf`) \n",
    "\n",
    "In the `outputs.tf` define the output variables for the AKS cluster module:\n",
    "\n",
    "```hcl\n",
    "output \"aks_cluster_name\" {\n",
    "  description = \"Name of the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.name\n",
    "}\n",
    "\n",
    "output \"aks_cluster_id\" {\n",
    "  description = \"ID of the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.id\n",
    "}\n",
    "\n",
    "output \"aks_kubeconfig\" {\n",
    "  description = \"Kubeconfig file for accessing the AKS cluster.\"\n",
    "  value       = <kubernetes-cluster-resource-type>.<kubernetes-cluster-resource-identifier>.kube_config_raw\n",
    "}\n",
    "```\n",
    "> Within the `value` argument of each `output` block you will have to replace the `<resource-type>` and `<resource-identifier>` with the correct resource type and identifier for each resource. You can find these values in the previously created `main.tf` where you provisioned your resources.\n",
    "\n",
    "These output variables provide information about the AKS cluster, including its name, ID, and the `kubeconfig` file for accessing the cluster using `kubectl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "Run `terraform init` to set up the Terraform workspace and download the necessary provider plugins and modules. \n",
    "\n",
    "In the next section we will apply both modules together, from the main project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Main Configuration\n",
    "\n",
    "In this section, we will define the main configuration for your project, which will utilize the networking module and the AKS cluster module to provision the necessary Azure resources.\n",
    "\n",
    "Begin by navigating to the project directory `aks-terraform`. Here we will begin defining your project's main configuration file, `main.tf`, by defining the Azure provider block for authentication. This block should be included at the beginning of the configuration file. \n",
    "\n",
    "```hcl\n",
    "terraform {\n",
    "  required_providers {\n",
    "    azurerm = {\n",
    "      source  = \"hashicorp/azurerm\"\n",
    "      version = \"=3.0.0\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "provider \"azurerm\" {\n",
    "  features {}\n",
    "  client_id       = var.client_id\n",
    "  client_secret   = var.client_secret\n",
    "  subscription_id = \"your-subscription-id\"\n",
    "  tenant_id       = \"your-tenant-id\"\n",
    "}\n",
    "```\n",
    "This provider block specifies that you will be using Azure as your cloud provider. It uses variables for the `client_id` and `client_secret`, which we will store in environment variables to avoid hardcoding them. First we need to add them to the main configuration's `variables.tf` as follows:\n",
    "\n",
    "```hcl\n",
    "#variables.tf\n",
    "\n",
    "variable \"client_id\" {\n",
    "  description = \"Access key for the provider\"\n",
    "  type        = string\n",
    "  sensitive   = true\n",
    "}\n",
    "\n",
    "variable \"client_secret\" {\n",
    "  description = \"Secret key for the provider\"\n",
    "  type        = string\n",
    "  sensitive   = true\n",
    "}\n",
    "```\n",
    "\n",
    "To use these variables securely, you will then need to open your `.zshrc` in a CLI text editor and add the following lines:\n",
    "\n",
    "```bash\n",
    "export TF_VAR_client_id=<your-client-id-here>\n",
    "export TF_VAR_client_secret=<your-client-secret-here>\n",
    "```\n",
    "\n",
    "The `TF_VAR_` prefix will allow Terraform to find these variables automatically and assign them to the ones you defined in `variables.tf`. Once you have added the variable definitions, save and exit your CLI text editor, and run the following to reinitialise your dotfile:\n",
    "\n",
    "```bash\n",
    "source ~/.zshrc\n",
    "```\n",
    "\n",
    ">IMPORTANT: Even if you use environment variables to hide your credentials during `terraform plan` and `terraform apply`, the secrets will still be present in your statefile. DO NOT upload your statefile to Github! Make sure to add it to your `.gitignore` to avoid any risk of this.\n",
    "\n",
    "\n",
    "### Use the Networking Module\n",
    "\n",
    "Now, let's use the networking module you created to provision the networking resources needed for your AKS cluster. In your `main.tf`, include the following code:\n",
    "\n",
    "```hcl\n",
    "# main.tf\n",
    "\n",
    "module \"networking\" {\n",
    "  source = \"./networking-module\"\n",
    "\n",
    "  # Input variables for the networking module\n",
    "  resource_group_name = \"networking-rg\"\n",
    "  location           = \"UK South\"\n",
    "  vnet_address_space = [\"10.0.0.0/16\"]\n",
    "\n",
    "  # Define more input variables as needed...\n",
    "}\n",
    "```\n",
    "This code imports the networking module and provides values for the required input variables.\n",
    "\n",
    "### Use the AKS Cluster Module\n",
    "\n",
    "Next, utilize the AKS cluster module to define and provision your AKS cluster. Add the following code to your `main.tf`:\n",
    "\n",
    "```hcl\n",
    "# main.tf\n",
    "\n",
    "module \"aks_cluster\" {\n",
    "  source = \"./aks-cluster-module\"\n",
    "\n",
    "  # Input variables for the AKS cluster module\n",
    "  aks_cluster_name           = \"terraform-aks-cluster\"\n",
    "  cluster_location           = \"UK South\"\n",
    "  dns_prefix                 = \"myaks-project\"\n",
    "  kubernetes_version         = \"1.26.6\"  # Adjust the version as needed\n",
    "  service_principal_client_id = var.your-service-principal-client-id\n",
    "  service_principal_client_secret = var.your-service-principal-client-secret\n",
    "\n",
    "  # Input variables referencing outputs from the networking module\n",
    "  resource_group_name         = module.networking.resource_group_name\n",
    "  vnet_id                     = module.networking.vnet_id\n",
    "  control_plane_subnet_id     = module.networking.control_plane_subnet_id\n",
    "  worker_node_subnet_id       = module.networking.worker_node_subnet_id\n",
    "  aks_nsg_id                  = module.networking.aks_nsg_id\n",
    "\n",
    "  # Define more input variables as needed...\n",
    "}\n",
    "```\n",
    "\n",
    "In this code, you import the AKS cluster module and provide values for the input variables required by the module. Note you will once again need to add input variables to `variables.tf`, and environment variables to `.zshrc`, for your service principal ID and secret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and Apply Configuration\n",
    "\n",
    "After defining the main configuration file, you can now review the changes and plan the deployment:\n",
    "\n",
    "```shell\n",
    "terraform init\n",
    "terraform plan\n",
    "```\n",
    "\n",
    "If the plan looks satisfactory (it should plan to deploy 8 different resources), you can apply the configuration to create the networking resources and the AKS cluster using `terraform apply`. With these networking configurations and the AKS cluster in place, your infrastructure will be set up according to your specifications. Be mindful that this might take a couple of minutes. Congratulations on deploying your first AKS cluster using Terraform!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the AKS Cluster\n",
    "\n",
    "Once you've deployed your AKS cluster, you'll need to access it to manage and deploy applications. In this section, we'll guide you on how to retrieve the `kubeconfig` and use `kubectl` to interact with the cluster.\n",
    "\n",
    "### Retrieve `kubeconfig`\n",
    "\n",
    "The `kubeconfig` is a configuration file that allows you to connect to your AKS cluster securely. To retrieve the `kubeconfig`, follow these steps:\n",
    "\n",
    "```shell\n",
    "# Use the Azure CLI to get the AKS cluster credentials\n",
    "az aks get-credentials --resource-group <your-resource-group> --name <your-aks-cluster-name>\n",
    "```\n",
    "\n",
    "Replace `<your-resource-group>` and `<your-aks-cluster-name>` with the appropriate values for your AKS cluster.\n",
    "\n",
    "The above command will fetch the `kubeconfig` and automatically merge it into your local `~/.kube/config` file, which is the default location for `kubeconfig`. Ensure that you have Azure CLI installed and configured with the necessary permissions.\n",
    "\n",
    "<p align=center><img src=images/kubeFile.png width=600 height=350></p>\n",
    "\n",
    "After retrieving the `kubeconfig`, you can start using `kubectl` to interact with your AKS cluster. For example check the status of your nodes you can run `kubectl get nodes`.\n",
    "\n",
    "With these steps, you can easily access and manage your AKS cluster using `kubectl`, making it a powerful tool for deploying and managing Kubernetes workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "When you no longer need your AKS cluster and associated resources, it's crucial to clean up to avoid unnecessary costs. Use Terraform's `terraform destroy` command to deprovision AKS and related resources while maintaining infrastructure as code (IaC) principles.\n",
    "\n",
    "Before performing any destructive actions, double-check that you have backups of critical data and configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the process of provisioning, configuring, and managing Azure Kubernetes Service (AKS) clusters using Terraform. By following Infrastructure as Code (IaC) principles, modularization, and best practices, you learned how to efficiently create and maintain AKS clusters to run containerized applications at scale."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
