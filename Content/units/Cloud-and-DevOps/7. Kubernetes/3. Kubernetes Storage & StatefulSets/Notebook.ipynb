{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage\n",
    "\n",
    "## Introduction\n",
    ">Pods and containers are __ephemeral__, i.e. they are short-lived.\n",
    "\n",
    "### Merits of pods and containers\n",
    "- Easy to create and destroy\n",
    "- Immutable and easy to reason about.\n",
    "- Easy to parallelise.\n",
    "\n",
    "### Demerits of pods and containers\n",
    "- When a pod is removed, all of the data created by it on the local disk are also removed.\n",
    "- Each container is a separate entity. Therefore, data sharing between containers is not possible, unless `Volume`s are employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volumes\n",
    "\n",
    "`Volume`s in `k8s` are slightly different from those in `Docker`.\n",
    "\n",
    "### Brief overview of `volume`s in `Docker`\n",
    "- The directory is located on the `disk` or in another `container`.\n",
    "- `Volume`s are mounted in containers during runtime.\n",
    "- Data sharing across instances (or using `cloud` storage) is possible via `drivers` (for more information, see [here](https://docs.docker.com/storage/volumes/#share-data-among-machines)).\n",
    "\n",
    "Although the offerings resolve some of our problems, the feature set is quite limited and inadequate for large-scale deployments.\n",
    "\n",
    "### High-level features\n",
    "- __`Volume`s can be mounted simultaneously.__\n",
    "- __`Ephemeral volume`s have lifetimes similar to those of their `POD`s.\n",
    "- __`Persistent volume`s have lifetimes independent of those of their `POD`s.\n",
    "- __Data is available across `container`s restart,__ handled by `kubelet`.\n",
    "\n",
    "Volumes can be attached to pods via the following:\n",
    "- `.spec.volumes`: specifies which `volumes` to use.\n",
    "- `.spec.containers[*].volumeMounts`: specifies  where and which volume to mount in a specific container.\n",
    "\n",
    "Consider the below example using a `DaemonSet`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  name: fluentd-elasticsearch\n",
    "  labels:\n",
    "    k8s-app: fluentd-logging\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      name: fluentd-elasticsearch\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        name: fluentd-elasticsearch\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: fluentd-elasticsearch\n",
    "        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n",
    "        resources:\n",
    "          limits:\n",
    "            memory: 200Mi\n",
    "          requests:\n",
    "            cpu: 100m\n",
    "            memory: 200Mi\n",
    "        # Here we can mount them with `name` matching\n",
    "        # Ephemeral Volumes\n",
    "        volumeMounts:\n",
    "        - name: varlog\n",
    "          mountPath: /var/log\n",
    "        - name: varlibdockercontainers\n",
    "          mountPath: /var/lib/docker/containers\n",
    "          readOnly: true\n",
    "      terminationGracePeriodSeconds: 30\n",
    "      # Here we define our volumes\n",
    "      # Data from POD will be mounted\n",
    "      volumes:\n",
    "      - name: varlog\n",
    "        hostPath:\n",
    "          path: /var/log\n",
    "      - name: varlibdockercontainers\n",
    "        hostPath:\n",
    "          path: /var/lib/docker/container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "- Create a .yaml file for creating the DeamonSet.\n",
    "- Create it, and use the describe command from kubectl to observe the volumes.\n",
    "- Go to the minikube dashboard, and search for the volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daemonset.apps/fluentd-elasticsearch created\n"
     ]
    }
   ],
   "source": [
    "# Create the DaemonSet\n",
    "!kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:           fluentd-elasticsearch\n",
      "Selector:       name=fluentd-elasticsearch\n",
      "Node-Selector:  <none>\n",
      "Labels:         k8s-app=fluentd-logging\n",
      "Annotations:    deprecated.daemonset.template.generation: 1\n",
      "Desired Number of Nodes Scheduled: 3\n",
      "Current Number of Nodes Scheduled: 3\n",
      "Number of Nodes Scheduled with Up-to-date Pods: 3\n",
      "Number of Nodes Scheduled with Available Pods: 3\n",
      "Number of Nodes Misscheduled: 0\n",
      "Pods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed\n",
      "Pod Template:\n",
      "  Labels:  name=fluentd-elasticsearch\n",
      "  Containers:\n",
      "   fluentd-elasticsearch:\n",
      "    Image:      quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n",
      "    Port:       <none>\n",
      "    Host Port:  <none>\n",
      "    Limits:\n",
      "      memory:  200Mi\n",
      "    Requests:\n",
      "      cpu:        100m\n",
      "      memory:     200Mi\n",
      "    Environment:  <none>\n",
      "    Mounts:\n",
      "      /var/lib/docker/containers from varlibdockercontainers (ro)\n",
      "      /var/log from varlog (rw)\n",
      "  Volumes:\n",
      "   varlog:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /var/log\n",
      "    HostPathType:  \n",
      "   varlibdockercontainers:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /var/lib/docker/container\n",
      "    HostPathType:  \n",
      "Events:\n",
      "  Type    Reason            Age   From                  Message\n",
      "  ----    ------            ----  ----                  -------\n",
      "  Normal  SuccessfulCreate  19m   daemonset-controller  Created pod: fluentd-elasticsearch-rkwrs\n",
      "  Normal  SuccessfulCreate  19m   daemonset-controller  Created pod: fluentd-elasticsearch-4m4wt\n",
      "  Normal  SuccessfulCreate  19m   daemonset-controller  Created pod: fluentd-elasticsearch-5wjx9\n"
     ]
    }
   ],
   "source": [
    "# Use the describe command\n",
    "!kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashboard should have an appearance similar to that in the figure below, with the volumes mounted in the container:\n",
    "<p><img src=images/volume.png></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume types\n",
    "\n",
    "`kubernetes` provides a few integrations for standard volumes:\n",
    "- `AWS Elastic Block Store`\n",
    "- Microsoft's Azure `Disk` and `File`\n",
    "- Self-hosted `cephfs`\n",
    "- [Google Cloud Persistent Disk](https://kubernetes.io/docs/concepts/storage/volumes/#gcepersistentdisk)\n",
    "\n",
    "An example config with `awsElasticBlockStore` is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: test-ebs\n",
    "spec:\n",
    "  containers:\n",
    "  - image: k8s.gcr.io/test-webserver\n",
    "    name: test-container\n",
    "    volumeMounts:\n",
    "    - mountPath: /test-ebs\n",
    "      name: test-volume\n",
    "  volumes:\n",
    "  - name: test-volume\n",
    "    # This AWS EBS volume must already exist.\n",
    "    awsElasticBlockStore:\n",
    "      volumeID: \"<volume id>\"\n",
    "      fsType: ext4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detailed information on volume types, check [here](https://kubernetes.io/docs/concepts/storage/volumes/#volume-types).\n",
    "\n",
    "__Note that these are all ephemeral `volume`s; therefore, they will only live as long as the pod.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent volumes\n",
    "\n",
    "> `Kubernetes` provides two resources for managing persistent storage: `PersistentVolume` and `PersistentVolumeClaim`.\n",
    "\n",
    "These allow us to abstract how storage is provided and expended.\n",
    "\n",
    "#### PersistentVolume\n",
    "\n",
    "A persistent volume refers to a storage volume in a cluster provisioned by an administrator. Persistent volumes are 'physical' volumes on the host machine.\n",
    "\n",
    "*Characteristics of persistent volumes*\n",
    "\n",
    "- They have resources in the cluster (similar to `Node`s).\n",
    "- They are volume plugins similar to `volume`s described above.\n",
    "- __Their lifetime is independent of that of any pod.__\n",
    "- When bounded, they can be used similarly to `volume`s.\n",
    "\n",
    "#### PersistentVolumeClaim\n",
    "\n",
    "A persistent volume claim (PVC) is a request for the platform to create a PV on your behalf. To do this, it will search for any 'available' PersistentVolume that meets the specified requirements.\n",
    "\n",
    "*Features*\n",
    "- Conceptually similar to `POD`s:\n",
    "    - `POD`s consume `Node` resources, whereas `PVC`s consume `PV` resources.\n",
    "    - `POD`s can request specific resources (e.g. RAM), whereas `PVC`s can request specific sizes and access modes (e.g. `read` and `write`).\n",
    "    \n",
    "#### Provisioning\n",
    "\n",
    "`PV`s can be provisioned in two ways:\n",
    "- `statically`: cluster admin creates `PV`s for consumption.\n",
    "- `dynamically`: cluster attempts to dynamically provision appropriate `PV`s based on the `PersistentVolumClaim`'s __`StorageClasses`__ (the administrator has to provision the `StorageClass`, which will be __described later__).\n",
    "\n",
    "*Features*\n",
    "- __`Dynamic provision` will always match the requirements of the `PVC`.__\n",
    "- __`Static Provision` must at least match the given claim__ (e.g. a claim of `50GB` might be given `100Gb`).\n",
    "\n",
    "#### Reclaim Policy\n",
    "\n",
    "When a user is finished with a volume, they can delete the PVC objects from the API, which allows the reclamation of the resource.\n",
    "\n",
    "There are three approaches for reclaiming the resource:\n",
    "- [`retain`](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#retain): leave the data as-is (leave `PersistentVolume` and external storage.\n",
    "- [`delete`](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#delete): delete `PersistentVolume` __and external storage__. This is the default approach for `Dynamic Provisioning`, although it is configurable.\n",
    "- [`recycle`](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#recycle): (__now deprecated; dynamic provisioning should be used instead__).\n",
    "\n",
    "Volumes can exist in any of the four states:\n",
    "\n",
    "- `Available`: the volume is ready to be bound to a pod.\n",
    "- `Bound`: the CLI shows the pod to which the `PersistentVolume` is bound.\n",
    "- `Released`: the `PesistentVolumeClaim` has ended; however, the resource is yet to be reclaimed by the `cluster`.\n",
    "- `Failed`: reclamation failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying `PersistentVolume`\n",
    "\n",
    "As with pods, PVs are created using `.yaml` config files, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: task-pv-volume\n",
    "  labels:\n",
    "    type: local\n",
    "spec:\n",
    "  storageClassName: manual\n",
    "  capacity:\n",
    "    storage: 10Gi\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  hostPath:\n",
    "    path: \"/mnt/data\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we describe some common arguments that you can pass:\n",
    "1. `.spec.capacity.storage`: request `10GB` of storage. Currently, only storage can be requested (see [`k8s` resource model for description of units](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md)).\n",
    "2. `.spec.volumeMode`: either `FileSystem` (default) or `Block`.\n",
    "    - `FileSystem`: directory mounted in pods.\n",
    "    - `Block`: uses a raw block of storage (without a filesystem created). The `Block` option is rarely used as applications need to know how to access `raw` data (see [here](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#raw-block-volume-support) for an example).\n",
    "3. `.spec.accessModes`: stipulates how data can be accessed.\n",
    "    - `ReadWriteOnce`: volume mounted as `rw` by a single `Node`.\n",
    "    - `ReadOnlyMany`: can be mounted by many `nodes`, but the data can only be read.\n",
    "    - `ReadWriteMany`: same as above; however, `rw` access is granted (applications may need to handle possible data races).\n",
    "    - `ReadWriteOncePod`: a single pod with `rw` access.\n",
    "      \n",
    "The modes above differ based on the type of `PersistentVolume` provider. A few of them are shown below:\n",
    "\n",
    "![](./images/modes_providers.png)\n",
    "\n",
    "4. __`.spec.storageclassName`__: specifies `StorageClass`. If left unspecified, __no `StorageClass` will be specified, and only a `PV` without one can be matched to the `POD`.__\n",
    "5. `.spec.mountOptions`: __not supported by all types.__. It specifies how to mount the `disk` and can left as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "1. Create a .yaml file with the configuration above for creating a PersistentVolume resource.\n",
    "2. `apply` it using the right `kubectl`.\n",
    "3. Observe the status of the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolume/task-pv-volume created\n"
     ]
    }
   ],
   "source": [
    "!kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE\n",
      "task-pv-volume   10Gi       RWO            Retain           Available           manual                  13m\n"
     ]
    }
   ],
   "source": [
    "!kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StorageClasses\n",
    "\n",
    "> A StorageClass provides a way for administrators to describe the 'classes' of storage they offer.\n",
    "\n",
    "StorageClasses allow us to __dynamically provision storage__ and serve as templates for new `PersistentVolume`s.\n",
    "\n",
    "As is conventional, these are defined using `.yaml` files and can be referred to by `PV` config files.\n",
    "\n",
    "Consider the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: standard\n",
    "provisioner: kubernetes.io/aws-ebs\n",
    "parameters:\n",
    "  type: gp2\n",
    "reclaimPolicy: Retain\n",
    "allowVolumeExpansion: true\n",
    "mountOptions:\n",
    "  - debug\n",
    "volumeBindingMode: Immediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `.metadata.name` value allows users to request this `StorageClass`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mandatory fields\n",
    "\n",
    "> `provisioner`: which volume plugin is used for provisioning `PV`.\n",
    "\n",
    "The most common ones are shipped with `k8s` under the `kubernetes.io` prefix. For example,\n",
    "\n",
    "- `local`: `kubernetes.io/no-provisioner` (create `PV`s dynamically from the local resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: local-storage\n",
    "provisioner: kubernetes.io/no-provisioner\n",
    "volumeBindingMode: WaitForFirstConsumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GCEPersistentDisk`: Persistent disk from Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: slow\n",
    "provisioner: kubernetes.io/gce-pd\n",
    "parameters:\n",
    "  type: pd-standard\n",
    "  fstype: ext4\n",
    "  replication-type: none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not limited to the ones provided. `Provider`s can be written by anyone and hosted.\n",
    "\n",
    "> `parameters`: for defining the per-provisioner specification of volume properties.\n",
    "\n",
    "Examples of different internal provisioners can be found [here](https://kubernetes.io/docs/concepts/storage/storage-classes/#aws-ebs).\n",
    "\n",
    "> `reclaimPolicy`: stipulates what should be done with the created `PersistentVolume` once it is freed from `PVC`.\n",
    "\n",
    "As mentioned previously, the option to `Delete` or `Retain` is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expandable Volumes\n",
    "\n",
    "> The option of expanding volumes dynamically was introduced with `k8s` 1.11.\n",
    "\n",
    "This occurs when the storage requirements in the `PVC` are changed and a new config is `apply`ied.\n",
    "\n",
    "> The easiest way to exploit this feature is to use an internal cloud provider.\n",
    "\n",
    "__Simply set `.allowVolumeExpansion: true` in the `StorageClass` definition.__\n",
    "\n",
    "Below is a list of `providers` that support expandable volumes.\n",
    "\n",
    "![](./images/expandable-volumes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Summary\n",
    "\n",
    "Here is a rough guideline for handling storage.\n",
    "\n",
    "> __Decide if your data should be shared between containers or pods.__\n",
    "\n",
    "If it is the former, should the data be preserved after pod termination?\n",
    "\n",
    "__If yes, use `ephemeral volumes` to simply data exchange between applications (`LAMP` example above).__\n",
    "\n",
    "__If the data should be shared between pods or preserved, use `PersistentVolumes`.__\n",
    "\n",
    "Thereafter, determine if dynamic provisioning is required (it is difficult to know beforehand how much storage is required).\n",
    "\n",
    "If not, create the following:\n",
    "- `PersistentVolume` `.yml` config (defines how a `volume` is created).\n",
    "- `PersistentVolumeClaim` `.yml` config (specifies how a `volume` is requested).\n",
    "- `MyApplication` `.yml` config (the `workload resource`; __remember to avoid bare pods__).\n",
    "\n",
    "If, however, dynamic provisioning is required, add another `.yml` config file to the steps above:\n",
    "- `StorageClass` `.yml` config (acts as a template for giving out `PersistentVolume`s to pods in need).\n",
    "\n",
    "> __This should be used for large-scale apps, where 'by-hand' provisioning is not feasible due to the following reasons:__\n",
    "\n",
    "- There are many pods requesting a high storage allocation.\n",
    "- It is impossible to know beforehand how many pods will run.\n",
    "\n",
    "> Note that cloud-storage providers are preferred in this case, __as local storage may be insufficient for large deployments.__\n",
    "\n",
    "\n",
    "*Other options*\n",
    "\n",
    "One can also use the aforementioned `expandable volumes` if\n",
    "- the maximum number of pods that will run at any given time is known.\n",
    "- the amount of storage required for each pod is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StatefulSets\n",
    "   \n",
    "Recall that `workload`s are used for __stateless applications__ (e.g. the ones not writing to external storage).\n",
    "\n",
    "In a nutshell, StatefulSets are a type of workload resource (that manages pods) that adds a storage volume to the pod. This way, all the data associated with the pod will be stored and can be reused the next time the same pod is run, hence the name 'Stateful'. This is useful, for example, for running a pod that depends on a database where the data is stored (e.g. an SQL database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "- `Storage` must be provisioned by an admin (or by `StorageClass` dynamically).\n",
    "- __Deleting will not delete the `Storage`__ (storage preservation > automatic purging).\n",
    "- __Headless `Service`,__ which is used for the network identity of `POD`s, __must be created.__\n",
    "\n",
    "### Components\n",
    "\n",
    "Here are the `.yaml` definitions necessary for a `StatefulSet`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: nginx\n",
    "  labels:\n",
    "    app: nginx\n",
    "spec:\n",
    "  ports:\n",
    "  - port: 80\n",
    "    name: web\n",
    "  clusterIP: None\n",
    "  selector:\n",
    "    app: nginx\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: web\n",
    "spec:\n",
    "  serviceName: \"nginx\"\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: k8s.gcr.io/nginx-slim:0.8\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "          name: web\n",
    "        volumeMounts:\n",
    "        - name: www\n",
    "          mountPath: /usr/share/nginx/html\n",
    "  volumeClaimTemplates:\n",
    "  - metadata:\n",
    "      name: www\n",
    "    spec:\n",
    "      accessModes: [ \"ReadWriteOnce\" ]\n",
    "      resources:\n",
    "        requests:\n",
    "          storage: 1Gi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Headless Service named `nginx` is used to control the network domain.\n",
    "- The `StatefulSet` named web has a Spec that indicates that three replicas of the `nginx` container will be launched in unique pods.\n",
    "- The `volumeClaimTemplates` will provide stable storage using the `PersistentVolumes` provisioned by a `PersistentVolume` provisioner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "1. Create a .yaml file with the configuration above for creating a PersistentVolume resource.\n",
    "2. `apply` it using the right `kubectl`.\n",
    "3. Go to the dashboard, and observe the PVCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/nginx created\n",
      "statefulset.apps/web created\n"
     ]
    }
   ],
   "source": [
    "!kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashboard's appearance should be similar to that shown below:\n",
    "<p align=center><img src=images/PVC.png></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the volumes are already bound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837723d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of\n",
    "\n",
    "- the merits of volumes over pods and containers.\n",
    "- the types of volumes and their benefits.\n",
    "- StorageClasses and how to handle storage.\n",
    "- StatefulSets and their limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4b72e",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- Read about `DefaultStorageClass` admission plugin and how it changes behaviour for __unspecified `StorageClassses`__ in the case of `PV` or `PVC`.\n",
    "- Learn about the `Volume Snapshot` feature of `PersistentVolume`s [here](https://kubernetes.io/docs/concepts/storage/volume-snapshots/).\n",
    "- Read up on how to create __non-empty `PersistentVolume`s.__ Explore the information in the [volume populators](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-populators-and-data-sources) section.\n",
    "- Find out how to monitor the health of your `Volume`s [here](https://kubernetes.io/docs/concepts/storage/volume-health-monitoring/)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
