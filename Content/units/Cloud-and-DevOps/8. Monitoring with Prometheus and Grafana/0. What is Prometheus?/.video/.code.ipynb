{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global:\n",
    "  scrape_interval: 15s # By default, scrape targets every 15 seconds.\n",
    "  # Attach these labels to any time series or alerts when communicating with\n",
    "  # external systems (federation, remote storage, Alertmanager).\n",
    "  external_labels:\n",
    "    monitor: 'codelab-monitor'\n",
    "\n",
    "# A scrape configuration containing exactly one endpoint to scrape:\n",
    "# Here it's Prometheus itself.\n",
    "scrape_configs:\n",
    "  # The job name added as a label `job=<job_name>` to any timeseries scraped\n",
    "  - job_name: 'prometheus'\n",
    "    # Override the global default and scrape targets from job every 5 seconds.\n",
    "    scrape_interval: '5s'\n",
    "    static_configs:\n",
    "      - targets: ['localhost:9090']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --rm -p 9090:9090 --name prometheus -v /path/to/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml --web.enable-lifecycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section with default values\n",
    "global:\n",
    "  scrape_interval: 15s # How frequently to scrape targets from jobs\n",
    "  scrape_timeout: 10s # If there is no response from instance do not try to scrape\n",
    "  evaluation_interval: 15s # How frequently to evaluate rules (e.g. reload graphs with new data)\n",
    "# Prometheus alert manager, left for now\n",
    "alerting:\n",
    "  alertmanagers:\n",
    "  - follow_redirects: true\n",
    "    scheme: http\n",
    "    timeout: 10s\n",
    "    api_version: v2\n",
    "    static_configs:\n",
    "    - targets: []\n",
    "# Specific configuration for jobs\n",
    "scrape_configs:\n",
    "- job_name: prometheus # Name of the job, can be anything\n",
    "  honor_timestamps: true # Use timestamps provided by job\n",
    "  scrape_interval: 15s # As before, but for this job\n",
    "  scrape_timeout: 10s # ^\n",
    "  metrics_path: /metrics # Where metrics are located w.r.t. port (localhost:9090/metrics)\n",
    "  scheme: http # Configures the protocol scheme used for requests (localhost is http)\n",
    "  follow_redirects: true\n",
    "  static_configs:\n",
    "  - targets:\n",
    "    - localhost:9090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global:\n",
    "  scrape_interval: '1s'  # By default, scrape targets every 15 seconds.\n",
    "  external_labels:\n",
    "    monitor: 'codelab-monitor'\n",
    "\n",
    "scrape_configs:\n",
    "  # Prometheus monitoring itself\n",
    "  - job_name: 'prometheus'\n",
    "    scrape_interval: '10s'\n",
    "    static_configs:\n",
    "      - targets: ['localhost:9090']\n",
    "  # OS monitoring\n",
    "  - job_name: 'node'\n",
    "    scrape_interval: '5s'\n",
    "    static_configs:\n",
    "      - targets: ['YOUR INTERNAL IP ADDRESS:9100']\n",
    "        labels:\n",
    "          group: 'production' # notice we have defined two nodes to be labelled in the production environment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
