{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKS Monitoring: Logs and Alarms\n",
    "\n",
    "Monitoring your AKS clusters is a fundamental practice for optimizing performance, managing resources, and enhancing security in your containerized applications. In this lesson, we will delve into two critical aspects of AKS monitoring: effective log analysis and setting up custom alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Analytics Workspace and Queries\n",
    "\n",
    "Log Analytics is the go-to platform for writing, testing, and executing log queries. It offers a wide range of capabilities, from simple queries that filter, sort, and analyze records to advanced queries that perform statistical analyses, allowing you to visualize trends and patterns within your data. \n",
    "\n",
    "To access Log Analytics for the AKS cluster in the Azure Portal, navigate to the AKS cluster and select **Logs** under the **Monitoring** page. Accessing Log Analytics will redirect you to the following page:\n",
    "\n",
    "<p align=center> <img src=images/LogAnalyticsVideo.png width=700 height=450> </p>\n",
    "\n",
    "This video provides a useful overview of the Log Analytics service, so make sure to watch it before continuing further. Once you've finished watching the introductory video, click **X**, and you will be redirected to a dialog box that contains example queries:\n",
    "\n",
    "\n",
    "<p align=center> <img src=images/LogQueries.png width=750 height=450> </p>\n",
    "\n",
    "These queries are excellent starting points, and you can browse or search for queries that align with your requirements. You might even find an example query that perfectly meets your needs, but alternatively you also have the option to load an example query into the editor and make necessary modifications.\n",
    "\n",
    "The example queries cover a wide range of topics by which you can sort, such as:\n",
    "\n",
    "- **Alerts**: This category typically includes queries related to setting up and managing alert rules for monitoring your AKS resources. It helps you define the conditions and thresholds for alerting when specific events occur.\n",
    "\n",
    "- **Container Logs**: Queries in this category focus on container-level logs, allowing you to dig into the details of what's happening inside your containers. You can filter, search, and analyze logs to troubleshoot issues and monitor application behavior.\n",
    "\n",
    "- **Find in Table**: These queries are incredibly useful for searching specific data in your logs. They can help you quickly locate information within large datasets, saving you time and effort in pinpointing relevant records.\n",
    "\n",
    "- **Availability**: The availability category offers queries to assess the uptime and availability of your AKS cluster, including checks on the health of nodes, pods, and services. These queries help you maintain consistent service availability.\n",
    "\n",
    "- **Performance**: The performance category includes queries that focus on assessing the performance of your AKS cluster. This can involve monitoring key metrics related to CPU and memory usage, network performance, and other performance-related aspects.\n",
    "\n",
    "Let's run the **Container CPU** query under the **Performance** category as an example. First, you will observe you have two choices, either **Run** or **Load to editor**. By selecting **Run**, you will execute the query immediately, and the results will be displayed in the **Results** section of Log Analytics. Choosing **Load to editor** loads the selected query into the query editor without executing it right away. This allows you to review and potentially edit the query before running it. Let's choose the first option for now.\n",
    "\n",
    "Running this will redirect you to the Log Analytics main interface:\n",
    "\n",
    "<p align=center> <img src=images/LogAnalyticsInterface.png width=900 height=500> </p>\n",
    "\n",
    "To help you make the most of Log Analytics, let's familiarize ourselves with the essential components of its user interface:\n",
    "\n",
    "- **Top Action Bar**: The top bar provides controls for working with queries in the query window. Here, you can find the following features:\n",
    "\n",
    "  - **Scope**: Specifies the scope of data to be used for the query. This means you can define whether the query should analyze all the data within a Log Analytics workspace or data specific to a particular resource across multiple workspaces. It's a crucial feature for narrowing down the focus of your query.\n",
    "  \n",
    "  - **Run Button**: The **Run** button executes the selected query in the query window. You can also run a query by selecting it and pressing **Shift+Enter**. It initiates the query and displays the results.\n",
    "  \n",
    "  - **Time Range**: Allows you to select the time range for the data available to the query. This is essential for specifying the period you want to analyze. If your query includes a time filter, the time range settings will be overridden.\n",
    "\n",
    "  - **Save Button**: The **Save** button is used to save the query to the *Query Explorer* for the workspace. **Query Explorer** is a feature in Log Analytics that enables easy access to saved queries.\n",
    "\n",
    "- **Left Sidebar**: The sidebar on the left presents tables within the workspace, sample queries, and filter options for the active query\n",
    "\n",
    "- **Query Window**: The query window provides you with the ability to create, modify, and execute queries using the *Kusto Query Language (KQL)*. KQL is a versatile query language designed for querying and analyzing data within Microsoft services like Log Analytics, Azure Monitor, and more. It offers a structured and SQL-like syntax for data manipulation, filtering, and transformation. \n",
    "\n",
    "- **Results Window**: The results are presented in a table format, organized by columns and rows. This view allows you to expand row values, modify the list of columns, sort results, and apply filters. Results can also be presented visually using the **Chart** feature. The chart view transforms query results into various chart types, with the option to choose your preferred chart style and specify columns for the x-axis, y-axis, and series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-On: Exploring AKS Cluster Logs\n",
    "\n",
    "In this hands-on, we will walk through the process of executing various log queries for an AKS cluster, and demonstrate how to save them for easy access. This allows us to analyze and monitor our AKS cluster efficiently.\n",
    "\n",
    "#### Step 1: Access Log Analytics Workspace\n",
    "\n",
    "If you haven't already access the Log Analytics interface, navigate to the **Logs** tab for the desired AKS cluster.\n",
    "\n",
    "#### Step 2: Explore and Save Log Queries\n",
    "\n",
    "We will explore and save different types of log queries related to our AKS cluster:\n",
    "\n",
    "**Log 1: Average Nodes CPU Usage Percentage per Minute**\n",
    "\n",
    "- Begin by tracking the average node's CPU usage per minute. To do this, choose **Avg node CPU usage percentage per minute** under the **Alerts** log queries.\n",
    "\n",
    "- Execute the query to visualize the results. Each row in the results section represents the average node CPU usage within a one-minute time bin.\n",
    "\n",
    "<p align=center> <img src=images/AverageCPUMin.png width=800 height=300> </p>\n",
    "\n",
    "- To ensure easy access, save the query by clicking the **Save** button, then selecting **Save as query**. Choose a descriptive name, and categorize it under **Containers**. Organizing AKS-related queries within this category will keep them grouped together for easier access. Finally, hit the **Save** button.\n",
    "\n",
    "**Log 2: Average Nodes Memory Usage Percentage per Minute**\n",
    "\n",
    "- Start by creating a new log query by clicking on the **+** button in the top ribbon of the Log Analytics interface. Now, let's focus on monitoring the average node's memory usage per minute. To do this, choose **Avg node memory usage percentage per minute** under the **Alerts** log queries.\n",
    "\n",
    "- Execute the query to visualize the results. Each row in the results section represents the average node memory usage within a one-minute time bin.\n",
    "\n",
    "- To ensure easy access, save the query by clicking the **Save** button, then selecting **Save as query**. Choose a descriptive name, and categorize it under **Containers**. Finally, hit the **Save** button.\n",
    "\n",
    "**Log 3: Pods Count with Phase**\n",
    "\n",
    "- Start by creating a new log query by clicking on the **+** button in the top ribbon of the Log Analytics interface. Now, let's focus on monitoring the number of pods in various phases. To do this, choose **List all the pods count with phase** under the **Availability** log queries.\n",
    "\n",
    "- Execute the query to visualize the results. Each row in the results section represents the count number of pods in various phases within a one-minute time bin.\n",
    "\n",
    "- To ensure easy access, save the query by clicking the **Save** button, then selecting **Save as query**. Choose a descriptive name, and categorize it under **Containers**. Finally, hit the **Save** button.\n",
    "\n",
    "**Log 4: Container Logs**\n",
    "\n",
    "- Start by creating a new log query by clicking on the **+** button in the top ribbon of the Log Analytics interface. Now, let's focus on monitoring the occurrence of a specific keyword within container logs. To do this, choose **Find a value in Container Logs Table** under the **Container Logs** log queries. Open this log query using the **Load to editor** option.\n",
    "\n",
    "- Take a look at the query instructions in the query window. You'll need to update the `FindString` value with the desired keyword, which in this case will be `warning`.\n",
    "\n",
    "<p align=center> <img src=images/CustomizeQuery.png width=800 height=175> </p>\n",
    "\n",
    "- Execute the query to visualize the results. Each row in the results section represents an instance where the specific keyword was found in the container logs.\n",
    "\n",
    "- To ensure easy access, save the query by clicking the **Save** button, then selecting **Save as query**. Choose a descriptive name, and categorize it under **Containers**. Finally, hit the **Save** button.\n",
    "\n",
    "**Log 5: Kubernetes Events**\n",
    "\n",
    "- Start by creating a new log query by clicking on the **+** button in the top ribbon of the Log Analytics interface. We'll focus on monitoring Kubernetes events within container logs. To do this, choose **Kubernetes events** under the **Diagnostic** log queries. \n",
    "\n",
    "- Execute the query to visualize the results. Each row in the results section represents an instance where specific Kubernetes events were found in the container logs.\n",
    "\n",
    "- To ensure easy access, save the query by clicking the **Save** button, then selecting **Save as query**. Choose a descriptive name, and categorize it under **Containers**. Finally, hit the **Save** button.\n",
    "\n",
    "#### Step 3: Access Saved Log Queries\n",
    "\n",
    "- In the Log Analytics interface, look for the **Other** category on the left sidebar. Click on this to expand this category and reveal the list of saved queries.\n",
    "\n",
    "- You will find the saved log queries that you created in the previous steps, organized under the appropriate categories you specified during the save process.\n",
    "\n",
    "- Select the relevant query you want to run or analyze. The query will load into the query window for further examination. You can now run the selected query, visualize its results, and perform any necessary analysis.\n",
    "\n",
    "By following these steps, you have gained practical experience in running and saving log queries for your AKS cluster using the Log Analytics workspace. Monitoring logs is essential for several reasons. Logs provide detailed, event-level information about your AKS cluster's operations and can help you identify issues, troubleshoot problems, and ensure compliance with various operational and security standards. \n",
    "\n",
    "Unlike metrics, which provide aggregated data and performance statistics, logs offer a granular view of what's happening within your cluster. This granularity enables you to dig deep into specific events and diagnose problems precisely. Effective log monitoring, in conjunction with metrics, offers a comprehensive approach to managing and maintaining your AKS resources, ensuring optimal performance and enhancing security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alarms\n",
    "\n",
    "Alarms are a fundamental component of any monitoring strategy. They ensure you can detect and address issues promptly, reducing the risk of disruptions and optimizing the performance of your applications.\n",
    "\n",
    "In this section, we'll walk through the process of creating custom alerts based on metrics and insights. We'll define alert conditions, thresholds, and notification methods to help you set up an effective monitoring system for your AKS clusters.\n",
    "\n",
    "The process of setting up alarms includes the following steps:\n",
    "\n",
    "### 1. Define Alert Conditions\n",
    "\n",
    "Setting up alarms involves defining specific alert conditions that determine when an alert should be triggered. These conditions are typically based on various metrics related to your AKS cluster's performance. Let's dive into how you can define these alert conditions in the Azure Portal:\n",
    "\n",
    "- Begin by opening the Alerts homepage for your AKS cluster. This can be accessed under the **Alerts** tab in the **Monitoring** page.\n",
    "\n",
    "- To set up a new alarm, click on the **Alert rules** in the top ribbon of the page. Here, you'll be able to create and manage your alert rules. This should redirect you to the following page:\n",
    "\n",
    "<p align=center> <img src=images/AlertRules.png width=900 height=225> </p>\n",
    "\n",
    "- By default, there are already two alert rules present for **CPU Usage Percentage** and **Memory Working Set Percentage**. The first rules monitors CPU usage and triggers an alert when it exceeds a specified threshold, allowing you to address performance issues caused by high CPU usage. The latter monitors memory usage and sends alerts when it crosses a predefined threshold, helping you maintain sufficient memory resources for your workloads. These serve as a good examples and can be customized to suit your specific monitoring needs.\n",
    "\n",
    "- Click the **+ Create** button to initiate the process of setting up a new alert. You'll be prompted to create a new alert rule. Start by specifying the alert's condition. This condition depends on the metric you want to monitor. For example, if you want to keep an eye on your AKS cluster's disk usage, you can select the appropriate metric (**Disk Used Percentage**) under the **Signal name** field and set your conditions.\n",
    "\n",
    "- Configure the threshold that triggers the alert. For example, let's set the threshold to 90%.\n",
    "\n",
    "- Next, we will need to configure the time settings of the alert rule. The **Check every** determines how often the rule should check for alert conditions. We will set this to 5 minutes, meaning the rule evaluates the conditions every 5 minutes. The **Loopback period** specifies how far back the rule should look when evaluating alert conditions. We will set this to 15 minutes, meaning the alert rule will look back at the last 15 minutes of the data to determine if the conditions are met.\n",
    "\n",
    "<p align=center> <img src=images/ExampleAlertRule.png width=950 height=600> </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Actions Groups\n",
    "\n",
    "> *Action groups* are collections of notification preferences and actions that can be bundled together to form a comprehensive response to an alert.\n",
    "\n",
    "- To create a new action group, click the **+ Create action group** button\n",
    "\n",
    "- Start by configuring the basics: the action group name (provide a name to help you identify its purpose), the display name (for easy reference), the subscription and its resource group\n",
    "\n",
    "<p align=center> <img src=images/ActionGroupBasics.png width=850 height=475> </p>\n",
    "\n",
    "- Choose the notification type(s) you want for this action group. Options include:\n",
    "\n",
    "  - **Email**: Sends notifications via email to designated recipients \n",
    "  - **SMS**: Sends notifications via SMS to mobile devices\n",
    "  - **Push**: Sends push notifications to the Azure mobile app or other configured channels\n",
    "  - **Voice**: Delivers voice call notifications to specified phone numbers\n",
    "  - **Azure Resource Manager Role**: Triggers an Azure Resource Manager role for managing access to resources\n",
    "\n",
    "- For this example I will choose email as the preferred method:\n",
    "\n",
    "<p align=center> <img src=images/EmailNotification.png width=850 height=475> </p>\n",
    "\n",
    "- Optionally, you can configure specific actions when an alert is triggered, in the **Actions** page of the **Create action group**. You can choose from a range of actions, such as integrating webhooks or utilizing Azure Logic Apps or Azure Functions for complex automation. For our example we will skip this step.\n",
    "\n",
    "- Click **Review + create** to review the configured settings, ensuring they align with your alert notification requirements. Once you're satisfied, click the **Create** button to create the action group. \n",
    "\n",
    "Once created, you should be redirected back to the **Create an alert rule** page. To finish the process of creating a new alert rule, fill in the necessary information on the **Details** page, including the alert rule name and description. Finally, review and create your new alert rule.\n",
    "\n",
    "If the alert rule is created successfully, you will find it listed in the alert rules. You may need to click on **Refresh** o ensure the rule appears:\n",
    "\n",
    "\n",
    "<p align=center> <img src=images/NewAlertRules.png width=950 height=250> </p>\n",
    "\n",
    "Once an alert rule is created you can modify it by double-clicking on its name, which will redirect you to the alert rule homepage. Here select **Edit** and you can reconfigure the alert rule as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Responding to Alerts\n",
    "\n",
    "Setting up alarms for your AKS cluster is just the first step in effective monitoring. Once the alerts are in place, it's crucial to have a well-defined response plan to address issues promptly and efficiently. Here are some important aspects to consider when responding to alerts:\n",
    "\n",
    "- **Alert Notifications**: When an alert is triggered, notifications are sent to the designated team or individual. Ensure that these notifications are configured to reach the right people who can take immediate action.\n",
    "\n",
    "- **Acknowledgement and Triage**: Upon receiving an alert, it's essential to acknowledge it promptly. After acknowledgement, perform initial triage to determine the severity of the issue. Some alerts might require immediate action, while others can be part of routine maintenance or troubleshooting.\n",
    "\n",
    "- **Remediation Actions**: Based on the nature of the alert, execute predefined remediation actions. These actions can include scaling resources, restarting containers, or applying configuration changes to mitigate the issue.\n",
    "\n",
    "- **Incident Documentation**: Maintain clear documentation of each alert and the actions taken to resolve it. This documentation is valuable for post-incident analysis and for building a knowledge base.\n",
    "\n",
    "- **Continuous Improvement**: After responding to alerts, conduct post-incident reviews to understand the root cause of the issue and to identify preventive measures. Use these findings to refine your monitoring and alerting strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Log Analytics is an essential tool for writing, testing, and executing log queries. It provides insights into your AKS cluster operations.\n",
    "- Saving log queries in Log Analytics allows for easy access and efficient analysis of AKS cluster logs\n",
    "- Setting up custom alerts for metrics and insights is a fundamental component of any monitoring strategy. Alerts help detect and address issues promptly, reducing the risk of disruptions and optimizing application performance.\n",
    "- Defining specific alert conditions based on relevant metrics is the first step in setting up alarms. Azure Portal provides an interface to configure the alert's condition, threshold, and evaluation settings.\n",
    "- Action groups are collections of notification preferences and actions that define how alerts are handled. These include email, SMS, push, voice, or custom actions. Creating action groups allows for comprehensive alert responses.\n",
    "- A well-defined response plan when alerts are triggered is essential, including notifications, acknowledgment, triage, remediation, documentation, and continuous improvement."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
