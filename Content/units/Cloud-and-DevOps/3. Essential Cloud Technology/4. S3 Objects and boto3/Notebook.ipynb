{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Objects and boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objects are the individual files or data entities that you store within Amazon S3 buckets. They can be anything from text files, images, videos, to database backups or application data. Each object in S3 is uniquely identified by an *object key*, which includes the object's name and its location within the bucket's logical hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Learning about S3 objects and `boto3` has many benefits for working with data in the cloud. It will help you become an expert in using scalable storage, improve how you manage data, build powerful applications, optimize performance and costs, and enhance problem-solving skills. By mastering S3 objects and `boto3`, you will gain valuable skills applicable to different projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Objects to a S3 Bucket\n",
    "\n",
    "Uploading objects to an S3 bucket using the AWS Management Console provides a user-friendly graphical interface to manage your S3 resources. This method is particularly useful for one-off uploads, quick tests, or simple file transfers.\n",
    "\n",
    "Follow this step-by-step walkthrough to upload your first object:\n",
    "\n",
    "1. Make sure you have already created a S3 bucket, where you can upload your objects to. You can use the previously created bucket from the Introduction to Amazon S3 lesson if you'd like.\n",
    "\n",
    "2. Select the desired bucket in the S3 service dashboard and click on the **Upload** button\n",
    "\n",
    "3. In the upload window, click on **Add files** or **Add folder** to select the objects you want to upload from your local machine. This will open up a file explore where you can search your local machine for the desired file.\n",
    "\n",
    "4. Optionally, you can set object properties such as permissions, encryption, and metadata. But for this example we will leave these settings as default.\n",
    "\n",
    "5. Click on **Upload** to initiate the upload process\n",
    "\n",
    "After the upload is complete, if it was successful you should be met with the following window:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/SuccessfullUpload.png\" width=\"900\" height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "###  Error handling and troubleshooting\n",
    "\n",
    "If you encounter any errors or issues during the upload process, you can:\n",
    "1. Check the error messages displayed in the AWS Management Console for guidance on the specific problem\n",
    "2. Verify your permissions and ensure you have the necessary permissions to upload objects to the bucket. An upload might fail if your IAM user doesn't have the permissions to upload objects (e.g. read-only permissions).\n",
    "3. Confirm that the object you are uploading adheres to the size limits and naming requirements of S3\n",
    "4. Double-check your network connectivity and ensure you have a stable internet connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Object Naming Conventions\n",
    "\n",
    "Following S3 object naming conventions promotes good data management practices, enhances collaboration, and improves the overall efficiency of working with S3 objects. It ensures that your objects are easily identifiable, searchable, and well-organized, which in turn facilitates data discovery, reduces errors, and simplifies maintenance tasks.\n",
    "\n",
    "Here are some important conventions to follow:\n",
    "- Adopt a consistent and meaningful naming convention for your S3 objects\n",
    "- Choose object names that are descriptive and provide context about the data they represent\n",
    "- Consider including relevant metadata or timestamps in the object names to facilitate easy identification and sorting\n",
    "- Avoid using special characters or spaces in object names to ensure compatibility across different systems and applications\n",
    "- Follow any naming conventions or guidelines specific to your organization or project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with S3 Objects\n",
    "\n",
    "S3 objects are the fundamental entities stored in an S3 bucket. They consist of several components that provide essential information and properties for managing the objects.\n",
    "\n",
    "### S3 Object Data\n",
    "\n",
    "The object data represents the actual content of the uploaded object. You can examine the uploaded object's content to understand its structure, format, and the information it contains. To do this you can simply navigate to the desired object and click the **Download** button, which will download the object on your local machine.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ObjectKey.png\" width=\"900\" height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "### S3 Object URI\n",
    "\n",
    "An *S3 URI (Uniform Resource Identifier)* is a string used to identify and reference objects stored in Amazon S3. An S3 URI typically consists of the `s3://` scheme followed by the bucket name and object key, separated by a forward slash (`/`).\n",
    "\n",
    "For example, our S3 URI looks like `s3://my-first-bucket-maya/cloud-meme.jpeg`, where `my-first-bucket-maya` is the name of the S3 bucket and `cloud-meme.jpeg` is the unique identifier of the object within the bucket.\n",
    "\n",
    "S3 URIs are used in various contexts, such as specifying source or destination locations for S3 operations, accessing objects programmatically, or constructing object URLs.\n",
    "\n",
    "### Entity Tag (ETag)\n",
    "\n",
    "The *entity tag*, commonly known as ETag, is a unique identifier associated with an S3 object.\n",
    "\n",
    "By default, the ETag for an object is the MD5 hash (widely used cryptographic algorithm that generates a fixed-size, 128-bit (16-byte) hash value from input data of any size) of its content. However, for objects uploaded using the multipart upload API, the ETag represents a concatenation of the MD5 hashes of each uploaded part, followed by a hyphen and the total number of parts.\n",
    "\n",
    "ETags are primarily used for integrity checks. They allow you to verify that the content of an object remains unchanged during transit or storage. \n",
    "\n",
    "### Object URL\n",
    "\n",
    "An *object URL* provides a direct web address to access an S3 object via HTTP or HTTPS. An object URL typically follows the pattern `https://s3.amazonaws.com/bucket-name/object-key` or `https://bucket-name.s3.amazonaws.com/object-key`, depending on the region and the specific S3 endpoint.\n",
    "\n",
    "Object URLs allow public or authenticated access to the object based on the bucket and object-level permissions. Access can be restricted by implementing access control policies and setting appropriate permissions. Object URLs are useful for sharing or embedding links to S3 objects, allowing users to download or view the object directly in a web browser or retrieve it programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Object Key\n",
    "\n",
    "> The *S3 object key serves* as a unique identifier for an object within an S3 bucket. \n",
    "\n",
    "To identify an object key, navigate to the appropriate bucket that contains the desired uploaded object. The object key will be displayed in the **Object overview** page.\n",
    "\n",
    "Understanding the object key is crucial for organizing and retrieving objects effectively. The object key defines the full path of the object within the bucket. For our previously uploaded object, the object key is simply the name of the object `cloud-meme.jpeg`.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/CreateFolder.png\" width=\"900\" height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "The object key can also resemble a file path with prefixes and delimiters (`/`) used for folder-like organization. For example if we want to create a folder-like organization within our bucket. To create a folder you will have click **Create folder** and to specify the **Folder name**. Let's now upload a file to this subfolder and look at the object key of this newly uploaded object.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ObjectKeySubfolder.png\" width=\"900\" height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "We can observe the object key contains the file path of the object followed by the `/` delimiter and then the object name. So for this object, the object key includes both the folder path `subfolder/` and the object name `TicketAtHome_idOrder-138595-2.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Object Metadata\n",
    "\n",
    "Object metadata provides additional information about an S3 object. It consists of key-value pairs that describe the object and its properties. Metadata can be useful for various purposes, such as categorizing objects, storing application-specific information, or facilitating data processing workflows.\n",
    "\n",
    "You can visualize the metadata for an object on the object home page under the **Properties** tab by scrolling down the page under and identifying the **Metadata** field.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ObjectMetadata.png\" width=\"900\" height=\"500\"/>\n",
    "</p>\n",
    "\n",
    "Common metadata fields include:\n",
    "\n",
    "- **`Content-Type`**: The `Content-Type` metadata field specifies the type of the object's content, indicating the nature or format of the data. Some common `Content-Type` values include `text/plain` for plain text files, `image/jpeg` for `JPEG` images, `application/json` for `JSON` files, and `application/pdf` for `PDF` documents.\n",
    "\n",
    "- **`Content-Length`**: The `Content-Length` metadata field indicates the size of the object's content in bytes. For example, if an object's `Content-Length` is 1,024 bytes, it signifies that the object is 1 kilobyte in size.\n",
    "\n",
    "- **`Last-Modified`**: The `Last-Modified` metadata field represents the timestamp when the object was last modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Control Policies\n",
    "\n",
    "S3 provides access control policies to define who can access the object and what actions they can perform. Exploring the object-level permissions allows you to ensure proper security and access control for the uploaded object. These can be setup under the **Permissions** tab in the object home page. They are based on ACLs just like we've seen before for buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `boto3`: Python SDK for AWS\n",
    "\n",
    "`boto3` is the official Python SDK (Software Development Kit) provided by AWS for interacting with AWS services, including S3. It offers a high-level, object-oriented API that simplifies the integration and automation of AWS services using Python. It provides a wide range of features and functionalities, enabling developers to manage resources, interact with services, and build scalable applications on AWS.\n",
    "\n",
    "### Installing and Setup\n",
    "\n",
    "Install `boto3` using pip, the Python package installer, by running the following command in your terminal or command prompt: `pip install boto3`. `boto3` has dependencies on the AWS CLI (Command Line Interface) so make sure this is installed as well.\n",
    "\n",
    "### Configuring `boto3` with AWS credentials\n",
    "\n",
    "`boto3` requires valid AWS credentials to authenticate and interact with AWS services. AWS credentials consist of an access key ID and a secret access key. If you followed along the AWS CLI lesson you should have already created an access and secret access key for your IAM administrator user, as well as configure the AWS CLI using `aws configure`. If you have not yet done this, make sure to follow the steps in the CLI lesson before proceeding further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with S3 Objects using `boto3`\n",
    "\n",
    "### Creating a S3 Bucket using `boto3`\n",
    "\n",
    "`boto3` provides a simple interface to create a S3 bucket programmatically. You can use `create_bucket` method of the `s3` client to create a new bucket. You will need to specify the desired bucket name and any additional configuration options as parameters.\n",
    "\n",
    "Let's look at an example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.create_bucket(Bucket='my-boto3-bucket-maya', CreateBucketConfiguration={'LocationConstraint': 'eu-west-1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions outside of `us-east-1` require the appropriate `LocationConstraint` to be specified in order to create the bucket in the desired region, which is why we need the `CreateBucketConfiguration={'LocationConstraint': 'eu-west-1'}` configuration specified.\n",
    "\n",
    "Once the above code ran, I can observe two buckets in my AWS account, one corresponding to the old bucket we have created and the newly created one using `boto3`.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/Boto3Bucket.png\" width=\"900\" height=\"450\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Objects to S3 Buckets\n",
    "\n",
    "`boto3` allows you to upload objects to S3 buckets easily. To do this you can use the `upload_file()` method of the `s3` client to upload a file from your local machine to an S3 bucket. You will need to specify the local file path, the S3 bucket name and the object key as parameters.\n",
    "\n",
    "Let's look at an example code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('/Users/maya/Downloads/cloud-meme.jpeg', 'my-boto3-bucket-maya', '/Users/maya/Downloads/cloud-meme.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, `'/Users/maya/Downloads/cloud-meme.jpeg'` represents the local path to the file I wanted to upload to the S3 bucket, `'my-boto3-bucket-maya'` is the S3 bucket name and `'memes/cloud-meme.jpeg'` is the object key. \n",
    "\n",
    "If we now inspect the `'my-boto3-bucket-maya'`, we can see that running the code above uploaded the desired object to the S3 bucket, and has also create the `memes` folder to which the object was uploaded.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/UploadObjects.png\" width=\"900\" height=\"650\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Objects from S3 Buckets\n",
    "\n",
    "`boto3` enables you to download objects from S3 buckets programmatically. To do this you can use the `download_file()` method of the `s3` client to download an object from an S3 bucket to your local machine. You will need to specify the S3 bucket name and object key, as well as the local file path where the object will be saved.\n",
    "\n",
    "Let's look at an example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('my-boto3-bucket-maya', 'memes/cloud-meme.jpeg', '/Users/maya/Downloads/new-cloud-meme.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, `'my-boto3-bucket-maya'` is the S3 bucket name, `'memes/cloud-meme.jpeg'` is the object key and\n",
    "`'/Users/maya/Downloads/new-cloud-meme.jpeg'` represents the local path at which we want to save the S3 object. \n",
    "\n",
    "If you now check the specified local path, you will be able to notice a new file called `new-cloud-meme.jpeg` saved at that location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying, moving, and deleting S3 objects\n",
    "\n",
    "`boto3` provides methods to perform operations like copying, moving, and deleting S3 objects: \n",
    "- You can use the `copy_object()` method of the `s3` client to copy an object within the same bucket or to a different bucket\n",
    "- Use the `move_object()` method of the `s3` client to move an object within the same bucket or to a different bucket\n",
    "- Use the `delete_object()` method of the `s3` client to delete an object from a bucket\n",
    "\n",
    "An example code would follow a similar structure to the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.copy_object(Bucket='my-bucket', Key='new-folder/file.txt', CopySource='my-bucket/folder/file.txt')\n",
    "s3.move_object(Bucket='my-bucket', Key='new-folder/file.txt', CopySource='my-bucket/folder/file.txt')\n",
    "s3.delete_object(Bucket='my-bucket', Key='folder/file.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Exception Handling with `boto3`\n",
    "\n",
    "### Understanding Common Errors and Exceptions\n",
    "\n",
    "When working with `boto3`, it's important to be aware of common errors and exceptions that can occur during interactions with AWS services.\n",
    "\n",
    "Some of the most common errors are:\n",
    "- `botocore.exceptions.NoCredentialsError`: Raised when valid AWS credentials are not found\n",
    "- `botocore.exceptions.ParamValidationError`: Raised when input parameters provided to `boto3` methods are invalid or do not meet the required constraints\n",
    "- `botocore.exceptions.ClientError`: A general exception representing errors returned by the AWS service. It includes information such as the HTTP status code, error code, and error message.\n",
    "\n",
    "### Implementing Error Handling Strategies in `boto3`\n",
    "\n",
    "Proper error handling is crucial for handling exceptions and failures when using `boto3`. One common strategy is to  wrap your `boto3` code in a `try`-`except` block to catch and handle specific exceptions that may occur during execution.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "try:\n",
    "    # Boto3 code that may raise exceptions\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    \n",
    "    # Process the response or perform other operations\n",
    "    print(response)\n",
    "\n",
    "except NoCredentialsError:\n",
    "    print(\"AWS credentials not found. Please configure your credentials.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchBucket':\n",
    "        print(\"The specified bucket does not exist.\")\n",
    "    else:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `NoCredentialsError`: This exception is raised when valid AWS credentials are not found or provided. The code catches this exception and prints a message instructing the user to configure their credentials.\n",
    "- `ClientError`: This exception represents errors returned by the AWS service. The code catches this exception and checks the error code. If the error code is `NoSuchBucket`, indicating that the specified bucket does not exist, it prints a message to inform the user. For other error codes, a generic error message is printed along with the exception instance.\n",
    "\n",
    "By understanding common errors and exceptions and implementing appropriate error handling strategies, you can gracefully handle exceptions, handle failures, and ensure robustness in your applications that interact with AWS services. Proper error handling improves the overall reliability and resilience of your `boto3`-based applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources for Further Learning\n",
    "\n",
    "To continue expanding your knowledge and skills in working with S3 objects and `boto3`, here are some resources for further learning:\n",
    "- [AWS S3 Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)\n",
    "- [AWS Boto3 Documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "\n",
    "These resources provide comprehensive documentation, tutorials, guides, and training materials to help you deepen your understanding of S3 and `boto3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Key Takeaways\n",
    "\n",
    "- S3 objects are the fundamental entities stored in Amazon S3, consisting of object data, object key, metadata, and optional versioning\n",
    "- S3 object naming conventions should be adopted to ensure readability, searchability, and proper organization of objects within buckets\n",
    "- The object key is a unique identifier for S3 objects and plays a significant role in retrieving and managing objects\n",
    "- Object metadata provides additional information about objects and can be used for various purposes such as indexing and categorization\n",
    "- `boto3`, the Python SDK for AWS, is a powerful tool for interacting with S3 and performing various operations on S3 objects programmatically\n",
    "- Error handling and exception handling are important when working with S3 and `boto3`. Proper error handling strategies help to handle exceptions gracefully and improve application reliability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
