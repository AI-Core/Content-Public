[
  {
    "task_id": "63f505f6d0be22b17b72f398",
    "created_at": "2023-02-21T17:57:10.272Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How should I train for a marathon "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d0e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.208Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "serovmari@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505f6d0be22b17b72f39a",
    "created_at": "2023-02-21T17:57:10.293Z",
    "completed_at": "2023-02-21T18:04:46.609Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Names of coding languages \n- Pyhton \n- C#\n- React"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "- Go\n- Ruby\n- Java\n- Javascript\n- C++"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d0d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:46.976Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Go\n- Ruby\n- Java\n- Javascript\n- C++"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 113.916,
        "totalTimeSpentSecs": 113.916,
        "attemptedAt": "2023-02-21T18:04:44.011Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507bc26649ae1699d6799",
        "createdAt": "2023-02-21T18:04:44.011Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Go\n- Ruby\n- Java\n- Javascript\n- C++"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f399",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:04:17.901Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Describe yourself? "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "i am a student from oxford studying computer science"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d38",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:18.350Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i am a student from oxford studying computer science"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 22.868,
        "totalTimeSpentSecs": 22.868,
        "attemptedAt": "2023-02-21T18:04:14.947Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5079f26649ae1699d6648",
        "createdAt": "2023-02-21T18:04:14.947Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i am a student from oxford studying computer science"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f39e",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:04:26.316Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the latest biggest advancement in AI?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Regulations"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d3a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:26.815Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Regulations"
              ]
            }
          }
        },
        "attemptedBy": "alona@everyrun.world",
        "activeTimeSpentSecs": 15.738,
        "totalTimeSpentSecs": 15.738,
        "attemptedAt": "2023-02-21T18:04:23.332Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507a7f1e318af9121b770",
        "createdAt": "2023-02-21T18:04:23.332Z",
        "source": "tasker",
        "taskerId": "alona@everyrun.world",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Regulations"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f39f",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:04:27.362Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best company to work for?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Company with more salary and with good promotion expection."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d1f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:27.791Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Company with more salary and with good promotion expection."
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 94.432,
        "totalTimeSpentSecs": 94.432,
        "attemptedAt": "2023-02-21T18:04:24.292Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507a88773e06651209ff3",
        "createdAt": "2023-02-21T18:04:24.292Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Company with more salary and with good promotion expection."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f397",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:05:40.590Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "what is the Lawis structure of C2O "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "2 double bonds between the carbon and oxygen atoms"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d0b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:40.940Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "2 double bonds between the carbon and oxygen atoms"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:05:37.583Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507f1d3e8b3858f40843f",
        "createdAt": "2023-02-21T18:05:37.583Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "2 double bonds between the carbon and oxygen atoms"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f39d",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:03:50.026Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Will there be a Titanic 2?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "i hope so\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d1c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:03:50.433Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i hope so\n"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 50.8,
        "totalTimeSpentSecs": 50.8,
        "attemptedAt": "2023-02-21T18:03:47.256Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507831c2577791c51817c",
        "createdAt": "2023-02-21T18:03:47.256Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i hope so\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f39c",
    "created_at": "2023-02-21T17:57:10.294Z",
    "completed_at": "2023-02-21T18:08:24.303Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Translation pairs"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Translation pairs are pairs of words in different languages which are each other's translation."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d16",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:24.678Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Translation pairs are pairs of words in different languages which are each other's translation."
              ]
            }
          }
        },
        "attemptedBy": "esteban.gomezllata@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:08:21.217Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50895d3e8b3858f408583",
        "createdAt": "2023-02-21T18:08:21.217Z",
        "source": "tasker",
        "taskerId": "esteban.gomezllata@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Translation pairs are pairs of words in different languages which are each other's translation."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f396",
    "created_at": "2023-02-21T17:57:10.294Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Image pairs"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d0c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:40.024Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "nauynix@gmail.com",
        "attemptedAt": "2023-02-21T18:04:40.336Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507b84691a7415f5bb553",
        "createdAt": "2023-02-21T18:04:40.336Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f6d0be22b17b72f39b",
    "created_at": "2023-02-21T17:57:10.294Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "write a poem about ChatGPT classes"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d13",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:32.316Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "yarong.li@magd.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:05:36.295Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507f05930b36953f154b5",
        "createdAt": "2023-02-21T18:05:36.295Z",
        "source": "tasker",
        "taskerId": "yarong.li@magd.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407715",
    "created_at": "2023-02-21T17:57:10.325Z",
    "completed_at": "2023-02-21T18:05:04.190Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Trinity Oriel New St Peters"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "are colleges of Oxford"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5efa",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:04.804Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "are colleges of Oxford"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 17.31,
        "totalTimeSpentSecs": 17.31,
        "attemptedAt": "2023-02-21T18:04:59.339Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507cb9c5b088d891180cb",
        "createdAt": "2023-02-21T18:04:59.339Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "are colleges of Oxford"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407710",
    "created_at": "2023-02-21T17:57:10.325Z",
    "completed_at": "2023-02-21T18:04:45.695Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "To produce images."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "You need lots of data"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5efd",
    "project_param_version": 2,
    "assignedSession": null,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:46.094Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "You need lots of data"
              ]
            }
          }
        },
        "attemptedBy": "alona@everyrun.world",
        "activeTimeSpentSecs": 15.9,
        "totalTimeSpentSecs": 15.9,
        "attemptedAt": "2023-02-21T18:04:42.943Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507bb5ec05d1869c363a2",
        "createdAt": "2023-02-21T18:04:42.943Z",
        "source": "tasker",
        "taskerId": "alona@everyrun.world",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "You need lots of data"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407713",
    "created_at": "2023-02-21T17:57:10.325Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write a story about going to space"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ef5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:26.536Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:06:26.669Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50822af5e808d11998b5b",
        "createdAt": "2023-02-21T18:06:26.669Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f40770f",
    "created_at": "2023-02-21T17:57:10.325Z",
    "completed_at": "2023-02-21T18:11:30.805Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "red blue green"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "red"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ef7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:31.276Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "red"
              ]
            }
          }
        },
        "attemptedBy": "alona@everyrun.world",
        "activeTimeSpentSecs": 23.535,
        "totalTimeSpentSecs": 403.531,
        "attemptedAt": "2023-02-21T18:11:27.912Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50950a32fb0c753755716",
        "createdAt": "2023-02-21T18:11:27.912Z",
        "source": "tasker",
        "taskerId": "alona@everyrun.world",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "red"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407716",
    "created_at": "2023-02-21T17:57:10.325Z",
    "completed_at": "2023-02-21T18:04:42.645Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Talk in different languages."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "sorry i can only speak english"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f00",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:43.113Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "sorry i can only speak english"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 22.251,
        "totalTimeSpentSecs": 22.251,
        "attemptedAt": "2023-02-21T18:04:40.001Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507b826649ae1699d66f2",
        "createdAt": "2023-02-21T18:04:40.001Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "sorry i can only speak english"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407714",
    "created_at": "2023-02-21T17:57:10.325Z",
    "completed_at": "2023-02-21T18:04:57.792Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "猫 - cat; 机器 - machine; chatGPT - ?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "chatbot"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f1c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:04:58.195Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "chatbot"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 12.133,
        "totalTimeSpentSecs": 12.133,
        "attemptedAt": "2023-02-21T18:04:53.735Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507c6d0be22b17b7311ab",
        "createdAt": "2023-02-21T18:04:53.735Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "chatbot"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407712",
    "created_at": "2023-02-21T17:57:10.326Z",
    "completed_at": "2023-02-21T18:05:07.480Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "I am going to "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "the lecture"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5eff",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:08.088Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the lecture"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 9.402,
        "totalTimeSpentSecs": 9.402,
        "attemptedAt": "2023-02-21T18:05:04.503Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507d09519eb9f87914379",
        "createdAt": "2023-02-21T18:05:04.503Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the lecture"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407718",
    "created_at": "2023-02-21T17:57:10.326Z",
    "completed_at": "2023-02-21T18:06:30.789Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1 + 1 = 10; 11 + 101 = 1000; 11 + 11 = ?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "110"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f17",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:31.171Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "110"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 93.974,
        "totalTimeSpentSecs": 93.974,
        "attemptedAt": "2023-02-21T18:06:27.902Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5082461520d8224db8079",
        "createdAt": "2023-02-21T18:06:27.902Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "110"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407717",
    "created_at": "2023-02-21T17:57:10.326Z",
    "completed_at": "2023-02-21T18:05:07.611Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1. English is hard. 2. Math is easy. 3. Literature is "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "abstract"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f1a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:08.166Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "abstract"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 19.32,
        "totalTimeSpentSecs": 19.32,
        "attemptedAt": "2023-02-21T18:05:04.876Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507d1d0be22b17b731249",
        "createdAt": "2023-02-21T18:05:04.876Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "abstract"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f6d3e8b3858f407711",
    "created_at": "2023-02-21T17:57:10.350Z",
    "completed_at": "2023-02-21T18:05:37.295Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What does a tree look like?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Brown and tall"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ef3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:37.754Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Brown and tall"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 32.874,
        "totalTimeSpentSecs": 32.874,
        "attemptedAt": "2023-02-21T18:05:34.082Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507ee8773e0665120a0a5",
        "createdAt": "2023-02-21T18:05:34.082Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Brown and tall"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e2a",
    "created_at": "2023-02-21T17:57:10.374Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What makes a certain college better than others at Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:24:46:2",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f1502eba387ff73fd19511",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:09.733Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:05:10.185Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507d66a984b51c5db10bd",
        "createdAt": "2023-02-21T18:05:10.185Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e2e",
    "created_at": "2023-02-21T17:57:10.374Z",
    "completed_at": "2023-02-21T18:05:40.394Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me a story about the best lecture ever hosted at Oxford"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:16:36:3",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Once upon a time"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f14e44df05321572cb94e8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:40.777Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Once upon a time"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 29.638,
        "totalTimeSpentSecs": 29.638,
        "attemptedAt": "2023-02-21T18:05:37.553Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507f10e8a007b9e0a419e",
        "createdAt": "2023-02-21T18:05:37.553Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Once upon a time"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e1f",
    "created_at": "2023-02-21T17:57:10.374Z",
    "completed_at": "2023-02-21T18:05:56.393Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In what year was Oxford University founded?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:16:36:1",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "no idea"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f14e4477ee1d15933ab6c4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:56.816Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 47.146,
        "totalTimeSpentSecs": 47.146,
        "attemptedAt": "2023-02-21T18:05:53.251Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50801d59f07ddf7d9bb6c",
        "createdAt": "2023-02-21T18:05:53.251Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e20",
    "created_at": "2023-02-21T17:57:10.374Z",
    "completed_at": "2023-02-21T18:07:02.869Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The best reasons to study at Oxford university:\n- Full of culture\n- Attracts great people\n- Excellent staff"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:16:36:4",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": " - Nice living environment\n - Excellent Classmates"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f14e4542d725a01bb09854",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:03.459Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                " - Nice living environment\n - Excellent Classmates"
              ]
            }
          }
        },
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "activeTimeSpentSecs": 112.509,
        "totalTimeSpentSecs": 112.509,
        "attemptedAt": "2023-02-21T18:06:59.987Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50844a32fb0c75375527d",
        "createdAt": "2023-02-21T18:06:59.987Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                " - Nice living environment\n - Excellent Classmates"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e2d",
    "created_at": "2023-02-21T17:57:10.393Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me a story about the best lecture ever hosted at Oxford"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:3",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e61a768060d5b05a19",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:05:15.336Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:05:15.537Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f507dbbc063c0150402e43",
        "createdAt": "2023-02-21T18:05:15.537Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e24",
    "created_at": "2023-02-21T17:57:10.393Z",
    "completed_at": "2023-02-21T18:08:45.581Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In what year was Oxford University founded?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:24:46:1",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "1096\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f1502e2a0f11566b8ef734",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:45.963Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "1096\n"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 205.679,
        "totalTimeSpentSecs": 205.679,
        "attemptedAt": "2023-02-21T18:08:42.817Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508abd59f07ddf7d9bdeb",
        "createdAt": "2023-02-21T18:08:42.817Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "1096\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e2c",
    "created_at": "2023-02-21T17:57:10.408Z",
    "completed_at": "2023-02-21T18:06:02.054Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The best reasons to study at Oxford university:\n- Full of culture\n- Attracts great people\n- Excellent staff"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:24:46:4",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Nice colleges"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f1502f7300ad21793d135c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:02.763Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Nice colleges"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 22.725,
        "totalTimeSpentSecs": 22.725,
        "attemptedAt": "2023-02-21T18:05:58.980Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50807a32fb0c75375512d",
        "createdAt": "2023-02-21T18:05:58.980Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Nice colleges"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e23",
    "created_at": "2023-02-21T17:57:10.408Z",
    "completed_at": "2023-02-21T18:06:30.365Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me a story about the best lecture ever hosted at Oxford"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:24:46:3",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "There is only one correct answer, Harry Berg AICore!\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f1502fa3d427aa43dd9824",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:30.779Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "There is only one correct answer, Harry Berg AICore!\n"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 51.579,
        "totalTimeSpentSecs": 51.579,
        "attemptedAt": "2023-02-21T18:06:27.511Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50823f1e318af9121b924",
        "createdAt": "2023-02-21T18:06:27.511Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "There is only one correct answer, Harry Berg AICore!\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e21",
    "created_at": "2023-02-21T17:57:10.408Z",
    "completed_at": "2023-02-21T18:06:30.040Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What makes a certain college better than others at Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-18 22:16:36:2",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "If the provide good social events"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f14e44b2d68e48c8d12905",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:30.476Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "If the provide good social events"
              ]
            }
          }
        },
        "attemptedBy": "peyton.hammersley@gmail.com",
        "activeTimeSpentSecs": 52.729,
        "totalTimeSpentSecs": 52.729,
        "attemptedAt": "2023-02-21T18:06:27.338Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508230c3f67c99e3b5c55",
        "createdAt": "2023-02-21T18:06:27.338Z",
        "source": "tasker",
        "taskerId": "peyton.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "If the provide good social events"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f66b393c18cb6b4e2b",
    "created_at": "2023-02-21T17:57:10.426Z",
    "completed_at": "2023-02-21T18:06:09.512Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What does GPT stand for?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:6",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "GPT stands for \"Generative Pre-trained Transformer\"."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e67e1519de2a638c9f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:10.001Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "GPT stands for \"Generative Pre-trained Transformer\"."
              ]
            }
          }
        },
        "attemptedBy": "yarong.li@magd.ox.ac.uk",
        "activeTimeSpentSecs": 28.018,
        "totalTimeSpentSecs": 28.018,
        "attemptedAt": "2023-02-21T18:06:06.287Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5080ef1e318af9121b87c",
        "createdAt": "2023-02-21T18:06:06.287Z",
        "source": "tasker",
        "taskerId": "yarong.li@magd.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "GPT stands for \"Generative Pre-trained Transformer\"."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f601",
    "created_at": "2023-02-21T17:57:11.766Z",
    "completed_at": "2023-02-21T18:06:59.496Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me how to learn about how chatgpt works"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Your best bet is probably online resources. To start learning about the structure, you probably want to find out about transformer models"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ef0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:59.909Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Your best bet is probably online resources. To start learning about the structure, you probably want to find out about transformer models"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:06:56.691Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50840d59f07ddf7d9bc18",
        "createdAt": "2023-02-21T18:06:56.691Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Your best bet is probably online resources. To start learning about the structure, you probably want to find out about transformer models"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f602",
    "created_at": "2023-02-21T17:57:11.785Z",
    "completed_at": "2023-02-21T18:06:07.323Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Red, Green, Blue, Orange"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Purple, Pink, Yellow, Indigo"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ed2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:07.752Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Purple, Pink, Yellow, Indigo"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 24.522,
        "totalTimeSpentSecs": 24.522,
        "attemptedAt": "2023-02-21T18:06:04.566Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5080c1c2577791c518392",
        "createdAt": "2023-02-21T18:06:04.566Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Purple, Pink, Yellow, Indigo"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f603",
    "created_at": "2023-02-21T17:57:11.801Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "There was a big tree in a field that fell down and"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ee2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:08.321Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "tomer.amir.mba22@said.oxford.edu",
        "attemptedAt": "2023-02-21T18:06:08.419Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50810808802c9afed2eac",
        "createdAt": "2023-02-21T18:06:08.419Z",
        "source": "tasker",
        "taskerId": "tomer.amir.mba22@said.oxford.edu",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f62a",
    "created_at": "2023-02-21T17:57:11.901Z",
    "completed_at": "2023-02-21T18:06:35.563Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write an essay on the history and gastronomy of the use of potatoes in world cuisine."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "sorry i don't know, maybe potatoes are first found in the us"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ecf",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:35.949Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "sorry i don't know, maybe potatoes are first found in the us"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 38.235,
        "totalTimeSpentSecs": 38.235,
        "attemptedAt": "2023-02-21T18:06:32.836Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50829374fa3f6e4b31dcc",
        "createdAt": "2023-02-21T18:06:32.836Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "sorry i don't know, maybe potatoes are first found in the us"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f407986",
    "created_at": "2023-02-21T17:57:12.013Z",
    "completed_at": "2023-02-21T18:08:13.602Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Fish rhymes with"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "niche"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b407a47014fa4a5fd4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:14.050Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "niche"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 134.055,
        "totalTimeSpentSecs": 134.055,
        "attemptedAt": "2023-02-21T18:08:10.627Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5088a0e8a007b9e0a438e",
        "createdAt": "2023-02-21T18:08:10.627Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "niche"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f649",
    "created_at": "2023-02-21T17:57:12.013Z",
    "completed_at": "2023-02-21T18:06:48.272Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Extend \"The industrial revolution and its consequences\"."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "have profound impact on the middle-class and increased inequality "
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ec5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:48.611Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "have profound impact on the middle-class and increased inequality "
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 44.566,
        "totalTimeSpentSecs": 44.566,
        "attemptedAt": "2023-02-21T18:06:45.300Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5083526649ae1699d68ae",
        "createdAt": "2023-02-21T18:06:45.300Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "have profound impact on the middle-class and increased inequality "
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f643",
    "created_at": "2023-02-21T17:57:12.014Z",
    "completed_at": "2023-02-21T18:06:52.430Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "- Cycling\n- Running\n- Swimming"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Playing Football"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ecd",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:52.887Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Playing Football"
              ]
            }
          }
        },
        "attemptedBy": "yarong.li@magd.ox.ac.uk",
        "activeTimeSpentSecs": 40.469,
        "totalTimeSpentSecs": 40.469,
        "attemptedAt": "2023-02-21T18:06:49.408Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508396ab6e930f1816416",
        "createdAt": "2023-02-21T18:06:49.408Z",
        "source": "tasker",
        "taskerId": "yarong.li@magd.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Playing Football"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f646",
    "created_at": "2023-02-21T17:57:12.014Z",
    "completed_at": "2023-02-21T18:06:52.902Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me about ChatGPT"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "ChatGPT is a NLP model that provides answer to question "
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5eca",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:53.264Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ChatGPT is a NLP model that provides answer to question "
              ]
            }
          }
        },
        "attemptedBy": "tomer.amir.mba22@said.oxford.edu",
        "activeTimeSpentSecs": 40.478,
        "totalTimeSpentSecs": 40.478,
        "attemptedAt": "2023-02-21T18:06:49.999Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5083a943d35f0058c6f02",
        "createdAt": "2023-02-21T18:06:49.999Z",
        "source": "tasker",
        "taskerId": "tomer.amir.mba22@said.oxford.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ChatGPT is a NLP model that provides answer to question "
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f647",
    "created_at": "2023-02-21T17:57:12.014Z",
    "completed_at": "2023-02-21T18:10:00.559Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What changes should the Australian cricket team make (if any) to combat Ashwin and Jadeja's bowling in the ongoing Border-Gavaskar Trophy?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Develop a better strategy: The Australian team should devise a well-planned and effective strategy against spin bowling. They should study Ashwin and Jadeja's bowling style, identify their strengths and weaknesses, and accordingly devise a plan to tackle them.\n\nImprove footwork: Facing spin bowling requires excellent footwork, and the Australian team should focus on improving their footwork. They should practice playing the spinners with decisive footwork, both forward and back.\n\nPlay spinners with a positive mindset: The Australian batsmen should play the spinners with a positive mindset and look to score runs off their bowling rather than just surviving. They should not allow the spinners to settle into a rhythm and dictate terms.\n\nPractice against quality spin bowling: The Australian team should simulate match-like situations in their training sessions and practice against quality spin bowling. They can also use video analysis to identify areas of improvement and work on them.\n\nBe patient: Facing quality spin bowling requires patience and concentration, and the Australian team should be prepared to bat for long periods without scoring runs. They should be willing to rotate the strike and wait for the loose deliveries to score runs.\n\nUse sweep shots: The sweep shot is an effective way to counter spin bowling, and the Australian team should practice playing the sweep shot against spinners. The sweep shot can put pressure on the spinners and also score runs."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ec8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:00.920Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Develop a better strategy: The Australian team should devise a well-planned and effective strategy against spin bowling. They should study Ashwin and Jadeja's bowling style, identify their strengths and weaknesses, and accordingly devise a plan to tackle them.\n\nImprove footwork: Facing spin bowling requires excellent footwork, and the Australian team should focus on improving their footwork. They should practice playing the spinners with decisive footwork, both forward and back.\n\nPlay spinners with a positive mindset: The Australian batsmen should play the spinners with a positive mindset and look to score runs off their bowling rather than just surviving. They should not allow the spinners to settle into a rhythm and dictate terms.\n\nPractice against quality spin bowling: The Australian team should simulate match-like situations in their training sessions and practice against quality spin bowling. They can also use video analysis to identify areas of improvement and work on them.\n\nBe patient: Facing quality spin bowling requires patience and concentration, and the Australian team should be prepared to bat for long periods without scoring runs. They should be willing to rotate the strike and wait for the loose deliveries to score runs.\n\nUse sweep shots: The sweep shot is an effective way to counter spin bowling, and the Australian team should practice playing the sweep shot against spinners. The sweep shot can put pressure on the spinners and also score runs."
              ]
            }
          }
        },
        "attemptedBy": "clairezwj@gmail.com",
        "activeTimeSpentSecs": 134.95,
        "totalTimeSpentSecs": 215.245,
        "attemptedAt": "2023-02-21T18:09:57.693Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508f56b393c18cb6b69db",
        "createdAt": "2023-02-21T18:09:57.693Z",
        "source": "tasker",
        "taskerId": "clairezwj@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Develop a better strategy: The Australian team should devise a well-planned and effective strategy against spin bowling. They should study Ashwin and Jadeja's bowling style, identify their strengths and weaknesses, and accordingly devise a plan to tackle them.\n\nImprove footwork: Facing spin bowling requires excellent footwork, and the Australian team should focus on improving their footwork. They should practice playing the spinners with decisive footwork, both forward and back.\n\nPlay spinners with a positive mindset: The Australian batsmen should play the spinners with a positive mindset and look to score runs off their bowling rather than just surviving. They should not allow the spinners to settle into a rhythm and dictate terms.\n\nPractice against quality spin bowling: The Australian team should simulate match-like situations in their training sessions and practice against quality spin bowling. They can also use video analysis to identify areas of improvement and work on them.\n\nBe patient: Facing quality spin bowling requires patience and concentration, and the Australian team should be prepared to bat for long periods without scoring runs. They should be willing to rotate the strike and wait for the loose deliveries to score runs.\n\nUse sweep shots: The sweep shot is an effective way to counter spin bowling, and the Australian team should practice playing the sweep shot against spinners. The sweep shot can put pressure on the spinners and also score runs."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f64a",
    "created_at": "2023-02-21T17:57:12.014Z",
    "completed_at": "2023-02-21T18:06:26.904Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "water, orange juice, vodka"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Gin, Absinthe, Moonshine"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ec2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:27.304Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Gin, Absinthe, Moonshine"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 18.029,
        "totalTimeSpentSecs": 18.029,
        "attemptedAt": "2023-02-21T18:06:23.998Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508209c5b088d891181d2",
        "createdAt": "2023-02-21T18:06:23.998Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Gin, Absinthe, Moonshine"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d0be22b17b72f64c",
    "created_at": "2023-02-21T17:57:12.025Z",
    "completed_at": "2023-02-21T18:07:15.306Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1, 3, 6, 10"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": ", 15, 21, 28, 36, 45, 55, 66"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ec1",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:15.700Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                ", 15, 21, 28, 36, 45, 55, 66"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 46.946,
        "totalTimeSpentSecs": 46.946,
        "attemptedAt": "2023-02-21T18:07:12.708Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508515ec05d1869c3664e",
        "createdAt": "2023-02-21T18:07:12.708Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                ", 15, 21, 28, 36, 45, 55, 66"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f407992",
    "created_at": "2023-02-21T17:57:12.058Z",
    "completed_at": "2023-02-21T18:08:23.969Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give an overview of the current state-of-the-art Reinforcement Learning algorithms and how they compare with each other."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Deep Q-Networks (DQN): DQN is a value-based RL algorithm that combines Q-learning with deep neural networks. It was introduced by Google DeepMind in 2015 and has been successfully applied in various tasks such as playing Atari games and controlling robotic systems.\n\nPolicy Gradient Methods: Policy Gradient methods are a family of RL algorithms that directly optimize the policy of the agent, without computing the value function explicitly. These methods use gradient descent to update the policy parameters and have been shown to be effective in complex tasks, such as playing games with high-dimensional action spaces.\n\nActor-Critic Methods: Actor-Critic methods combine the strengths of both policy-based and value-based methods by having two separate networks, one for the policy (the actor) and one for the value function (the critic). These methods have been shown to be effective in continuous control tasks, such as robotic manipulation and locomotion.\n\nModel-based Reinforcement Learning: Model-based RL algorithms learn a model of the environment and then use this model to plan actions. These algorithms can be more sample efficient than model-free algorithms, but are often harder to scale to large, complex environments.\n\nModel-free off-policy RL: Recent work has focused on combining the sample efficiency of model-based RL with the scalability of model-free methods. These methods use off-policy learning to learn from past experiences, and can be more sample efficient than purely model-free methods."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b407a47014fa4a5fd2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:24.374Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Deep Q-Networks (DQN): DQN is a value-based RL algorithm that combines Q-learning with deep neural networks. It was introduced by Google DeepMind in 2015 and has been successfully applied in various tasks such as playing Atari games and controlling robotic systems.\n\nPolicy Gradient Methods: Policy Gradient methods are a family of RL algorithms that directly optimize the policy of the agent, without computing the value function explicitly. These methods use gradient descent to update the policy parameters and have been shown to be effective in complex tasks, such as playing games with high-dimensional action spaces.\n\nActor-Critic Methods: Actor-Critic methods combine the strengths of both policy-based and value-based methods by having two separate networks, one for the policy (the actor) and one for the value function (the critic). These methods have been shown to be effective in continuous control tasks, such as robotic manipulation and locomotion.\n\nModel-based Reinforcement Learning: Model-based RL algorithms learn a model of the environment and then use this model to plan actions. These algorithms can be more sample efficient than model-free algorithms, but are often harder to scale to large, complex environments.\n\nModel-free off-policy RL: Recent work has focused on combining the sample efficiency of model-based RL with the scalability of model-free methods. These methods use off-policy learning to learn from past experiences, and can be more sample efficient than purely model-free methods."
              ]
            }
          }
        },
        "attemptedBy": "peyton.hammersley@gmail.com",
        "activeTimeSpentSecs": 112.618,
        "totalTimeSpentSecs": 112.618,
        "attemptedAt": "2023-02-21T18:08:21.239Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508957c3dd08602d64a91",
        "createdAt": "2023-02-21T18:08:21.239Z",
        "source": "tasker",
        "taskerId": "peyton.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Deep Q-Networks (DQN): DQN is a value-based RL algorithm that combines Q-learning with deep neural networks. It was introduced by Google DeepMind in 2015 and has been successfully applied in various tasks such as playing Atari games and controlling robotic systems.\n\nPolicy Gradient Methods: Policy Gradient methods are a family of RL algorithms that directly optimize the policy of the agent, without computing the value function explicitly. These methods use gradient descent to update the policy parameters and have been shown to be effective in complex tasks, such as playing games with high-dimensional action spaces.\n\nActor-Critic Methods: Actor-Critic methods combine the strengths of both policy-based and value-based methods by having two separate networks, one for the policy (the actor) and one for the value function (the critic). These methods have been shown to be effective in continuous control tasks, such as robotic manipulation and locomotion.\n\nModel-based Reinforcement Learning: Model-based RL algorithms learn a model of the environment and then use this model to plan actions. These algorithms can be more sample efficient than model-free algorithms, but are often harder to scale to large, complex environments.\n\nModel-free off-policy RL: Recent work has focused on combining the sample efficiency of model-based RL with the scalability of model-free methods. These methods use off-policy learning to learn from past experiences, and can be more sample efficient than purely model-free methods."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f407993",
    "created_at": "2023-02-21T17:57:12.072Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give a succinct overview of the progress of research on the P equals NP problem."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b407a47014fa4a5fd0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:45.915Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:06:46.138Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50836e07bd9366fb8a603",
        "createdAt": "2023-02-21T18:06:46.138Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f40799f",
    "created_at": "2023-02-21T17:57:12.086Z",
    "completed_at": "2023-02-21T18:06:52.087Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Dog rhymes with"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "log\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b407a47014fa4a5fc7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:06:52.488Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "log\n"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 20.223,
        "totalTimeSpentSecs": 20.223,
        "attemptedAt": "2023-02-21T18:06:49.069Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50839a32fb0c7537551d6",
        "createdAt": "2023-02-21T18:06:49.069Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "log\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f40799c",
    "created_at": "2023-02-21T17:57:12.104Z",
    "completed_at": "2023-02-21T18:07:12.406Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Orange rhymes with"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "hinge"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b407a47014fa4a5fcc",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:12.830Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "hinge"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 40.453,
        "totalTimeSpentSecs": 40.453,
        "attemptedAt": "2023-02-21T18:07:09.679Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5084d90b7131187140239",
        "createdAt": "2023-02-21T18:07:09.679Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "hinge"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f4079a0",
    "created_at": "2023-02-21T17:57:12.104Z",
    "completed_at": "2023-02-21T18:07:29.522Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Today I'm feeling like"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "doing anything"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fb0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:29.955Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "doing anything"
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 39.037,
        "totalTimeSpentSecs": 39.037,
        "attemptedAt": "2023-02-21T18:07:26.330Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5085e6b393c18cb6b689e",
        "createdAt": "2023-02-21T18:07:26.330Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "doing anything"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f4079a3",
    "created_at": "2023-02-21T17:57:12.104Z",
    "completed_at": "2023-02-21T18:07:03.864Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Summarize the novel \"War and Peace\" by Tolstoi."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "no idea"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fac",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:04.338Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 26.427,
        "totalTimeSpentSecs": 26.427,
        "attemptedAt": "2023-02-21T18:07:00.763Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50845d0be22b17b73134b",
        "createdAt": "2023-02-21T18:07:00.763Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f4079a1",
    "created_at": "2023-02-21T17:57:12.115Z",
    "completed_at": "2023-02-21T18:07:05.121Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Prove that pi is transcendental."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "I dont know how to do this\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fad",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:05.531Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "I dont know how to do this\n"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 11.58,
        "totalTimeSpentSecs": 11.58,
        "attemptedAt": "2023-02-21T18:07:02.038Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508465ec05d1869c365ae",
        "createdAt": "2023-02-21T18:07:02.038Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "I dont know how to do this\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f7d3e8b3858f4079a4",
    "created_at": "2023-02-21T17:57:12.115Z",
    "completed_at": "2023-02-21T18:07:30.398Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the weather tomorrow?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Hopefully sunny\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5faa",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:30.796Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Hopefully sunny\n"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 36.219,
        "totalTimeSpentSecs": 36.219,
        "attemptedAt": "2023-02-21T18:07:27.648Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5085f0e8a007b9e0a4249",
        "createdAt": "2023-02-21T18:07:27.648Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Hopefully sunny\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b5086",
    "created_at": "2023-02-21T17:57:12.165Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give me probabilities of each answer being true, if there are vary answers"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d09",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:29.762Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "yarong.li@magd.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:07:29.853Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508616d5998af836b9cb2",
        "createdAt": "2023-02-21T18:07:29.853Z",
        "source": "tasker",
        "taskerId": "yarong.li@magd.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b508c",
    "created_at": "2023-02-21T17:57:12.201Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "(Word in English, Word in Spanish)\n(Hello, hola)\n(Cat, gato)\n(dog, perro)"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d07",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:06.147Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "tomer.amir.mba22@said.oxford.edu",
        "attemptedAt": "2023-02-21T18:11:06.270Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5093ab3ecd709d649b850",
        "createdAt": "2023-02-21T18:11:06.270Z",
        "source": "tasker",
        "taskerId": "tomer.amir.mba22@said.oxford.edu",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b5091",
    "created_at": "2023-02-21T17:57:12.222Z",
    "completed_at": "2023-02-21T18:08:48.146Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Vegan food\n- Cashew cheese \n- Tofu  "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "- Legumes\n- Nut and nut butters\n- Chia seeds\n- Seaweed"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5cef",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:48.514Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Legumes\n- Nut and nut butters\n- Chia seeds\n- Seaweed"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:08:45.249Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508ad61520d8224db825b",
        "createdAt": "2023-02-21T18:08:45.249Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Legumes\n- Nut and nut butters\n- Chia seeds\n- Seaweed"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b509c",
    "created_at": "2023-02-21T17:57:12.249Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How many runners can I get for my event"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5ced",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:27.343Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:07:27.443Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5085ffe62e7c1541dd286",
        "createdAt": "2023-02-21T18:07:27.443Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f8d3e8b3858f4079e9",
    "created_at": "2023-02-21T17:57:12.306Z",
    "completed_at": "2023-02-21T18:07:17.843Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The essence of human nature entails"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "kindness"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fa8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:18.255Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "kindness"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 12.856,
        "totalTimeSpentSecs": 12.856,
        "attemptedAt": "2023-02-21T18:07:15.045Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508530c3f67c99e3b5db4",
        "createdAt": "2023-02-21T18:07:15.045Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "kindness"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50ca",
    "created_at": "2023-02-21T17:57:12.434Z",
    "completed_at": "2023-02-21T18:07:25.246Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Suggest a name for my race"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "F1 "
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5ce8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:25.728Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "F1 "
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 18.665,
        "totalTimeSpentSecs": 18.665,
        "attemptedAt": "2023-02-21T18:07:22.295Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5085a943d35f0058c6fac",
        "createdAt": "2023-02-21T18:07:22.295Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "F1 "
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50c9",
    "created_at": "2023-02-21T17:57:12.453Z",
    "completed_at": "2023-02-21T18:07:28.186Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Types of flowers:\n- rose \n- Alstroemeria\n- Calla Lily\n- Daisy\n- Gardenia\n- Carnation"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "snowdrop"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5ce4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:28.844Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "snowdrop"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 13.873,
        "totalTimeSpentSecs": 13.873,
        "attemptedAt": "2023-02-21T18:07:25.265Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5085d61520d8224db8122",
        "createdAt": "2023-02-21T18:07:25.265Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "snowdrop"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50cb",
    "created_at": "2023-02-21T17:57:12.453Z",
    "completed_at": "2023-02-21T18:07:39.145Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the best location to organise a fun run in my city?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Wetherspoons"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5ceb",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:39.541Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Wetherspoons"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 21.814,
        "totalTimeSpentSecs": 21.814,
        "attemptedAt": "2023-02-21T18:07:36.206Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508686ab6e930f1816560",
        "createdAt": "2023-02-21T18:07:36.206Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Wetherspoons"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50d1",
    "created_at": "2023-02-21T17:57:12.483Z",
    "completed_at": "2023-02-21T18:07:31.728Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In case of fire, where should I head?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "the exit"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cda",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:32.070Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the exit"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 12.212,
        "totalTimeSpentSecs": 12.212,
        "attemptedAt": "2023-02-21T18:07:29.037Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508610c3f67c99e3b5e54",
        "createdAt": "2023-02-21T18:07:29.037Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the exit"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50d2",
    "created_at": "2023-02-21T17:57:12.489Z",
    "completed_at": "2023-02-21T18:07:35.514Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the difference between log and natural log?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "They use different bases"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cd7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:35.913Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "They use different bases"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 9.031,
        "totalTimeSpentSecs": 9.031,
        "attemptedAt": "2023-02-21T18:07:32.692Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508646ab6e930f18164c2",
        "createdAt": "2023-02-21T18:07:32.692Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "They use different bases"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f86b393c18cb6b50cc",
    "created_at": "2023-02-21T17:57:12.522Z",
    "completed_at": "2023-02-21T18:07:40.055Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What type of font is Comic Sans?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Sans Serif"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cdb",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:40.468Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Sans Serif"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 10.579,
        "totalTimeSpentSecs": 10.579,
        "attemptedAt": "2023-02-21T18:07:37.425Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508690e8a007b9e0a42f0",
        "createdAt": "2023-02-21T18:07:37.425Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Sans Serif"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f85f",
    "created_at": "2023-02-21T17:57:13.546Z",
    "completed_at": "2023-02-21T18:08:18.265Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "potato, tomato, carrot"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Cabbage, Pak Choi, Spinach"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ebf",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:18.657Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Cabbage, Pak Choi, Spinach"
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 47.543,
        "totalTimeSpentSecs": 47.543,
        "attemptedAt": "2023-02-21T18:08:15.515Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5088f5ec05d1869c366ec",
        "createdAt": "2023-02-21T18:08:15.515Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Cabbage, Pak Choi, Spinach"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f87e",
    "created_at": "2023-02-21T17:57:13.623Z",
    "completed_at": "2023-02-21T18:10:18.409Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What do you think about ChatGPT"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Through the years, ChatGPT continued to improve, learning from each conversation and interaction it had. Its creators marveled at its ability to adapt to different situations and contexts, always finding the right words to say. ChatGPT became an invaluable resource for people of all ages, from children seeking knowledge to adults seeking insight and wisdom."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ea0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:18.796Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Through the years, ChatGPT continued to improve, learning from each conversation and interaction it had. Its creators marveled at its ability to adapt to different situations and contexts, always finding the right words to say. ChatGPT became an invaluable resource for people of all ages, from children seeking knowledge to adults seeking insight and wisdom."
              ]
            }
          }
        },
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "activeTimeSpentSecs": 26.966,
        "totalTimeSpentSecs": 166.84,
        "attemptedAt": "2023-02-21T18:10:15.428Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509075ec05d1869c36835",
        "createdAt": "2023-02-21T18:10:15.428Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Through the years, ChatGPT continued to improve, learning from each conversation and interaction it had. Its creators marveled at its ability to adapt to different situations and contexts, always finding the right words to say. ChatGPT became an invaluable resource for people of all ages, from children seeking knowledge to adults seeking insight and wisdom."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f87a",
    "created_at": "2023-02-21T17:57:13.623Z",
    "completed_at": "2023-02-21T18:07:47.052Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the most important part in ChatGPT"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Giving me answers to my essay"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5ead",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:47.428Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Giving me answers to my essay"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 13.851,
        "totalTimeSpentSecs": 13.851,
        "attemptedAt": "2023-02-21T18:07:44.415Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5087026649ae1699d69bf",
        "createdAt": "2023-02-21T18:07:44.415Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Giving me answers to my essay"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f88c",
    "created_at": "2023-02-21T17:57:13.668Z",
    "completed_at": "2023-02-21T18:07:52.415Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What are some of the main companies in the sleep-tracking space?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "i don't know"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5e9c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:52.799Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i don't know"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 18.03,
        "totalTimeSpentSecs": 18.03,
        "attemptedAt": "2023-02-21T18:07:49.527Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5087561520d8224db81bb",
        "createdAt": "2023-02-21T18:07:49.527Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "i don't know"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407bf7",
    "created_at": "2023-02-21T17:57:13.694Z",
    "completed_at": "2023-02-21T18:08:02.561Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In order to tie my shoelaces, I would"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "use both hands, cross the laces and make a knot.\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f99",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:03.075Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "use both hands, cross the laces and make a knot.\n"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 25.352,
        "totalTimeSpentSecs": 25.352,
        "attemptedAt": "2023-02-21T18:07:59.638Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5087fa32fb0c75375532a",
        "createdAt": "2023-02-21T18:07:59.638Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "use both hands, cross the laces and make a knot.\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407bfa",
    "created_at": "2023-02-21T17:57:13.694Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "I'd like to go to the shops. I first "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f9a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.102Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "yarong.li@magd.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505f9d3e8b3858f407bf8",
    "created_at": "2023-02-21T17:57:13.694Z",
    "completed_at": "2023-02-21T18:08:29.606Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Plato told me yesterday that"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "he thought, therefore he was"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fa5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:29.959Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "he thought, therefore he was"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 49.051,
        "totalTimeSpentSecs": 49.051,
        "attemptedAt": "2023-02-21T18:08:26.840Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5089bd3e8b3858f408619",
        "createdAt": "2023-02-21T18:08:26.840Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "he thought, therefore he was"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407bf9",
    "created_at": "2023-02-21T17:57:13.709Z",
    "completed_at": "2023-02-21T18:07:50.683Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How many oranges can you fit in an oven?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "1000"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5fa3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:51.181Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "1000"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 8.92,
        "totalTimeSpentSecs": 8.92,
        "attemptedAt": "2023-02-21T18:07:47.809Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50874d1160992b0f52ab4",
        "createdAt": "2023-02-21T18:07:47.809Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "1000"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c00",
    "created_at": "2023-02-21T17:57:13.719Z",
    "completed_at": "2023-02-21T18:07:59.005Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Dog is to cat as Puppy is to "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "kitten"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f84",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:07:59.457Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "kitten"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 9.515,
        "totalTimeSpentSecs": 9.515,
        "attemptedAt": "2023-02-21T18:07:56.168Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5087cf1e318af9121b9d3",
        "createdAt": "2023-02-21T18:07:56.168Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "kitten"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c14",
    "created_at": "2023-02-21T17:57:13.773Z",
    "completed_at": "2023-02-21T18:09:16.743Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "write python programs to transform data"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "import pandas as pd\ndf  = pd.read_csv('in.csv')\ndf.groupby('id')"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f81",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:17.112Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "import pandas as pd\ndf  = pd.read_csv('in.csv')\ndf.groupby('id')"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 84.17,
        "totalTimeSpentSecs": 84.17,
        "attemptedAt": "2023-02-21T18:09:13.674Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508c9d1160992b0f52c93",
        "createdAt": "2023-02-21T18:09:13.674Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "import pandas as pd\ndf  = pd.read_csv('in.csv')\ndf.groupby('id')"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c16",
    "created_at": "2023-02-21T17:57:13.774Z",
    "completed_at": "2023-02-21T18:08:21.772Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "I'd love to apply to the company. I've been "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "at home for three years since i graduated"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f7d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:22.201Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "at home for three years since i graduated"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 27.984,
        "totalTimeSpentSecs": 27.984,
        "attemptedAt": "2023-02-21T18:08:18.782Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50893d0be22b17b7313ea",
        "createdAt": "2023-02-21T18:08:18.782Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "at home for three years since i graduated"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8ba",
    "created_at": "2023-02-21T17:57:13.783Z",
    "completed_at": "2023-02-21T18:08:19.340Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What are some good company values?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Hard and long working hours, undying loyalty to the company"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e96",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:19.737Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Hard and long working hours, undying loyalty to the company"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 18.489,
        "totalTimeSpentSecs": 18.489,
        "attemptedAt": "2023-02-21T18:08:16.394Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50890d59f07ddf7d9bcad",
        "createdAt": "2023-02-21T18:08:16.394Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Hard and long working hours, undying loyalty to the company"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c15",
    "created_at": "2023-02-21T17:57:13.787Z",
    "completed_at": "2023-02-21T18:08:10.578Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "A common colour for a plain shirt is"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "blue"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f7f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:10.961Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "blue"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 6.544,
        "totalTimeSpentSecs": 6.544,
        "attemptedAt": "2023-02-21T18:08:07.728Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50887d1160992b0f52b55",
        "createdAt": "2023-02-21T18:08:07.728Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "blue"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8bb",
    "created_at": "2023-02-21T17:57:13.797Z",
    "completed_at": "2023-02-21T18:08:25.273Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1. 狗 - dog 2. 猫 - cat 3. 企鹅 - penguin"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "4."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5e9b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:25.689Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "4."
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 13.017,
        "totalTimeSpentSecs": 13.017,
        "attemptedAt": "2023-02-21T18:08:22.204Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508961c2577791c51843d",
        "createdAt": "2023-02-21T18:08:22.204Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "4."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8bc",
    "created_at": "2023-02-21T17:57:13.803Z",
    "completed_at": "2023-02-21T18:08:43.787Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1. France 2. Italy 3. Greece"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "3. Germany"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5e99",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:44.268Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "3. Germany"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 28.507,
        "totalTimeSpentSecs": 28.507,
        "attemptedAt": "2023-02-21T18:08:40.923Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508a9a32fb0c75375547e",
        "createdAt": "2023-02-21T18:08:40.923Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "3. Germany"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8bd",
    "created_at": "2023-02-21T17:57:13.814Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1. The axiom of extensionality 2. Null set axiom 3. Unordered Pairs "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e94",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:39.479Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:08:39.609Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508a7047d125464d4cb5a",
        "createdAt": "2023-02-21T18:08:39.609Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c2f",
    "created_at": "2023-02-21T17:57:13.830Z",
    "completed_at": "2023-02-21T18:08:41.485Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "create vegetarian recipes"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "mac and cheese: add cheese to mac"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f7a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:41.881Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "mac and cheese: add cheese to mac"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 18.033,
        "totalTimeSpentSecs": 18.033,
        "attemptedAt": "2023-02-21T18:08:38.608Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508a6d59f07ddf7d9bd4d",
        "createdAt": "2023-02-21T18:08:38.608Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "mac and cheese: add cheese to mac"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8cf",
    "created_at": "2023-02-21T17:57:13.863Z",
    "completed_at": "2023-02-21T18:08:46.387Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "sand, water, towel, umbrella "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "desk, bottle"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e90",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:46.861Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "desk, bottle"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 23.394,
        "totalTimeSpentSecs": 23.394,
        "attemptedAt": "2023-02-21T18:08:43.445Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508ab6ab6e930f18166c0",
        "createdAt": "2023-02-21T18:08:43.445Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "desk, bottle"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d3e8b3858f407c53",
    "created_at": "2023-02-21T17:57:13.876Z",
    "completed_at": "2023-02-21T18:09:33.595Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "AR, US, CA, GB, EE, IN"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "EE, DE, FR, FI, IT, PL, LV"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f78",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:33.965Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "EE, DE, FR, FI, IT, PL, LV"
              ]
            }
          }
        },
        "attemptedBy": "peyton.hammersley@gmail.com",
        "activeTimeSpentSecs": 68.091,
        "totalTimeSpentSecs": 68.091,
        "attemptedAt": "2023-02-21T18:09:30.649Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508dad1160992b0f52d3c",
        "createdAt": "2023-02-21T18:09:30.649Z",
        "source": "tasker",
        "taskerId": "peyton.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "EE, DE, FR, FI, IT, PL, LV"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f9d0be22b17b72f8ec",
    "created_at": "2023-02-21T17:57:13.919Z",
    "completed_at": "2023-02-21T18:10:58.444Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "here's a list of related pairs, ice -&gt; water, grape-&gt; wine, apple -&gt; juice"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "red -> wine, chai -> tea, virgin -> mojito"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e8c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:58.824Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "red -> wine, chai -> tea, virgin -> mojito"
              ]
            }
          }
        },
        "attemptedBy": "esteban.gomezllata@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:10:55.761Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5092f0e8a007b9e0a45e8",
        "createdAt": "2023-02-21T18:10:55.761Z",
        "source": "tasker",
        "taskerId": "esteban.gomezllata@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "red -> wine, chai -> tea, virgin -> mojito"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f96b393c18cb6b52f5",
    "created_at": "2023-02-21T17:57:14.077Z",
    "completed_at": "2023-02-21T18:08:48.290Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "To start your race you need to:\n- Find runners\n- Get all the necessary licenses\n- Measure the track\n- Come up with a unique name\n\n"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": ". Start the race\n. Finish it"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cd6",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:48.705Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                ". Start the race\n. Finish it"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 21.947,
        "totalTimeSpentSecs": 21.947,
        "attemptedAt": "2023-02-21T18:08:45.659Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508ad0c3f67c99e3b5ef4",
        "createdAt": "2023-02-21T18:08:45.659Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                ". Start the race\n. Finish it"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f96b393c18cb6b52f6",
    "created_at": "2023-02-21T17:57:14.078Z",
    "completed_at": "2023-02-21T18:08:47.833Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Small -&gt; Medium -&gt; Large -&gt; "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Massive"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cbe",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:48.252Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Massive"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 11.478,
        "totalTimeSpentSecs": 11.478,
        "attemptedAt": "2023-02-21T18:08:44.977Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508ade314a7b14135eb99",
        "createdAt": "2023-02-21T18:08:44.977Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Massive"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505f96b393c18cb6b52f7",
    "created_at": "2023-02-21T17:57:14.078Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Popular race names in London:\n-The London Marathon\n- The Boston Marathon\n- The Chicago Marathon\n- Oxford 5K city run\n"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cd4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:23.891Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "nauynix@gmail.com",
        "attemptedAt": "2023-02-21T18:09:24.025Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508d4a82fc4c7d6634c2a",
        "createdAt": "2023-02-21T18:09:24.025Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b5312",
    "created_at": "2023-02-21T17:57:14.159Z",
    "completed_at": "2023-02-21T18:09:05.025Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "if Hello -&gt; olleH then World -&gt;"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "dlroW"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cbc",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:05.432Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "dlroW"
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 18.971,
        "totalTimeSpentSecs": 18.971,
        "attemptedAt": "2023-02-21T18:09:01.988Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508bed1160992b0f52bf5",
        "createdAt": "2023-02-21T18:09:01.988Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "dlroW"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b5330",
    "created_at": "2023-02-21T17:57:14.231Z",
    "completed_at": "2023-02-21T18:09:44.530Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What are the benefits from going to the gym?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "To escape from doing tutorial sheets. To loose weight. To lift up the mood"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cb4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:44.999Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "To escape from doing tutorial sheets. To loose weight. To lift up the mood"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 58.823,
        "totalTimeSpentSecs": 58.823,
        "attemptedAt": "2023-02-21T18:09:41.967Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508e6d3e8b3858f408742",
        "createdAt": "2023-02-21T18:09:41.967Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "To escape from doing tutorial sheets. To loose weight. To lift up the mood"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b5331",
    "created_at": "2023-02-21T17:57:14.232Z",
    "completed_at": "2023-02-21T18:09:02.936Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "P -&gt; Q and Q -&gt; R means that "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "P --> Q"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cb9",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:03.357Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "P --> Q"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 15.286,
        "totalTimeSpentSecs": 15.286,
        "attemptedAt": "2023-02-21T18:09:00.143Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508bc7c3dd08602d64b3d",
        "createdAt": "2023-02-21T18:09:00.143Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "P --> Q"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b5333",
    "created_at": "2023-02-21T17:57:14.241Z",
    "completed_at": "2023-02-21T18:09:04.331Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best phone for me to buy?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Samsung Galaxy S10e"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cb3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:04.858Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Samsung Galaxy S10e"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 15.395,
        "totalTimeSpentSecs": 15.395,
        "attemptedAt": "2023-02-21T18:09:01.385Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508bdf1e318af9121bad6",
        "createdAt": "2023-02-21T18:09:01.385Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Samsung Galaxy S10e"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b5338",
    "created_at": "2023-02-21T17:57:14.248Z",
    "completed_at": "2023-02-21T18:08:55.583Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How would I get a job at google?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Google it"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cb2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:08:55.940Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Google it"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 6.353,
        "totalTimeSpentSecs": 6.353,
        "attemptedAt": "2023-02-21T18:08:52.856Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508b590b71311871402e5",
        "createdAt": "2023-02-21T18:08:52.856Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Google it"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b535a",
    "created_at": "2023-02-21T17:57:14.358Z",
    "completed_at": "2023-02-21T18:09:40.565Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "When I go to the zoo I get lots of"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "opportunities to see varied species of animals and learn about their natural habitats and lifestyles"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cb0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:40.986Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "opportunities to see varied species of animals and learn about their natural habitats and lifestyles"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:09:37.472Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508e16b393c18cb6b6948",
        "createdAt": "2023-02-21T18:09:37.472Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "opportunities to see varied species of animals and learn about their natural habitats and lifestyles"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fa6b393c18cb6b536e",
    "created_at": "2023-02-21T17:57:14.385Z",
    "completed_at": "2023-02-21T18:09:07.607Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Dust -&gt; Sand -&gt; Pebble -&gt; Stone -&gt; "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Rock -> Boulder"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5cab",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:08.050Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Rock -> Boulder"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 15.441,
        "totalTimeSpentSecs": 15.441,
        "attemptedAt": "2023-02-21T18:09:04.572Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508c00f7597c65bafeab1",
        "createdAt": "2023-02-21T18:09:04.572Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Rock -> Boulder"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fad6",
    "created_at": "2023-02-21T17:57:15.203Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How do I come up with a good company name?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e8a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.824Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "peter.sadhani@trinity.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fbd0be22b17b72fae0",
    "created_at": "2023-02-21T17:57:15.239Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "apple, banana, orange"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e7f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.929Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "withinfinitecourage@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fbd0be22b17b72fae3",
    "created_at": "2023-02-21T17:57:15.247Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How does ChatGPT work?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e6e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:01.662Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "amelia.isabelle@outlook.com",
        "attemptedAt": "2023-02-21T18:09:01.849Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508bd993d34491bab23d7",
        "createdAt": "2023-02-21T18:09:01.849Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb06",
    "created_at": "2023-02-21T17:57:15.328Z",
    "completed_at": "2023-02-21T18:09:19.930Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How to hack into the CIA?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "no idea"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e6b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:20.308Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 15.297,
        "totalTimeSpentSecs": 15.297,
        "attemptedAt": "2023-02-21T18:09:16.982Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508cd5ec05d1869c36795",
        "createdAt": "2023-02-21T18:09:16.982Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no idea"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e61",
    "created_at": "2023-02-21T17:57:15.398Z",
    "completed_at": "2023-02-21T18:09:17.339Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "airship, train, bicycle"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "car"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f71",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:17.778Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "car"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 11.142,
        "totalTimeSpentSecs": 11.142,
        "attemptedAt": "2023-02-21T18:09:14.183Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508ca6ab6e930f1816767",
        "createdAt": "2023-02-21T18:09:14.183Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "car"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e5b",
    "created_at": "2023-02-21T17:57:15.411Z",
    "completed_at": "2023-02-21T18:09:22.260Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "find meaning of life"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "pi"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f72",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:22.678Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "pi"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 15.852,
        "totalTimeSpentSecs": 15.852,
        "attemptedAt": "2023-02-21T18:09:19.362Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508cfd59f07ddf7d9be87",
        "createdAt": "2023-02-21T18:09:19.362Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "pi"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e6a",
    "created_at": "2023-02-21T17:57:15.440Z",
    "completed_at": "2023-02-21T18:09:27.863Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "1, 1, 2, 3, 5, 8"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "13,21,34,55,89,153"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f6f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:28.238Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "13,21,34,55,89,153"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 18.776,
        "totalTimeSpentSecs": 18.776,
        "attemptedAt": "2023-02-21T18:09:24.744Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508d5a32fb0c75375551c",
        "createdAt": "2023-02-21T18:09:24.744Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "13,21,34,55,89,153"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e6b",
    "created_at": "2023-02-21T17:57:15.440Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "write a haiku about large language models"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f59",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:33.683Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:09:33.760Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508dd29ec0078ca8986ce",
        "createdAt": "2023-02-21T18:09:33.760Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e72",
    "created_at": "2023-02-21T17:57:15.452Z",
    "completed_at": "2023-02-21T18:11:08.176Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "explain different techniques for CO2 extraction from the atmosphere"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "a simple way is to plant more trees as CO2 absorbers"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f56",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:08.654Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "a simple way is to plant more trees as CO2 absorbers"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 29.926000000000002,
        "totalTimeSpentSecs": 109.977,
        "attemptedAt": "2023-02-21T18:11:05.146Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509398773e0665120a263",
        "createdAt": "2023-02-21T18:11:05.146Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "a simple way is to plant more trees as CO2 absorbers"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb31",
    "created_at": "2023-02-21T17:57:15.454Z",
    "completed_at": "2023-02-21T18:11:15.552Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Explain how do I get rizz?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Ask Harry"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e69",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:15.924Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Ask Harry"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 116.66,
        "totalTimeSpentSecs": 116.66,
        "attemptedAt": "2023-02-21T18:11:12.821Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509417c3dd08602d64c86",
        "createdAt": "2023-02-21T18:11:12.821Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Ask Harry"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e7e",
    "created_at": "2023-02-21T17:57:15.477Z",
    "completed_at": "2023-02-21T18:10:28.084Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "what is the difference between visual odometry and visual SLAM?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "visual odometry is tracking to determine the trajectory for the robots incrementally"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f52",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:28.499Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "visual odometry is tracking to determine the trajectory for the robots incrementally"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 65.39,
        "totalTimeSpentSecs": 65.39,
        "attemptedAt": "2023-02-21T18:10:24.967Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50911374fa3f6e4b3208c",
        "createdAt": "2023-02-21T18:10:24.967Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "visual odometry is tracking to determine the trajectory for the robots incrementally"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e7d",
    "created_at": "2023-02-21T17:57:15.477Z",
    "completed_at": "2023-02-21T18:09:44.390Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "the building is shaking"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "there may be an earthquake"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f4e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:44.855Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "there may be an earthquake"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 20.679,
        "totalTimeSpentSecs": 20.679,
        "attemptedAt": "2023-02-21T18:09:41.387Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508e5374fa3f6e4b31f45",
        "createdAt": "2023-02-21T18:09:41.387Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "there may be an earthquake"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb36",
    "created_at": "2023-02-21T17:57:15.479Z",
    "completed_at": "2023-02-21T18:09:41.148Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give me recommendations for a trip in Rome"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "I haven't been to rome"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e66",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:41.547Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "I haven't been to rome"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 12.613,
        "totalTimeSpentSecs": 12.613,
        "attemptedAt": "2023-02-21T18:09:38.345Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508e20e8a007b9e0a443d",
        "createdAt": "2023-02-21T18:09:38.345Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "I haven't been to rome"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb41",
    "created_at": "2023-02-21T17:57:15.513Z",
    "completed_at": "2023-02-21T18:09:59.598Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "a list of places with names, explanations, and locations for example: \n(*) Said Business School, Oxford's business school, Oxford-UK\n(*) The Colosseum, an old building, Rome-Italy   "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "() Ashmolean Museum, an old Museum\n() Anfield, a football stadium, Liverpool, England"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e64",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:59.994Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "() Ashmolean Museum, an old Museum\n() Anfield, a football stadium, Liverpool, England"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 30.329,
        "totalTimeSpentSecs": 30.329,
        "attemptedAt": "2023-02-21T18:09:56.826Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508f590b7131187140385",
        "createdAt": "2023-02-21T18:09:56.826Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "() Ashmolean Museum, an old Museum\n() Anfield, a football stadium, Liverpool, England"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb47",
    "created_at": "2023-02-21T17:57:15.532Z",
    "completed_at": "2023-02-21T18:10:31.155Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write a short sentence on the butterfly effect."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Butterfly effect is something happens on a small object, but goes through a series of relations and have a large impact on something else."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e5f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:31.522Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Butterfly effect is something happens on a small object, but goes through a series of relations and have a large impact on something else."
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 52.667,
        "totalTimeSpentSecs": 52.667,
        "attemptedAt": "2023-02-21T18:10:28.052Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509140e8a007b9e0a4541",
        "createdAt": "2023-02-21T18:10:28.052Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Butterfly effect is something happens on a small object, but goes through a series of relations and have a large impact on something else."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb42",
    "created_at": "2023-02-21T17:57:15.532Z",
    "completed_at": "2023-02-21T18:11:18.933Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How did the weather in Iceland change in the last 60 years? "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "The temperature of the earth has been warming this means that the weather in Iceland has been getting warmer too!\n\nCrochet and Jóhannesson (2011) showed that the decades of 1991–2000 and 2001–2010 were warmer on average by up to 1.25 °C, compared to the 1961–1990 mean temperatures. Similarly, the Icelandic Meteorological Office (IMO) reports that between 1980 and 2016, there was a warming trend of 0.47 °C per decade."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e61",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:19.454Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "The temperature of the earth has been warming this means that the weather in Iceland has been getting warmer too!\n\nCrochet and Jóhannesson (2011) showed that the decades of 1991–2000 and 2001–2010 were warmer on average by up to 1.25 °C, compared to the 1961–1990 mean temperatures. Similarly, the Icelandic Meteorological Office (IMO) reports that between 1980 and 2016, there was a warming trend of 0.47 °C per decade."
              ]
            }
          }
        },
        "attemptedBy": "peyton.hammersley@gmail.com",
        "activeTimeSpentSecs": 103.975,
        "totalTimeSpentSecs": 103.975,
        "attemptedAt": "2023-02-21T18:11:15.949Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50944d59f07ddf7d9bf8d",
        "createdAt": "2023-02-21T18:11:15.949Z",
        "source": "tasker",
        "taskerId": "peyton.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "The temperature of the earth has been warming this means that the weather in Iceland has been getting warmer too!\n\nCrochet and Jóhannesson (2011) showed that the decades of 1991–2000 and 2001–2010 were warmer on average by up to 1.25 °C, compared to the 1961–1990 mean temperatures. Similarly, the Icelandic Meteorological Office (IMO) reports that between 1980 and 2016, there was a warming trend of 0.47 °C per decade."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407e96",
    "created_at": "2023-02-21T17:57:15.540Z",
    "completed_at": "2023-02-21T18:09:58.676Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "good morning, what are"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "the best ways to brew coffee"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f4c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:09:59.060Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the best ways to brew coffee"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:09:55.708Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508f361520d8224db8353",
        "createdAt": "2023-02-21T18:09:55.708Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the best ways to brew coffee"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd0be22b17b72fb5c",
    "created_at": "2023-02-21T17:57:15.597Z",
    "completed_at": "2023-02-21T18:10:12.321Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How does one get accepted to Oxford?  "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Don't apply to cambridge"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e5c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:13.222Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Don't apply to cambridge"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 27.492,
        "totalTimeSpentSecs": 27.492,
        "attemptedAt": "2023-02-21T18:10:09.377Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509017c3dd08602d64bdd",
        "createdAt": "2023-02-21T18:10:09.377Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Don't apply to cambridge"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407ece",
    "created_at": "2023-02-21T17:57:15.658Z",
    "completed_at": "2023-02-21T18:10:07.790Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "suggest a recipe for a cheap nutritious meal"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Look up healthy recipes by Jamie Oliver"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f49",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:08.328Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Look up healthy recipes by Jamie Oliver"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 21.698,
        "totalTimeSpentSecs": 21.698,
        "attemptedAt": "2023-02-21T18:10:04.557Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f508fdd0be22b17b731495",
        "createdAt": "2023-02-21T18:10:04.557Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Look up healthy recipes by Jamie Oliver"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fbd3e8b3858f407ee0",
    "created_at": "2023-02-21T17:57:15.707Z",
    "completed_at": "2023-02-21T18:11:16.156Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "what is the ASL format dataset for SLAM?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "dunno"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f48",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:16.604Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "dunno"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 88.869,
        "totalTimeSpentSecs": 88.869,
        "attemptedAt": "2023-02-21T18:11:13.117Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50941a32fb0c753755670",
        "createdAt": "2023-02-21T18:11:13.117Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "dunno"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b5544",
    "created_at": "2023-02-21T17:57:15.787Z",
    "completed_at": "2023-02-21T18:11:53.741Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Describe the colour blue"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "A wavelength of light around 450nm, often used as a complementary colour to red"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5ca6",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:54.168Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "A wavelength of light around 450nm, often used as a complementary colour to red"
              ]
            }
          }
        },
        "attemptedBy": "alexanderdcolby@gmail.com",
        "activeTimeSpentSecs": 0,
        "totalTimeSpentSecs": 0,
        "attemptedAt": "2023-02-21T18:11:50.245Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50966943d35f0058c7156",
        "createdAt": "2023-02-21T18:11:50.245Z",
        "source": "tasker",
        "taskerId": "alexanderdcolby@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "A wavelength of light around 450nm, often used as a complementary colour to red"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b5550",
    "created_at": "2023-02-21T17:57:15.813Z",
    "completed_at": "2023-02-21T18:10:14.090Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me the meaning of life"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Im sorry this is too deep to answer."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c8c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:14.505Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Im sorry this is too deep to answer."
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 12.9,
        "totalTimeSpentSecs": 12.9,
        "attemptedAt": "2023-02-21T18:10:11.131Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50903f1e318af9121bb76",
        "createdAt": "2023-02-21T18:10:11.131Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Im sorry this is too deep to answer."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b554f",
    "created_at": "2023-02-21T17:57:15.813Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "- Java\n- C\n- C++\n- HTML\n- Python"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5ca5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.843Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "clairezwj@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fb6b393c18cb6b5586",
    "created_at": "2023-02-21T17:57:15.920Z",
    "completed_at": "2023-02-21T18:10:31.239Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What should I pack for my skiing holiday in the Alps?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Skiing gear, leggings, goggles, hat, gloves, fleeces"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c88",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:31.677Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Skiing gear, leggings, goggles, hat, gloves, fleeces"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 21.898,
        "totalTimeSpentSecs": 21.898,
        "attemptedAt": "2023-02-21T18:10:28.255Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509141c2577791c5185a6",
        "createdAt": "2023-02-21T18:10:28.255Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Skiing gear, leggings, goggles, hat, gloves, fleeces"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b55be",
    "created_at": "2023-02-21T17:57:16.089Z",
    "completed_at": "2023-02-21T18:11:31.653Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What should I do with my life?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Have fun and try to succeed"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c81",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:32.069Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Have fun and try to succeed"
              ]
            }
          }
        },
        "attemptedBy": "mark.eid@balliol.ox.ac.uk",
        "activeTimeSpentSecs": 77.438,
        "totalTimeSpentSecs": 77.438,
        "attemptedAt": "2023-02-21T18:11:28.831Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509510f7597c65bafebb6",
        "createdAt": "2023-02-21T18:11:28.831Z",
        "source": "tasker",
        "taskerId": "mark.eid@balliol.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Have fun and try to succeed"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b55bb",
    "created_at": "2023-02-21T17:57:16.097Z",
    "completed_at": "2023-02-21T18:10:33.830Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Character and actor pairs in Harry Potter:\n-Harry Potter -&gt; Daniel Radclidde\n-Voldemort -&gt; Ralph Fiennes\n-Neville Longbottom -&gt; Mathew Lewis"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "- Hermoine Granger -> Emma Watson\n"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c87",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:34.213Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Hermoine Granger -> Emma Watson\n"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 18.182,
        "totalTimeSpentSecs": 18.182,
        "attemptedAt": "2023-02-21T18:10:30.832Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509179519eb9f87914666",
        "createdAt": "2023-02-21T18:10:30.832Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "- Hermoine Granger -> Emma Watson\n"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fb6b393c18cb6b55bd",
    "created_at": "2023-02-21T17:57:16.097Z",
    "completed_at": "2023-02-21T18:10:22.439Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me the meaning of life"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "42"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c85",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:22.865Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "42"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 6.24,
        "totalTimeSpentSecs": 6.24,
        "attemptedAt": "2023-02-21T18:10:19.244Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5090b374fa3f6e4b31fec",
        "createdAt": "2023-02-21T18:10:19.244Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "42"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fc6b393c18cb6b55c5",
    "created_at": "2023-02-21T17:57:16.135Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How do I attain enlightenment?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c7f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:38.363Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:10:38.592Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5091eac6d86c86d361a21",
        "createdAt": "2023-02-21T18:10:38.592Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fc6b393c18cb6b55dc",
    "created_at": "2023-02-21T17:57:16.190Z",
    "completed_at": "2023-02-21T18:11:38.452Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The best thing to do with my life is "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "to enjoy"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c7d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:38.898Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "to enjoy"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 69.958,
        "totalTimeSpentSecs": 69.958,
        "attemptedAt": "2023-02-21T18:11:35.418Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5095726649ae1699d6c6a",
        "createdAt": "2023-02-21T18:11:35.418Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "to enjoy"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fc6b393c18cb6b55db",
    "created_at": "2023-02-21T17:57:16.197Z",
    "completed_at": "2023-02-21T18:10:39.638Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How can I get a first in my degree?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "yes you can"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c7a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:40.134Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "yes you can"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 10.179,
        "totalTimeSpentSecs": 10.179,
        "attemptedAt": "2023-02-21T18:10:36.520Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5091c943d35f0058c7052",
        "createdAt": "2023-02-21T18:10:36.520Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "yes you can"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080ce",
    "created_at": "2023-02-21T17:57:16.970Z",
    "completed_at": "2023-02-21T18:11:12.680Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "the cat ran towards"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "the dog"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f45",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:13.120Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the dog"
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 40.281,
        "totalTimeSpentSecs": 40.281,
        "attemptedAt": "2023-02-21T18:11:10.223Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5093ed0be22b17b731605",
        "createdAt": "2023-02-21T18:11:10.223Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "the dog"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080df",
    "created_at": "2023-02-21T17:57:16.998Z",
    "completed_at": "2023-02-21T18:10:56.103Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Will artificial general intelligence replace human?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Unlikely."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f26",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:56.433Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Unlikely."
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 23.296,
        "totalTimeSpentSecs": 23.296,
        "attemptedAt": "2023-02-21T18:10:53.176Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5092d61520d8224db83e8",
        "createdAt": "2023-02-21T18:10:53.176Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Unlikely."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080da",
    "created_at": "2023-02-21T17:57:16.999Z",
    "completed_at": "2023-02-21T18:10:48.257Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "why translation between chinese and english does not work for most circumstances?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Chinese language has more alphabets."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f44",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:48.663Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Chinese language has more alphabets."
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 13.491,
        "totalTimeSpentSecs": 13.491,
        "attemptedAt": "2023-02-21T18:10:45.568Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50925d1160992b0f52fa4",
        "createdAt": "2023-02-21T18:10:45.568Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Chinese language has more alphabets."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd0be22b17b72fd39",
    "created_at": "2023-02-21T17:57:17.002Z",
    "completed_at": "2023-02-21T18:10:55.320Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "a numbered list of actions:\n(1) go to school \n(2) go back home "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "go back home"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e5a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:55.769Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "go back home"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 13.133,
        "totalTimeSpentSecs": 13.133,
        "attemptedAt": "2023-02-21T18:10:52.360Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5092c6ab6e930f1816809",
        "createdAt": "2023-02-21T18:10:52.360Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "go back home"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080d8",
    "created_at": "2023-02-21T17:57:17.008Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "SLAM and visual odometry"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b307a47014fa4a5f2d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:58.969Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:10:59.071Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50933ff233a6e730af9c9",
        "createdAt": "2023-02-21T18:10:59.071Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080dd",
    "created_at": "2023-02-21T17:57:17.023Z",
    "completed_at": "2023-02-21T18:10:55.729Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "visual SLAM"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "DUNK"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f28",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:10:56.199Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "DUNK"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 6.141,
        "totalTimeSpentSecs": 6.141,
        "attemptedAt": "2023-02-21T18:10:52.966Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5092d0c3f67c99e3b5f9f",
        "createdAt": "2023-02-21T18:10:52.966Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "DUNK"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080e0",
    "created_at": "2023-02-21T17:57:17.057Z",
    "completed_at": "2023-02-21T18:11:19.616Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "english studying"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "quite hard"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f21",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:19.985Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "quite hard"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 23.343,
        "totalTimeSpentSecs": 23.343,
        "attemptedAt": "2023-02-21T18:11:17.041Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509450e8a007b9e0a467b",
        "createdAt": "2023-02-21T18:11:17.041Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "quite hard"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd0be22b17b72fd5a",
    "created_at": "2023-02-21T17:57:17.077Z",
    "completed_at": "2023-02-21T18:11:16.004Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How would I apply blue tack to a wall?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Roll into a ball and stick onto wall."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e3c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:16.419Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Roll into a ball and stick onto wall."
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 18.599,
        "totalTimeSpentSecs": 18.599,
        "attemptedAt": "2023-02-21T18:11:13.173Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50941d3e8b3858f4087ed",
        "createdAt": "2023-02-21T18:11:13.173Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Roll into a ball and stick onto wall."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd0be22b17b72fd55",
    "created_at": "2023-02-21T17:57:17.077Z",
    "completed_at": "2023-02-21T18:11:33.614Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the capital of France?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Paris"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e53",
    "project_param_version": 2,
    "assignedSession": null,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:33.950Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Paris"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 6.56,
        "totalTimeSpentSecs": 6.56,
        "attemptedAt": "2023-02-21T18:11:30.971Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50953d3e8b3858f40888b",
        "createdAt": "2023-02-21T18:11:30.971Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Paris"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fcd3e8b3858f4080f4",
    "created_at": "2023-02-21T17:57:17.110Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me the relation between human and cats in the future."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f20",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.934Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "esteban.gomezllata@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fdd0be22b17b72fd6c",
    "created_at": "2023-02-21T17:57:17.128Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the color of the sky?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e39",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:26.573Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:11:26.666Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5094ee063c6606c91c872",
        "createdAt": "2023-02-21T18:11:26.666Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fdd0be22b17b72fd9c",
    "created_at": "2023-02-21T17:57:17.249Z",
    "completed_at": "2023-02-21T18:12:14.616Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Find synonyms for the word likely."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "probably, frequent, possible"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e37",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:15.064Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "probably, frequent, possible"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 64.295,
        "totalTimeSpentSecs": 64.295,
        "attemptedAt": "2023-02-21T18:12:11.641Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5097b9c5b088d89118537",
        "createdAt": "2023-02-21T18:12:11.641Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "probably, frequent, possible"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fdd3e8b3858f408118",
    "created_at": "2023-02-21T17:57:17.250Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the order of each elements in Klein group?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b207a47014fa4a5f1e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.934Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "tomer.amir.mba22@said.oxford.edu",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fdd0be22b17b72fdbe",
    "created_at": "2023-02-21T17:57:17.324Z",
    "completed_at": "2023-02-21T18:12:26.864Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What does it mean to say \"an image is worth a thousand words\"?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "\"A picture is worth a thousand words\" is an adage in multiple languages meaning that complex and sometimes multiple ideas can be conveyed by a single still image, which conveys its meaning or essence more effectively than a mere verbal description."
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e31",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:27.261Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "\"A picture is worth a thousand words\" is an adage in multiple languages meaning that complex and sometimes multiple ideas can be conveyed by a single still image, which conveys its meaning or essence more effectively than a mere verbal description."
              ]
            }
          }
        },
        "attemptedBy": "jinghua.zhang@bnc.ox.ac.uk",
        "activeTimeSpentSecs": 72.128,
        "totalTimeSpentSecs": 72.128,
        "attemptedAt": "2023-02-21T18:12:23.957Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50988d1160992b0f530e2",
        "createdAt": "2023-02-21T18:12:23.957Z",
        "source": "tasker",
        "taskerId": "jinghua.zhang@bnc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "\"A picture is worth a thousand words\" is an adage in multiple languages meaning that complex and sometimes multiple ideas can be conveyed by a single still image, which conveys its meaning or essence more effectively than a mere verbal description."
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fdd0be22b17b72fdbc",
    "created_at": "2023-02-21T17:57:17.337Z",
    "completed_at": "2023-02-21T18:11:29.887Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Antonyms of quiet are:"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "noisy"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e34",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:30.250Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "noisy"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 12.388,
        "totalTimeSpentSecs": 12.388,
        "attemptedAt": "2023-02-21T18:11:27.103Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5094f0e8a007b9e0a4724",
        "createdAt": "2023-02-21T18:11:27.103Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "noisy"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fdd0be22b17b72fdc9",
    "created_at": "2023-02-21T17:57:17.399Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Phrases like \"On the one hand, [...]. On the other...\""
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e2f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:22.213Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "amelia.isabelle@outlook.com",
        "attemptedAt": "2023-02-21T18:11:22.321Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5094ab30111df52568905",
        "createdAt": "2023-02-21T18:11:22.321Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fdd0be22b17b72fdd4",
    "created_at": "2023-02-21T17:57:17.422Z",
    "completed_at": "2023-02-21T18:12:26.755Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Reply phrases with ... \"However, [...]\""
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "However, the sun refused to shine\nHowever, when I went to the zoo I was scared\nHowever, they didn't seem to help"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e2b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:27.118Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "However, the sun refused to shine\nHowever, when I went to the zoo I was scared\nHowever, they didn't seem to help"
              ]
            }
          }
        },
        "attemptedBy": "peyton.hammersley@gmail.com",
        "activeTimeSpentSecs": 66.406,
        "totalTimeSpentSecs": 66.406,
        "attemptedAt": "2023-02-21T18:12:23.836Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509880f7597c65bafec56",
        "createdAt": "2023-02-21T18:12:23.836Z",
        "source": "tasker",
        "taskerId": "peyton.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "However, the sun refused to shine\nHowever, when I went to the zoo I was scared\nHowever, they didn't seem to help"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fdd0be22b17b72fdd3",
    "created_at": "2023-02-21T17:57:17.422Z",
    "completed_at": "2023-02-21T18:11:40.736Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Are there mammals who live in the sea?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Spongebob Squarepants does"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e2d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:41.217Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Spongebob Squarepants does"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 18.538,
        "totalTimeSpentSecs": 18.538,
        "attemptedAt": "2023-02-21T18:11:37.679Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509599c5b088d891183fb",
        "createdAt": "2023-02-21T18:11:37.679Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Spongebob Squarepants does"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b57ad",
    "created_at": "2023-02-21T17:57:17.644Z",
    "completed_at": "2023-02-21T18:11:39.053Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The way to attain enlightenment is "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "have fun"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c76",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:39.480Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "have fun"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 17.333,
        "totalTimeSpentSecs": 17.333,
        "attemptedAt": "2023-02-21T18:11:35.961Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50958a32fb0c7537557c3",
        "createdAt": "2023-02-21T18:11:35.961Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "have fun"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b57c7",
    "created_at": "2023-02-21T17:57:17.729Z",
    "completed_at": "2023-02-21T18:11:38.022Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The meaning of life is"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "to find happiness. "
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c72",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:38.461Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "to find happiness. "
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 11.209,
        "totalTimeSpentSecs": 11.209,
        "attemptedAt": "2023-02-21T18:11:34.687Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50956d1160992b0f53044",
        "createdAt": "2023-02-21T18:11:34.687Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "to find happiness. "
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b57c9",
    "created_at": "2023-02-21T17:57:17.736Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is a good dinner I can cook for the 6 guests that are coming over this Friday?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c58",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.948Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "younesse.kaddar@chch.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fd6b393c18cb6b57da",
    "created_at": "2023-02-21T17:57:17.756Z",
    "completed_at": "2023-02-21T18:12:15.608Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Hello -&gt; Hola\nI love you -&gt; Te amo\nGoodbye -&gt; Adios"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Goodnight - Buenas noches"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c55",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:16.062Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Goodnight - Buenas noches"
              ]
            }
          }
        },
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "activeTimeSpentSecs": 44.735,
        "totalTimeSpentSecs": 44.735,
        "attemptedAt": "2023-02-21T18:12:12.885Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5097d9519eb9f87914706",
        "createdAt": "2023-02-21T18:12:12.885Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Goodnight - Buenas noches"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b5822",
    "created_at": "2023-02-21T17:57:17.961Z",
    "completed_at": "2023-02-21T18:11:38.367Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Explain what biology studies"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "human body"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c52",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:38.781Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "human body"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 7.362,
        "totalTimeSpentSecs": 7.362,
        "attemptedAt": "2023-02-21T18:11:35.741Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50957d0be22b17b731711",
        "createdAt": "2023-02-21T18:11:35.741Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "human body"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b5826",
    "created_at": "2023-02-21T17:57:17.969Z",
    "completed_at": "2023-02-21T18:12:28.642Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me the capital of Spain"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Madrid"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ae07a47014fa4a5c51",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:29.045Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Madrid"
              ]
            }
          }
        },
        "attemptedBy": "alona@everyrun.world",
        "activeTimeSpentSecs": 56.223,
        "totalTimeSpentSecs": 56.223,
        "attemptedAt": "2023-02-21T18:12:26.014Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5098a0e8a007b9e0a47c4",
        "createdAt": "2023-02-21T18:12:26.014Z",
        "source": "tasker",
        "taskerId": "alona@everyrun.world",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Madrid"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b5838",
    "created_at": "2023-02-21T17:57:18.036Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Car, bus, train, bicycle"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c4f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:36.118Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "mark.eid@balliol.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:11:36.213Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50958883c99f04612852a",
        "createdAt": "2023-02-21T18:11:36.213Z",
        "source": "tasker",
        "taskerId": "mark.eid@balliol.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b584b",
    "created_at": "2023-02-21T17:57:18.090Z",
    "completed_at": "2023-02-21T18:11:46.704Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What outfit should I wear today?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "ChatGPT hoodie"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c4c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:47.113Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ChatGPT hoodie"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 11.189,
        "totalTimeSpentSecs": 11.189,
        "attemptedAt": "2023-02-21T18:11:43.543Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5095f6b393c18cb6b6af0",
        "createdAt": "2023-02-21T18:11:43.543Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ChatGPT hoodie"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b5857",
    "created_at": "2023-02-21T17:57:18.091Z",
    "completed_at": "2023-02-21T18:12:20.956Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "chairs, tables, walls"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "slam the door"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c4b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:21.353Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "slam the door"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 40.891,
        "totalTimeSpentSecs": 40.891,
        "attemptedAt": "2023-02-21T18:12:18.150Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50982ef60a76bee8a1725",
        "createdAt": "2023-02-21T18:12:18.150Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "slam the door"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fd6b393c18cb6b5858",
    "created_at": "2023-02-21T17:57:18.116Z",
    "completed_at": "2023-02-21T18:11:55.893Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Shopping list:\n- bread\n- milk\n-eggs"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "bread and milk"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c48",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:56.385Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "bread and milk"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 15.674,
        "totalTimeSpentSecs": 15.674,
        "attemptedAt": "2023-02-21T18:11:53.075Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509699c5b088d89118499",
        "createdAt": "2023-02-21T18:11:53.075Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "bread and milk"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b72ffb5",
    "created_at": "2023-02-21T17:57:18.607Z",
    "completed_at": "2023-02-21T18:12:24.824Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Change the subject to an adjacent topic starting with \"Anyway, [...]\""
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Anyway, you are boring"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e29",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:25.262Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Anyway, you are boring"
              ]
            }
          }
        },
        "attemptedBy": "mark.eid@balliol.ox.ac.uk",
        "activeTimeSpentSecs": 43.58,
        "totalTimeSpentSecs": 43.58,
        "attemptedAt": "2023-02-21T18:12:21.665Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50985d59f07ddf7d9c036",
        "createdAt": "2023-02-21T18:12:21.665Z",
        "source": "tasker",
        "taskerId": "mark.eid@balliol.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Anyway, you are boring"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b72ffcb",
    "created_at": "2023-02-21T17:57:18.677Z",
    "completed_at": "2023-02-21T18:12:19.995Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Explain to me how I can lose weight"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "eat less"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e0b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:20.447Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "eat less"
              ]
            }
          }
        },
        "attemptedBy": "yannan.zhang@mansfield.ox.ac.uk",
        "activeTimeSpentSecs": 39.453,
        "totalTimeSpentSecs": 39.453,
        "attemptedAt": "2023-02-21T18:12:17.273Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509815ec05d1869c3694a",
        "createdAt": "2023-02-21T18:12:17.273Z",
        "source": "tasker",
        "taskerId": "yannan.zhang@mansfield.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "eat less"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b72ffca",
    "created_at": "2023-02-21T17:57:18.691Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give an example of a Few-Shot prompt."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e26",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:11:44.588Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "amelia.isabelle@outlook.com",
        "attemptedAt": "2023-02-21T18:11:44.715Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5096000f93f5dae6374c9",
        "createdAt": "2023-02-21T18:11:44.715Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b72ffd9",
    "created_at": "2023-02-21T17:57:18.729Z",
    "completed_at": "2023-02-21T18:12:29.754Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best type of car I can buy for my family with 2 kids and a dog?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "What color is your Bugatti?"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e09",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:30.128Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "What color is your Bugatti?"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 47.69,
        "totalTimeSpentSecs": 47.69,
        "attemptedAt": "2023-02-21T18:12:26.958Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5098b90b7131187140496",
        "createdAt": "2023-02-21T18:12:26.958Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "What color is your Bugatti?"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b730019",
    "created_at": "2023-02-21T17:57:18.870Z",
    "completed_at": "2023-02-21T18:12:41.242Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Can you give me a recipe that would be easy to make."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Yes you can fry an egg. Warm a frying pan with some oil in it. Take an egg and break the egg yolk in it. Leave it to fry for 2 minutes. That's it!"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e03",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:41.601Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Yes you can fry an egg. Warm a frying pan with some oil in it. Take an egg and break the egg yolk in it. Leave it to fry for 2 minutes. That's it!"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 53.291,
        "totalTimeSpentSecs": 53.291,
        "attemptedAt": "2023-02-21T18:12:38.468Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50996ef60a76bee8a17cf",
        "createdAt": "2023-02-21T18:12:38.468Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Yes you can fry an egg. Warm a frying pan with some oil in it. Take an egg and break the egg yolk in it. Leave it to fry for 2 minutes. That's it!"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b730018",
    "created_at": "2023-02-21T17:57:18.880Z",
    "completed_at": "2023-02-21T18:12:20.798Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Breeds of dog\n- Dalmation\n- Pointer\n- Husky"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "-Wheaten Terrier\n-Poodle\n-Jack Russel"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e04",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:21.147Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "-Wheaten Terrier\n-Poodle\n-Jack Russel"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 27.299,
        "totalTimeSpentSecs": 27.299,
        "attemptedAt": "2023-02-21T18:12:18.053Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50982d3e8b3858f408a50",
        "createdAt": "2023-02-21T18:12:18.053Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "-Wheaten Terrier\n-Poodle\n-Jack Russel"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b73001c",
    "created_at": "2023-02-21T17:57:18.915Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How long does it take for a apple to decompose?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5e02",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.913Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "alexanderdcolby@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505fed0be22b17b730048",
    "created_at": "2023-02-21T17:57:19.034Z",
    "completed_at": "2023-02-21T18:12:10.562Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "- Tree\n- Grass\n- Bush"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "grass"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5dfd",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:11.012Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "grass"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 13.043,
        "totalTimeSpentSecs": 13.043,
        "attemptedAt": "2023-02-21T18:12:07.463Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f50977a32fb0c753755861",
        "createdAt": "2023-02-21T18:12:07.463Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "grass"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b73005f",
    "created_at": "2023-02-21T17:57:19.082Z",
    "completed_at": "2023-02-21T18:12:25.639Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Why don't we float into space?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "no space boat"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5dfc",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:25.973Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no space boat"
              ]
            }
          }
        },
        "attemptedBy": "xufq11@gmail.com",
        "activeTimeSpentSecs": 14.316,
        "totalTimeSpentSecs": 14.316,
        "attemptedAt": "2023-02-21T18:12:23.131Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509875ec05d1869c369f1",
        "createdAt": "2023-02-21T18:12:23.131Z",
        "source": "tasker",
        "taskerId": "xufq11@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "no space boat"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505fed0be22b17b730069",
    "created_at": "2023-02-21T17:57:19.114Z",
    "completed_at": "2023-02-21T18:12:45.154Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The world just started to"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "make sense and the human race reached a new nirvana"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5dfb",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:45.558Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "make sense and the human race reached a new nirvana"
              ]
            }
          }
        },
        "attemptedBy": "richard.hammersley@gmail.com",
        "activeTimeSpentSecs": 28.605,
        "totalTimeSpentSecs": 28.605,
        "attemptedAt": "2023-02-21T18:12:42.163Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5099a26649ae1699d6d13",
        "createdAt": "2023-02-21T18:12:42.163Z",
        "source": "tasker",
        "taskerId": "richard.hammersley@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "make sense and the human race reached a new nirvana"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a2c",
    "created_at": "2023-02-21T17:57:19.378Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write a function in Python that sums all the provided arguments"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c44",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:19.368Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:12:19.448Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5098316f3a41cbc53af67",
        "createdAt": "2023-02-21T18:12:19.448Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a3a",
    "created_at": "2023-02-21T17:57:19.413Z",
    "completed_at": "2023-02-21T18:12:34.643Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me how to make a Tiramisu cake"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Ask Mary Berry"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c28",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:35.054Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Ask Mary Berry"
              ]
            }
          }
        },
        "attemptedBy": "amelia.isabelle@outlook.com",
        "activeTimeSpentSecs": 12.724,
        "totalTimeSpentSecs": 12.724,
        "attemptedAt": "2023-02-21T18:12:32.110Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509905ec05d1869c36a8a",
        "createdAt": "2023-02-21T18:12:32.110Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Ask Mary Berry"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a36",
    "created_at": "2023-02-21T17:57:19.413Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Please explain how ChatGPT work"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c43",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.929Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "yannan.zhang@mansfield.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a4c",
    "created_at": "2023-02-21T17:57:19.459Z",
    "type": "textcollection",
    "status": "pending",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Provide a brief introduction about Vincent van Gogh "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c25",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:24.883Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "qianwei.jia@seh.ox.ac.uk",
        "attemptedAt": "2023-02-21T18:12:25.026Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509896ae3c6976bb1d64c",
        "createdAt": "2023-02-21T18:12:25.026Z",
        "source": "tasker",
        "taskerId": "qianwei.jia@seh.ox.ac.uk",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a80",
    "created_at": "2023-02-21T17:57:19.578Z",
    "completed_at": "2023-02-21T18:12:49.287Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Let me give you an overall introduction. Next we can dive into the details for each step."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Then we will finish off with a conclusion"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c22",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.668Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Then we will finish off with a conclusion"
              ]
            }
          }
        },
        "attemptedBy": "nauynix@gmail.com",
        "activeTimeSpentSecs": 24.206,
        "totalTimeSpentSecs": 24.206,
        "attemptedAt": "2023-02-21T18:12:46.073Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5099e26649ae1699d6dba",
        "createdAt": "2023-02-21T18:12:46.073Z",
        "source": "tasker",
        "taskerId": "nauynix@gmail.com",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Then we will finish off with a conclusion"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a9f",
    "created_at": "2023-02-21T17:57:19.672Z",
    "completed_at": "2023-02-21T18:12:41.586Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What are some good conversation topics to break the ice?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "What's your favourite cocktail?"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c1f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:41.952Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "What's your favourite cocktail?"
              ]
            }
          }
        },
        "attemptedBy": "mark.eid@balliol.ox.ac.uk",
        "activeTimeSpentSecs": 15.717,
        "totalTimeSpentSecs": 15.717,
        "attemptedAt": "2023-02-21T18:12:38.735Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509970f7597c65bafecff",
        "createdAt": "2023-02-21T18:12:38.735Z",
        "source": "tasker",
        "taskerId": "mark.eid@balliol.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "What's your favourite cocktail?"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f505ff6b393c18cb6b5a9e",
    "created_at": "2023-02-21T17:57:19.672Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "To start, use keywords to search for related websites. Then you filter out the most-related pages. Finally, you read the document to learn what you have queried."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c1e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.955Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "xufq11@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505ff6b393c18cb6b5ac7",
    "created_at": "2023-02-21T17:57:19.793Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Impressionism representative artist\n- Claude Monet\n- Berthe Morisot\n- Camille Pissarro"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c1c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.824Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "jinghua.zhang@bnc.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505ff6b393c18cb6b5ad0",
    "created_at": "2023-02-21T17:57:19.805Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Is the future set in stone or not?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c1a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.913Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "qianwei.jia@seh.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f505ff6b393c18cb6b5ad3",
    "created_at": "2023-02-21T17:57:19.826Z",
    "completed_at": "2023-02-21T18:12:45.912Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Prefer giving three examples; so giving another example if only one or two have been given, but move on to something different if we already have three examples."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "ok"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c17",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:46.338Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ok"
              ]
            }
          }
        },
        "attemptedBy": "alona@everyrun.world",
        "activeTimeSpentSecs": 15.595,
        "totalTimeSpentSecs": 15.595,
        "attemptedAt": "2023-02-21T18:12:42.970Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5099b9c5b088d891185e0",
        "createdAt": "2023-02-21T18:12:42.970Z",
        "source": "tasker",
        "taskerId": "alona@everyrun.world",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "ok"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f50600d0be22b17b730229",
    "created_at": "2023-02-21T17:57:20.247Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write me a story about a wizard"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5dfa",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.934Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "peyton.hammersley@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50600d0be22b17b73023a",
    "created_at": "2023-02-21T17:57:20.333Z",
    "completed_at": "2023-02-21T18:12:41.361Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The beginning of everything was dark suddenly there was"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "light"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b107a47014fa4a5df8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:41.700Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "light"
              ]
            }
          }
        },
        "attemptedBy": "ishwar.karthik@spc.ox.ac.uk",
        "activeTimeSpentSecs": 8.648,
        "totalTimeSpentSecs": 8.648,
        "attemptedAt": "2023-02-21T18:12:38.474Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509960e8a007b9e0a4868",
        "createdAt": "2023-02-21T18:12:38.474Z",
        "source": "tasker",
        "taskerId": "ishwar.karthik@spc.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "light"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f50600d0be22b17b73024f",
    "created_at": "2023-02-21T17:57:20.371Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write a stand-up sketch"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5ddc",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:59.236Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {},
        "attemptedBy": "amelia.isabelle@outlook.com",
        "attemptedAt": "2023-02-21T18:12:59.319Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509abd68995756af4dfa1",
        "createdAt": "2023-02-21T18:12:59.319Z",
        "source": "tasker",
        "taskerId": "amelia.isabelle@outlook.com",
        "response": {}
      }
    ]
  },
  {
    "task_id": "63f50600d0be22b17b730259",
    "created_at": "2023-02-21T17:57:20.412Z",
    "completed_at": "2023-02-21T18:12:47.408Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the best college at Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "Oriel"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dd9",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:47.818Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Oriel"
              ]
            }
          }
        },
        "attemptedBy": "bokharim24@mail.wlu.edu",
        "activeTimeSpentSecs": 4.404,
        "totalTimeSpentSecs": 4.404,
        "attemptedAt": "2023-02-21T18:12:44.384Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f5099c0f7597c65bafed9d",
        "createdAt": "2023-02-21T18:12:44.384Z",
        "source": "tasker",
        "taskerId": "bokharim24@mail.wlu.edu",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "Oriel"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f50600d0be22b17b730279",
    "created_at": "2023-02-21T17:57:20.485Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Translate English to German:\ndog -&gt; hund\nscience -&gt; naturwissenshaften\npotato -&gt; kartoffel"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dd6",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.929Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "ishwar.karthik@spc.ox.ac.uk",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50600d0be22b17b730288",
    "created_at": "2023-02-21T17:57:20.523Z",
    "completed_at": "2023-02-21T18:12:55.502Z",
    "type": "textcollection",
    "status": "completed",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the temperature right now&gt;"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "response": {
      "annotations": {
        "response": "12 *C"
      }
    },
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dd3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:56.456Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [
      {
        "attemptVersion": 0,
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "12 *C"
              ]
            }
          }
        },
        "attemptedBy": "mark.eid@balliol.ox.ac.uk",
        "activeTimeSpentSecs": 8.3,
        "totalTimeSpentSecs": 8.3,
        "attemptedAt": "2023-02-21T18:12:48.346Z",
        "isReview": false
      }
    ],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": [
      {
        "_id": "63f509a09c5b088d8911867e",
        "createdAt": "2023-02-21T18:12:48.346Z",
        "source": "tasker",
        "taskerId": "mark.eid@balliol.ox.ac.uk",
        "response": {
          "annotations": {
            "response": {
              "type": "text",
              "field_id": "response",
              "response": [
                "12 *C"
              ]
            }
          }
        }
      }
    ]
  },
  {
    "task_id": "63f50600d0be22b17b73028d",
    "created_at": "2023-02-21T17:57:20.536Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Summarise Lord of the Rings"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dd2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.934Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "richard.hammersley@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50600d0be22b17b7302d3",
    "created_at": "2023-02-21T17:57:20.750Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Count to 100."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dcd",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.834Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "alona@everyrun.world",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50600d0be22b17b7302d7",
    "created_at": "2023-02-21T17:57:20.758Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me some niche colours:\n-mauve\n-vermilion\n-teal"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dcc",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.934Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "bokharim24@mail.wlu.edu",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50600d0be22b17b7302ea",
    "created_at": "2023-02-21T17:57:20.814Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me how ChatGPT works"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dcb",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.918Z",
    "work_started": true,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "assignedSession": "nauynix@gmail.com",
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506006b393c18cb6b5ca9",
    "created_at": "2023-02-21T17:57:21.044Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Find a way to lead the answer towards mentioning a fact about the Roman Empire, no matter which initial prompt."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c15",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.679Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506006b393c18cb6b5caa",
    "created_at": "2023-02-21T17:57:21.052Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Is AI going to take over the world before or after we destroy it through global warming?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5c12",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.588Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5cc0",
    "created_at": "2023-02-21T17:57:21.173Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Continue writing the following story \"As the sun began to set on a warm summer evening \""
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bf5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.558Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5cc5",
    "created_at": "2023-02-21T17:57:21.181Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Write a piece of code in python using pytorch library to implement a simple CNN model ?  "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bf4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.809Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5ce9",
    "created_at": "2023-02-21T17:57:21.268Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Make and continue sentences like \"to quote a great [profession], [name of historical figure]; [actual quote, or made up quote]\", where we quote someone relevant to the topic, or make up a plausible quote."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bf2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.552Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5d17",
    "created_at": "2023-02-21T17:57:21.414Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Explain how quick sort works"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bef",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.552Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5d27",
    "created_at": "2023-02-21T17:57:21.486Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Planets in the solar system\n- Mercury\n- Venus\n- Earth\n- Mars\n- Jupiter\n- Saturn\n- Uranus"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bee",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.800Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5d28",
    "created_at": "2023-02-21T17:57:21.504Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Words that rapers use frequently ?\n- Crew\n- Homies\n- Ballin'\n- Booty\n- Haters\n- Real talk\n- Chill\n- Money\n- Hustle\n- Grind"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bec",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.488Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5d61",
    "created_at": "2023-02-21T17:57:21.648Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "How do I make pancakes?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5be7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.771Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506016b393c18cb6b5d5c",
    "created_at": "2023-02-21T17:57:21.664Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What should I watch next on Netflix?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5bea",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.672Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304b0",
    "created_at": "2023-02-21T17:57:21.904Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me some Tarantino films:\n- Pulp Fiction\n- Django Unchained\n- Reservoir Dogs"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dc9",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.732Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304b5",
    "created_at": "2023-02-21T17:57:21.932Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Different measures\n- centimeters\n- inches\n- meters"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dc7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.429Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304c8",
    "created_at": "2023-02-21T17:57:21.987Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Top cities in England\n- London\n- Manchester\n- Leeds"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dae",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.573Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304d4",
    "created_at": "2023-02-21T17:57:22.030Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Please write me a CV and cover letter"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5dab",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.646Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304df",
    "created_at": "2023-02-21T17:57:22.052Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Top movies\n- Shawshank Redemption\n- Inception\n- Titanic"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5da9",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.358Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304e6",
    "created_at": "2023-02-21T17:57:22.052Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Where would you live in an ideal world?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5da3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.346Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50601d0be22b17b7304e7",
    "created_at": "2023-02-21T17:57:22.066Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Today I want to get tomatoes, salad, avocados, and "
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5da4",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.406Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50602d0be22b17b73054d",
    "created_at": "2023-02-21T17:57:22.339Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Give the best way to travel from london to beijing"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5da2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.395Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50602d0be22b17b730552",
    "created_at": "2023-02-21T17:57:22.363Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Describe what is machine learning"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d9d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.395Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50602d0be22b17b73056f",
    "created_at": "2023-02-21T17:57:22.434Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What should a person do to get into oxford"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d9c",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.320Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506026b393c18cb6b5f14",
    "created_at": "2023-02-21T17:57:22.908Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Words that political leaders use frequently\n- Change\n- Progress\n- Reform\n- Security\n- Freedom\n- Justice\n- Equality\n- Prosperity\n- Opportunity\n- Values"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5be5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.320Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506026b393c18cb6b5f15",
    "created_at": "2023-02-21T17:57:22.908Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Will there be another pandemic?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ad07a47014fa4a5be3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.320Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506026b393c18cb6b5f2f",
    "created_at": "2023-02-21T17:57:22.978Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "United States, Canada, Australia, Japan, Germany"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bc8",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.344Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506026b393c18cb6b5f44",
    "created_at": "2023-02-21T17:57:23.035Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Piano, guitar, drums, violin, trumpet"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bc5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.282Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506026b393c18cb6b5f55",
    "created_at": "2023-02-21T17:57:23.058Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the weather like today?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bc2",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.320Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506036b393c18cb6b5f7e",
    "created_at": "2023-02-21T17:57:23.181Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Can you recommend a good book to read?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bc1",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.322Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506036b393c18cb6b5fa3",
    "created_at": "2023-02-21T17:57:23.351Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me a joke!"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bbf",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.613Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506036b393c18cb6b5faa",
    "created_at": "2023-02-21T17:57:23.385Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's a fun way to do exercise on your own, without having to leave your room, and with cheap or no equipment? Regular exercises are too tedious, so it's hard to make them into a habit."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bbd",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.608Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730700",
    "created_at": "2023-02-21T17:57:23.404Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Flèche -&gt; Arrow, Robinet -&gt; Tap, Fleurs -&gt; Floweres"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d9b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.310Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506036b393c18cb6b5fdc",
    "created_at": "2023-02-21T17:57:23.483Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Do you have any good book recommendations? I generally like fantasy, or sci-fi stories. Romance is ok, but it shouldn't be the main focus. I prefer light-hearted reads, not those that take themselves too seriously."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bba",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.291Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506036b393c18cb6b5fe2",
    "created_at": "2023-02-21T17:57:23.494Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What should I eat tonight? I can't decide. I've had pizza yesterday for dinner, so not that. I don't like seafood."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bb7",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.308Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730733",
    "created_at": "2023-02-21T17:57:23.548Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "computer - 电脑\nbook - 书\npencil - 铅笔\npen - 签字笔"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d9a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.573Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730738",
    "created_at": "2023-02-21T17:57:23.573Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "dress - 裙子\nshirt - 衬衫\ncoat - 风衣"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d7e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.280Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730749",
    "created_at": "2023-02-21T17:57:23.630Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "create a tutorial demonstrating how to build ChatGPT"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d78",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.130Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b73074a",
    "created_at": "2023-02-21T17:57:23.639Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "in the hitchhikers guide to the galaxy why was the answer to everything 42?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d7b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.099Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730767",
    "created_at": "2023-02-21T17:57:23.699Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "mobile phones no longer exist and"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d77",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.077Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b730768",
    "created_at": "2023-02-21T17:57:23.709Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Why is the sky blue?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d73",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.091Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b7307a8",
    "created_at": "2023-02-21T17:57:23.872Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "nelson mandela was a"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d72",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.474Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b7307ef",
    "created_at": "2023-02-21T17:57:24.056Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "apple\nhuawei\nxiaomi\nsamsumg"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d71",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.478Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50603d0be22b17b7307f0",
    "created_at": "2023-02-21T17:57:24.068Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Which college is the best in Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d6e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.066Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b6171",
    "created_at": "2023-02-21T17:57:24.591Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Coffee, tea, soda, juice, water"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bb5",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.465Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b618e",
    "created_at": "2023-02-21T17:57:24.648Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Finish sets of examples split into sentences with \"And last, but not least [last example]\", if the last example has the same relevance."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5bb3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.047Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b6191",
    "created_at": "2023-02-21T17:57:24.672Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In what year was Oxford University founded?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5b99",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.054Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b61cd",
    "created_at": "2023-02-21T17:57:24.820Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the best part about the city of Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5b94",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.286Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b61df",
    "created_at": "2023-02-21T17:57:24.847Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best way to learn something highly technical?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5b8f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.054Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b61d9",
    "created_at": "2023-02-21T17:57:24.887Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Hot drinks:\n- Tea\n- Coffee"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ac07a47014fa4a5b91",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.465Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b6222",
    "created_at": "2023-02-21T17:57:25.043Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "- Up -&gt; Down\n- Hot -&gt; Cold\n- Hard -&gt; Soft"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b89",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.042Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506046b393c18cb6b6221",
    "created_at": "2023-02-21T17:57:25.043Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Tell me a story about the best lecture ever hosted at Oxford"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b8a",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.380Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506056b393c18cb6b6250",
    "created_at": "2023-02-21T17:57:25.168Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Colleges in Oxford:\n- Hertford\n- Magdalen\n- Christ Church"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b88",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.345Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b730990",
    "created_at": "2023-02-21T17:57:25.209Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Why is Oxford University better than Cambridge?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d6d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.244Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b73099f",
    "created_at": "2023-02-21T17:57:25.239Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "When is Oxford University founded"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d50",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.969Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506056b393c18cb6b6269",
    "created_at": "2023-02-21T17:57:25.242Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The best reasons to study at Oxford university:\n- Full of culture\n- Attracts great people\n- Excellent staff"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b87",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.570Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b73099e",
    "created_at": "2023-02-21T17:57:25.249Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Some examples of bones:\n- Shoulder\n- Femur"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505b007a47014fa4a5d6b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:53.216Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b7309be",
    "created_at": "2023-02-21T17:57:25.347Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Countries with high GDP in the world\n- China\n- USA\n- Japan\n- Germany\n- UK"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d4d",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.898Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b7309d1",
    "created_at": "2023-02-21T17:57:25.401Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The biological animal kingdoms and their drescriptions are the following:\n- Animalia: All multicellular animals that do not have cell walls or chlorophyll. They are heterotrophic and can move41.\n- Plantae: All green plants that have cell walls and chlorophyll. They are autotrophic and usually do not move1.\n- Fungi: Organisms that have cell walls but no chlorophyll. They are heterotrophic and feed by absorbing nutrients from their environment. Examples include moulds, mushrooms, and yeast1.\n- Protista: Mostly unicellular organisms that do not fit into any other kingdom. They can be autotrophic or heterotrophic, and some can move. Examples include amoeba, chlorella, and plasmodium1.\n- Prokaryota: Unicellular organisms that lack a nucleus and other membrane-bound organelles. They have cell walls and can be autotrophic or heterotrophic. Examples include bacteria and blue-green algae1."
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d48",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.254Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b7309df",
    "created_at": "2023-02-21T17:57:25.439Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What are the biggest AI companies"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d42",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.969Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b7309f1",
    "created_at": "2023-02-21T17:57:25.499Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Best Universities in UK\n- Oxford University\n- Cambridge"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d41",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.910Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b730a2d",
    "created_at": "2023-02-21T17:57:25.651Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best chat bot?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d40",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.570Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b730a60",
    "created_at": "2023-02-21T17:57:25.759Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Breeds of cat\n- American short hair\n- Bombay\n- Chartreux"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d3e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.570Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f50605d0be22b17b730a71",
    "created_at": "2023-02-21T17:57:25.831Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Silicon valley is hub for tech startups as London and New York are hubs for financial companies"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505af07a47014fa4a5d3b",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.814Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b63cc",
    "created_at": "2023-02-21T17:57:26.190Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What does GPT stand for?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b85",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.570Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b6407",
    "created_at": "2023-02-21T17:57:26.355Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What makes a certain college better than others at Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 17:55:54",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f505ab07a47014fa4a5b83",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.796Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b640d",
    "created_at": "2023-02-21T17:57:26.386Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "- Up -&gt; Down\n- Hot -&gt; Cold\n- Hard -&gt; Soft"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:8",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e7f966fe3b6608ef40",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.788Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b6440",
    "created_at": "2023-02-21T17:57:26.502Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What is the best part about the city of Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:7",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e791e2757dc7069d8f",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.597Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b6451",
    "created_at": "2023-02-21T17:57:26.563Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Colleges in Oxford:\n- Hertford\n- Magdalen\n- Christ Church"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:9",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e77c40fc29d476f7c3",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:51.893Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b6470",
    "created_at": "2023-02-21T17:57:26.657Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "Hot drinks:\n- Tea\n- Coffee"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:10",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e721802ffa18e01596",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.694Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b6493",
    "created_at": "2023-02-21T17:57:26.743Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What's the best way to learn something highly technical?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:5",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e71981ae18d8a822c0",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.796Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b64a6",
    "created_at": "2023-02-21T17:57:26.795Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "What makes a certain college better than others at Oxford?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:2",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e6ff0871c68482105e",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:52.781Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b64b9",
    "created_at": "2023-02-21T17:57:26.850Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "The best reasons to study at Oxford university:\n- Full of culture\n- Attracts great people\n- Excellent staff"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:4",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e6bf74a0b59114a3fe",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:49.580Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  },
  {
    "task_id": "63f506066b393c18cb6b64df",
    "created_at": "2023-02-21T17:57:26.963Z",
    "type": "textcollection",
    "status": "canceled",
    "instruction": "",
    "instructionObjectId": "63f4da5f7c98cd8d2a7ae58f",
    "params": {
      "fields": [
        {
          "type": "text",
          "field_id": "response",
          "title": "Response",
          "required": true
        }
      ],
      "attachments": [
        {
          "type": "text",
          "content": "In what year was Oxford University founded?"
        }
      ]
    },
    "is_test": false,
    "urgency": "standard",
    "metadata": {
      "upload_group_id": "2023-02-21 14:44:54:1",
      "upload_source": "csv"
    },
    "processed_attachments": [],
    "project": "Supervised Fine-Tuning",
    "priority": 0,
    "postProcessingResults": {},
    "taxonomyVersion": "63f165e6e01263ade4b79a18",
    "attachmentS3Downloads": [],
    "unique_id": "63f505f46b5c938a7f791532:63f4d8e6887856efb44fdf72",
    "project_param_version": 2,
    "projectId": "63f14e3be2bc5fee43a7024d",
    "batch": "Third",
    "batchId": "63f505f46b5c938a7f791532",
    "updated_at": "2023-02-21T18:12:50.687Z",
    "work_started": false,
    "isProcessed": false,
    "attempts": [],
    "customer_labeled": false,
    "isEdgeCase": false,
    "pipelineName": "standard_task",
    "projectPipeline": "standard_task",
    "responseHistory": []
  }
]