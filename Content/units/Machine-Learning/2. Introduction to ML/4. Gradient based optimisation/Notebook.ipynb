{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Based Optimisation\n",
    "\n",
    "## Introduction\n",
    "\n",
    ">Previously, we learnt how to optimise the parameters of linear regression using its analytical solutions. However, this technique has some fundamental drawbacks:\n",
    "\n",
    "- It is available only for special cases of ML methods, i.e. __it cannot be generalised.__\n",
    "- Its computation is not feasible for large datasets and cases involving many features.\n",
    "\n",
    "In this notebook, we learn how to use **gradient-based optimisation** as another technique to find model parameterisations that perform well.\n",
    "\n",
    "Gradient-based optimisation is not exclusively used in ML. It is a technique used for optimising all kinds of functions in all kinds of domains.\n",
    "\n",
    "> We will employ gradient-based optimisation to minimise the criteria of our ML algorithms.\n",
    "\n",
    "To improve your understanding, a depiction of gradient-based optimisation is provided in the diagram below. In our case, $f(w)$ represents the criterion that we intend to minimise, which varies with the model parameters ($w$ & $b$ for linear regression):\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Gradient-Based Optimisation\n",
    "\n",
    "Our loss is simply a mathematical function that depends on the parameters of our model (for example, we used the mean-squared error (MSE) loss function in the previous notebooks).\n",
    "Our objective is to move the parameters to the point where this loss is minimised.\n",
    "\n",
    "> If we evaluated the loss value for every possible different parameterisation of our model, we would produce a **loss surface**. \n",
    "\n",
    "The next step would involve identifying the lowest point on this surface. \n",
    "- At this point, it will have a gradient (steepness) of zero with respect to the parameters.\n",
    "- As the parameters move away from that minima in any direction, the gradient will increase in that direction.\n",
    "\n",
    "To return to the minima, we would __move our weights in the opposite direction to the gradient__ (simply subtract it).\n",
    "\n",
    "![](./images/grad-based-optim.jpg)\n",
    "\n",
    "## Numerical Example\n",
    "\n",
    "Below is an example showing the shift direction for parameter $W$, initialised as $w=4$, for a surface given by\n",
    "\n",
    "$$\n",
    "L=(W-2)^2\n",
    "$$ \n",
    "\n",
    "At this point on the surface, the loss gradient with respect to this parameter is positive; therefore, we should shift it in the negative direction to move it closer to the optima.\n",
    "\n",
    "![](images/sgd_numerical_example.jpg)\n",
    "\n",
    "Below is a more complex potential loss surface with more than one parameter (the vertical axis represents the loss value, while others represent the parameter values). In reality, we will often have many more features, and we will not be able to visualise the loss surface since this would require more than three dimensions.\n",
    "\n",
    "<img style=\"height: 200px\" src='./images/comp-loss-surface.png'/>\n",
    "\n",
    "> **Note: Since gradient-based optimisation depends on us computing the gradient of the loss function, our loss function and model must be fully differentiable (i.e. they must be a smooth, continuous function).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent is an iterative, gradient-based optimisation technique. \n",
    "\n",
    "In other words, it is a technique for finding the minima (or maxima) of a function, and it does so by iteratively moving the parameters downhill in the opposite direction to the surface gradient.\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)\n",
    "\n",
    "## The learning rate ($\\alpha$)\n",
    "\n",
    "To update the parameters, we shift them in the opposite direction to the gradient. However, by what degree should they be shifted?\n",
    "\n",
    "> The learning rate, $\\alpha$ (often abbreviated as `lr` in the source code), __multiplies the gradient__ to decrease (usually) or increase its magnitude.\n",
    "\n",
    "Thus, the `step_size` is the `gradient` multiplied by the `lr`.\n",
    "\n",
    "### Things to note\n",
    "\n",
    "#### Low `lr`\n",
    "\n",
    "If the `lr` is significantly low, we may \n",
    "- __experience a delay__ in the convergence.\n",
    "- be unable to move from the local minima or saddle points (we will go over that shortly).\n",
    "\n",
    "![title](images/low-lr.jpg)\n",
    "\n",
    "#### High `lr`\n",
    "\n",
    "If the `lr` is significantly high, we may \n",
    "- jump from the minimum.\n",
    "- diverge rather than __converge__.\n",
    "\n",
    "![title](images/high-lr.jpg)\n",
    "\n",
    "Therefore, we include the `lr` to scale up/down the steps. \n",
    "\n",
    "> Note, however, that the `lr` should mostly be less than 1.\n",
    "\n",
    "Experiment with the learning rate, and adjust it until your model converges.\n",
    "\n",
    "![title](images/convergence.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Optima\n",
    "\n",
    "If we are attempting to minimise a function with respect to 1 or 2 parameters, the gradient descent may get stuck in local optima.\n",
    "\n",
    "However, most of the useful models in practice depend on many more parameters (neural networks can easily have millions).\n",
    "\n",
    "> As the number of parameters increases, it becomes exponentially unlikely that any parameterisation occurs at the minima, rather than at a saddle point; therefore, there is still room for improvement.\n",
    "\n",
    "Furthermore, __in practice, we often do not need to find a global optima.__\n",
    "The local optima can be good enough to realise the required performance.\n",
    "\n",
    "Moreover, we can attempt to counter the inability to move from the local optima using different optimisation algorithms, such as [gradient descent with (Nesterov) momentum](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "The diagrams shown above visualise how a single parameter affects the loss. \n",
    "\n",
    "A model with multiple parameters (such as a weight and a bias, or multiple weights) would be optimised in the same way; there would simply be more of these functions. \n",
    "\n",
    "> Think of each of the graphs as a cross-section through a **loss surface**. \n",
    "\n",
    "A loss surface is shown below, which visualises the variation in a model's criterion as a function of both parameters.\n",
    "\n",
    "$$\n",
    "L = w_1^4 + w_2^2\n",
    "$$\n",
    "\n",
    "<img style=\"height: 300px\" src='images/x2x4.png'/>\n",
    "\n",
    "![](images/multivariate_sgd.jpg)\n",
    "\n",
    "If we know the function from which the loss is computed and it is differentiable, we can calculate the derivative of the loss with respect to our model parameters by hand or using an automatic differentiation graph (we will cover this in Deep Learning).\n",
    "\n",
    "Thereafter, we can iteratively move each parameter in the direction of the opposite gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A helper function\n",
    "\n",
    "We will use this code shortly to visualise the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(losses):\n",
    "    \"\"\"Helper function for plotting the loss against the epoch\"\"\"\n",
    "    plt.figure() # make a figure\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(losses) # plot costs\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "Run the cells below to obtain the data and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aicore\n",
      "  Downloading aicore-0.0.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /home/ivanyingx/miniconda3/lib/python3.9/site-packages (from aicore) (1.21.4)\n",
      "Collecting scikit-learn>=0.23.2\n",
      "  Downloading scikit_learn-1.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7 MB 206 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /home/ivanyingx/miniconda3/lib/python3.9/site-packages (from scikit-learn>=0.23.2->aicore) (1.7.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 90.6 MB/s \n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn, aicore\n",
      "Successfully installed aicore-0.0.3 joblib-1.1.0 scikit-learn-1.0.1 threadpoolctl-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install aicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivanyingx/miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "from aicore.ml import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use `data.split` to split the data into training, validation, and test sets.\n",
    "(X_train, y_train), (X_validation, y_validation), (X_test, y_test) = data.split(\n",
    "    datasets.load_boston(return_X_y=True)\n",
    ")\n",
    "X_train, X_validation, X_test = data.standardize_multiple(X_train, X_validation, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "Here is the same model we implemented previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, optimiser, n_features): # initalise parameters \n",
    "        self.w = np.random.randn(n_features) ## randomly initialise the weight\n",
    "        self.b = np.random.randn() ## randomly initialise the bias\n",
    "        self.optimiser = optimiser\n",
    "        \n",
    "    def predict(self, X): # how do we calculate the output from an input in our model?\n",
    "        ypred = X @ self.w + self.b ## make a prediction using a linear hypothesis\n",
    "        return ypred # return prediction\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        all_costs = [] ## initialise an empty list of costs to plot later\n",
    "        for epoch in range(self.optimiser.epochs): ## for this many complete the runs through the dataset    \n",
    "\n",
    "            # MAKE PREDICTIONS AND UPDATE MODEL\n",
    "            predictions = self.predict(X) ## make predictions\n",
    "            new_w, new_b = self.optimiser.step(self.w, self.b, X, predictions, y) ## calculate updated params\n",
    "            self._update_params(new_w, new_b) ## update the model weight and bias\n",
    "            \n",
    "            # CALCULATE THE LOSS FOR VISUALISATION\n",
    "            cost = mse_loss(predictions, y) ## compute the loss \n",
    "            all_costs.append(cost) ## add the cost for this batch of examples to the list of costs (for plotting)\n",
    "\n",
    "        plot_loss(all_costs)\n",
    "        print('Final cost:', cost)\n",
    "        print('Weight values:', self.w)\n",
    "        print('Bias values:', self.b)\n",
    "\n",
    "    \n",
    "    def _update_params(self, new_w, new_b):\n",
    "        self.w = new_w ## set this instance's weights to the new weight value passed to the function\n",
    "        self.b = new_b ## do the same for the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The criterion\n",
    "\n",
    "Recall the formula:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    L_{mse} = \\frac{1}{N}\\sum_{i}^{N}(\\hat{y_i} - y_i)^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_hat, labels): # define the criterion (loss function)\n",
    "    errors = y_hat - labels ## calculate the errors\n",
    "    squared_errors = errors ** 2 ## square the errors\n",
    "    mean_squared_error = sum(squared_errors) / len(squared_errors) ## calculate the mean \n",
    "    return mean_squared_error # return the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimiser: gradient descent\n",
    "\n",
    "With linear regression, it is possible to swap out different optimisers and use the same model, data and criterion.\n",
    "\n",
    "#### Implementing gradient descent from scratch\n",
    "\n",
    "Below is a derivation for computing the rate of change (gradient) in the loss with respect to our model's parameters when using a linear model and the MSE loss function.\n",
    "![title](images/NN1_single_grad_calc.jpg)\n",
    "\n",
    "Complete the class below to return the derivative of the loss w.r.t the weight and bias by implementing the above equations in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGDOptimiser:\n",
    "    def __init__(self, lr, epochs):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _calc_deriv(self, features, predictions, labels):\n",
    "        m = len(labels) ## m = number of examples\n",
    "        diffs = predictions - labels ## calculate the errors\n",
    "        dLdw = 2 * np.sum(features.T * diffs).T / m ## calculate the loss derivative with respect to the weights\n",
    "        dLdb = 2 * np.sum(diffs) / m ## calculate the loss derivative with respect to the bias\n",
    "        return dLdw, dLdb ## return the rate of change in the loss with respect to w and b, separately.\n",
    "\n",
    "    def step(self, w, b, features, predictions, labels):\n",
    "        dLdw, dLdb = self._calc_deriv(features, predictions, labels)\n",
    "        new_w = w - self.lr * dLdw\n",
    "        new_b = b - self.lr * dLdb\n",
    "        return new_w, new_b\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The combination\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimiser = SGDOptimiser(lr=learning_rate, epochs=num_epochs)\n",
    "model = LinearRegression(optimiser=optimiser, n_features=X_train.shape[1])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn` example\n",
    "\n",
    "`sklearn` packs all the steps above into a simple [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_model = LinearRegression() ## instantiate the linear-regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "    return mse_loss(\n",
    "        model.predict(X),\n",
    "        y\n",
    "    )\n",
    "\n",
    "print(f\"Training loss before fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(\n",
    "    f\"Validation loss before fit: {calculate_loss(model, X_validation, y_validation)}\"\n",
    ")\n",
    "print(f\"Test loss before fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_regression_model.fit(X_train, y_train) ## fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform the same task; however, we will fit the model for some epochs and observe the loss after training, validation and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training loss after fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(f\"Validation loss after fit: {calculate_loss(model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss after fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can examine the final parameters of the model when using sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('final weights:', model.coef_)\n",
    "print('final bias:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Gradient-Based Optimisation\n",
    "\n",
    "> Gradient-based optimisation uses __heuristics,__ which indicate the method of improvement w.r.t. the loss (e.g. how to minimise it).\n",
    "\n",
    "There are other available options, such as analytical solutions; however, they have noticeable shortcomings.\n",
    "\n",
    "We could also search for parameters __randomly__; however,\n",
    "\n",
    "- our search region may not contain an optimal parameterisation for our model. For example, if we allowed bias `[-10, 10]`, we would never obtain the solution. \n",
    "- we will experience an exponential increase in runtime with each additional parameter.\n",
    "- there will be no feedback from the process (the gradient is our feedback here).\n",
    "\n",
    "> The question of what to do when the data do not fit into the memory remains unanswered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing the Whole Dataset Through Each Prediction\n",
    "\n",
    "We are aware that to perform gradient-based optimisation, inputs must be passed through the model (forward pass), following which the loss is computed and its variation with respect to the model's parameters investigated (backward pass).\n",
    "\n",
    "Modern datasets can be absolutely large. This implies that the forward pass can be time-intensive, since the function represented by the model has to be applied to each provided input for a forward pass.\n",
    "\n",
    "> Passing the full dataset through the model at each pass is called **full-batch gradient descent**.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- The whole dataset may hinder generalisation and lead to overfitting.\n",
    "- It is quite slow (relatively slow memory access, more cache misses, etcetera).\n",
    "\n",
    "\n",
    "## Using a Single Datapoint for Each Update\n",
    "\n",
    "If we pass a single example to our network and backpropagate based on that, these will probably occur:\n",
    "\n",
    "- the `gradient` will vary __significantly__ (a single example is usually uninformative for the whole task).\n",
    "- the `outliers` (special data points, which could as well be noise and are completely non-representative of the task) will have a considerable effect on the dataset.\n",
    "\n",
    "The approach involving passing single examples through the model at each pass is called **online stochastic gradient descent**.\n",
    "\n",
    "If, for some reason (memory constraints or examples come in as a stream), we have to employ this approach, mini-batch gradient descent would be the best solution.\n",
    "\n",
    "## Mini-Batch Gradient Descent\n",
    "\n",
    "The modern technique for conducting training involves neither the whole dataset nor the single datapoint (fully stochastic). \n",
    "\n",
    "Instead, we use mini-batch training:\n",
    "\n",
    "> Sample several (usually `64-2048`, depending on the memory) datapoints to compute a sample of the gradient.\n",
    "\n",
    "Most optimisation algorithms converge at a considerably high speed if they are allowed to rapidly compute approximate gradients rather than slowly compute exact gradients. \n",
    "\n",
    "The size of the mini-batch is called the **batch size**, and this technique is currently the most widely used, particularly in neural networks.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- The size can be adjusted to fit the memory on most machines.\n",
    "- High speed (parallelise is easy to realise for multiples of `2`).\n",
    "- It improves generalisation as each batch is slightly noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shuffling\n",
    "\n",
    "Data shuffling is particularly important for __large and highly complex models__ (neural networks). If this is not carried out, we might risk the following:\n",
    "\n",
    "- The same updates may be provided to the model at each batch. Since we intend to estimate the total average, the batches must be different.\n",
    "- The model 'memorises' the batch (the occurs in neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor Conditioning\n",
    "\n",
    "Different features in different datasets can have different ranges.\n",
    "- Some features can be binary or in the `[0, 1]` range.\n",
    "- Others have values in the hundreds or even thousands.\n",
    "\n",
    "This is problematic for most ML models because when a small change in the weight connected to features with large values occurs, the output changes significantly. This increases the influence of the weight, and consequently the feature, simply because it is larger. \n",
    "\n",
    "Resultantly, the loss function will appear as that shown in the image below: steep in one direction and shallow in another.\n",
    "\n",
    "![](images/unnormalised.png)\n",
    "\n",
    "In the steep direction, the learning rate will have to be sufficiently low to prevent diverging optimisation. However, because the gradient signal in the other direction has an overly low intensity, no progress will be made in that direction.\n",
    "\n",
    "> If the features are on different orders of magnitude, the maximum learning rate that works will be overly small to make progress in every direction.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider a case with two weights, `a` and `b`, and a single example, `x`, with two features:\n",
    "\n",
    "- the first has a value `0.1`, whereas the second has a value of `1000`.\n",
    "\n",
    "Now, the formula for the linear regression would be\n",
    "\n",
    "$$\n",
    "    \\hat{y} = 0.1a + 1000b\n",
    "$$\n",
    "\n",
    "Now, we investigate the impact of `a` and `b` on $\\hat{y}$:\n",
    "- $a = 10, b = 0.001$ - `a` and `b` have the same impact on $\\hat{y}$.\n",
    "- $a = 1, b = 1$ - `b` has `10000` times (!!!) more impact on $\\hat{y}$.\n",
    "\n",
    "It is unlikely that `a` has `10000` times less impact on the value we intend to predict (this is also unlikely in the real world).\n",
    "\n",
    "> We should assume that all variables are __equally important, unless we verify them__ via statistical testing or other measures.\n",
    "\n",
    "The range of the values __is not as important a factor__ as the relative differences between the values.\n",
    "\n",
    "#### Solution 1\n",
    "\n",
    "One idea would be to use a different learning rate for each weight. However, we will have to search for the correct learning rate as many times as the number of parameters available. In many cases, examples can have a large number of features (in images, each pixel is a feature).\n",
    "\n",
    "#### Solution 2: normalisation or standardisation\n",
    "\n",
    "As a better solution, the data can be normalised.\n",
    "\n",
    "> Normalisation is the process of bringing features to the same value range.\n",
    "\n",
    "This ensures that the relative differences between the values for each feature are prioritised, not the scale.\n",
    "\n",
    "> It is good practice to always normalise features, unless they are not continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation and Standardisation\n",
    "\n",
    "There are numerous schemes to put values in the `[0, 1]` range. Here, we will employ the `minmax` approach.\n",
    "We can do this by subtracting the minimum and subsequently dividing by the range (feature normalisation).\n",
    "\n",
    "![title](images/normalisation.jpg)\n",
    "\n",
    "Alternatively, we can use a similar method called standardisation, where we subtract the mean and subsequently divide by the standard deviation.\n",
    "\n",
    "![](images/standardisation.jpg)\n",
    "\n",
    "Feature normalisation puts the gradients of each different model parameter in the same order of magnitude. This converts loss surfaces that appear as *valleys* into loss surfaces that appear as *bowls*. Feature normalisation promotes optimisation for all model parameters using the same learning rate.\n",
    "\n",
    "![](images/bowl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Always normalise and standardise your input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation Issues\n",
    "\n",
    "### Data leakage\n",
    "\n",
    "The statistics computed from the unsplit dataset will contain information about every example.\n",
    "\n",
    "Normalising dataset splits based on such statistics will leak information about the test and validation sets.\n",
    "\n",
    "> Always split before normalising your data. \n",
    "\n",
    "### Training-testing skew\n",
    "\n",
    "This occurs when the training data appear different from the testing data. This can be a result of normalising the validation or testing sets using their mean and standard deviation, rather than the same ones employed to normilise the training data. If the other sets have different statistics, your model may receive inputs that appear rather different from those on which it was trained to make predictions.\n",
    "\n",
    "> All data sets should be normalised using the same statistics.\n",
    "\n",
    "Normalise your validation and test sets using the mean and standard deviation from your training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Below, we provide a function for normalising data. Notice how it computes the statistics if they are not provided (as it should for the training set), but will otherwise allow you to pass them in (as you should for the other sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(dataset, mean=None, std=None):\n",
    "    if mean is None and std is None:\n",
    "        mean, std = np.mean(dataset, axis=0), np.std(\n",
    "            dataset, axis=0\n",
    "        )  ## get the mean and standard deviation of the dataset\n",
    "    standardized_dataset = (dataset - mean) / std\n",
    "    return standardized_dataset, (mean, std)\n",
    "\n",
    "X_train, (mean, std) = standardize_data(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of\n",
    "\n",
    "- the gradient-based optimisation and learning rate concepts.\n",
    "- how to implement the stochastic gradient descent algorithm from scratch in Python.\n",
    "- how to implement linear regression from scratch in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2592652612463181e69ac003232387e3e9a99279aa6b168e76f5df16d5110f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
