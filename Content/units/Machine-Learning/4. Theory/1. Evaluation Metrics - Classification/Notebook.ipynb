{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - Classification\n",
    "\n",
    "### Learning Objectives:\n",
    "- [Evaluation metrics: why do we need them?](#Evaluation-metrics:-why-do-we-need-them?)\n",
    "- [Classification Metrics](#Classification-Metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> __Evaluation metrics__, as the name suggests, are metrics used to measure the performance of a model or algorithm. \n",
    "\n",
    "There are numerous evaluation metrics. Certain metrics can only be used for certain types of models, and different metrics can be used to evaluate different performance areas. \n",
    "\n",
    "Therefore, the optimal metric will vary depending on the following:\n",
    "- the model.\n",
    "- the data.\n",
    "- the goal.\n",
    "\n",
    "### Importance of metrics\n",
    "\n",
    "The process of building models works on a constructive feedback principle. \n",
    "\n",
    "A model is built, feedback is obtained via metrics, improvements are made, and the cycle continues until the desired performance is achieved. \n",
    "\n",
    "By evaluating a model using multiple (appropriate) metrics, we can\n",
    "- ensure that it is robust.\n",
    "- tune it in multiple ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The insufficiency of the loss\n",
    "\n",
    "> The loss is rarely taken as the main metric in ML tasks.\n",
    "\n",
    "Loss allows us to learn the things that we are really after and often works as a proxy for the real goal.\n",
    "\n",
    "> Always evaluate the loss, but do not rely only on it.\n",
    "\n",
    "Human assessment of performance is still required. Occasionally, the loss may be abruptly large, and yet the model will work great for the task (GANs are an example).\n",
    "\n",
    "Other times, the loss may be minimal, but the model will not work as intended (reinforcement learning and wrong reward function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "In any classification problem, the goal is to predict the category of a given observation based on the general properties of a training dataset. \n",
    "\n",
    "In this context, the simplest way to measure performance, whether with binary or multiclass classification, is to measure the number of correct predictions out of the whole dataset.\n",
    "\n",
    "> Accuracy is defined as the percentage of correct predictions out of all the predictions.\n",
    "\n",
    "\n",
    "#### Example\n",
    "\n",
    "Create an `accuracy` function that accepts the `reduction` function (set it to the default value, `= np.mean`) and apply it to `vector`, which is `labels` equal to `targets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def accuracy(labels, targets, reduction=np.mean):\n",
    "    return reduction(labels == targets)\n",
    "\n",
    "\n",
    "targets = np.random.randint(0, 10, size=100)\n",
    "labels = np.random.randint(0, 10, size=100)\n",
    "\n",
    "accuracy(labels, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merits of accuracy\n",
    "\n",
    "- The same estimation method can be employed for any classification task.\n",
    "- The higher the accuracy, the better.\n",
    "\n",
    "#### Demerits of accuracy\n",
    "\n",
    "Accuracy, although helpful, is useless in some cases.\n",
    "\n",
    "Consider a dataset with `10` positive labels and `90` negative labels. If we always predict the negative labels, we will achieve `90%` accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.concatenate((np.zeros(90), np.ones(10)))\n",
    "predictions = np.zeros(100)\n",
    "\n",
    "accuracy(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This highlights the need to monitor other metrics as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "If there are two categories, and we consider one to be 'Positive' and the other to be 'Negative', we can derive the evaluation metrics that measure more specific aspects of performance by categorising the prediction outcome under the following four categories:\n",
    "\n",
    "- __True positive:__ the model predicts the label to be 'Positive', and the true label is 'Positive'.\n",
    "- __True negative:__ the model predicts the label to be 'Negative', and the true label is 'Negative'.\n",
    "- __False positive:__ the model predicts the label to be 'Positive', and the true label is 'Negative'.\n",
    "- __False negative:__ the model predicts the label to be 'Negative', and the true label is 'Positive'.\n",
    "\n",
    "These outcomes can be displayed in a tabular form, in what is known as a __confusion matrix:__\n",
    "\n",
    "<p align=center><img src=images/confusion-matrix.png width=600></p>\n",
    "\n",
    "[Source](https://glassboxmedicine.com/2019/02/17/measuring-performance-the-confusion-matrix/)\n",
    "\n",
    "> The values that go in each cell can either be the absolute frequency of that class (e.g. the actual number of false positives) or the normalised value (false positives in the `[0, 1]` range).\n",
    "\n",
    "Conventionally, we go with the first case, although the second may be useful for comparing the proportions of each cell.\n",
    "\n",
    "From this grouping of the possible outcomes of a binary prediction, we can come up with useful metrics. Let us start with the `true positive` calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True positive\n",
    "\n",
    "> A true positive for a binary case occurs when a model predicts `true` and the label is `true`.\n",
    "\n",
    "*Example*\n",
    "\n",
    "Code a `true_positive` function that accepts `predictions` and `targets` as arguments. \n",
    "\n",
    "- Use `astype(bool)` on `labels` and `targets`.\n",
    "- Negate any of the `labels` / `targets` if needed.\n",
    "- Return `np.sum` with `boolean` and (`&` for numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assume they are binary\n",
    "def true_positive(labels, targets):\n",
    "    return np.sum(labels.astype(bool) & targets.astype(bool))\n",
    "\n",
    "true_positive(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True negative\n",
    "\n",
    "> A true negative for a binary case occurs when a model predicts `false` and the label is `false`.\n",
    "\n",
    "*Example*\n",
    "\n",
    "Code a `true_negative` function that accepts `predictions` and `targets` as arguments. \n",
    "\n",
    "- Use `astype(bool)` on `labels` and `targets`.\n",
    "- Negate any of the `labels` / `targets` if needed.\n",
    "- Return `np.sum` with `boolean` and (`&` for numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assume they are binary\n",
    "def true_negative(labels, targets):\n",
    "    return np.sum(~labels.astype(bool) & ~targets.astype(bool))\n",
    "\n",
    "true_negative(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False positive\n",
    "\n",
    "> A false positive for a binary case occurs when a model predicts `true` and the label is `false`.\n",
    "\n",
    "*Example*\n",
    "\n",
    "Code a `false_positive` function that accepts `predictions` and `targets` as arguments. \n",
    "\n",
    "- Use `astype(bool)` on `labels` and `targets`.\n",
    "- Negate any of the `labels` / `targets` if needed.\n",
    "- Return `np.sum` with `boolean` and (`&` for numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assume they are binary\n",
    "def false_positive(labels, targets):\n",
    "    return np.sum(~labels.astype(bool) & targets.astype(bool))\n",
    "\n",
    "false_positive(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False negative\n",
    "\n",
    "> A false positive for a binary case occurs when a model predicts `false` and the label is `true`.\n",
    "\n",
    "*Example*\n",
    "\n",
    "Code a `false_negative` function that accepts `predictions` and `targets` as arguments. \n",
    "\n",
    "- Use `astype(bool)` on `labels` and `targets`.\n",
    "- Negate any of the `labels` / `targets` if needed.\n",
    "- Return `np.sum` with `boolean` and (`&` for numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assume they are binary\n",
    "def false_negative(labels, targets):\n",
    "    return np.sum(labels.astype(bool) & ~targets.astype(bool))\n",
    "\n",
    "false_negative(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the confusion matrix\n",
    "\n",
    "Given the above, we can use `sklearn` `plot_confusion_matrix` to easily view the confusion matrix for the `breast_cancer` dataset.\n",
    "\n",
    "Split the dataset into `training` & `test` sets only. Fit on the training set, evaluate predictions on the tests, and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Loading the breast-cancer dataset\n",
    "X, Y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Confusion Matrix:\n",
      "Normalized Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff6a8d011f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Fitting the logistic-regression model to the data\n",
    "myLogisticModel = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, Y_train)\n",
    "y_hat = myLogisticModel.predict(X_test)\n",
    "\n",
    "# Displaying the confusion matrix\n",
    "print(\"True Confusion Matrix:\")\n",
    "plot_confusion_matrix(myLogisticModel, X_test, Y_test, display_labels=[\"benign\", \"malignant\"])\n",
    "print(\"Normalized Confusion Matrix:\")\n",
    "plot_confusion_matrix(myLogisticModel, X_test, Y_test, normalize='pred', display_labels=[\"benign\", \"malignant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy by the confusion matrix\n",
    "\n",
    "Accuracy can be defined using the confusion matrix as well.\n",
    "\n",
    "$$ \n",
    "\\text{Acc} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "Let us use `sklearn` to calculate the accuracy metric and compare the result with our implementation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (our): 0.9590643274853801\n",
      "Accuracy (scikit-learn) 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy (our):\", accuracy(Y_test, y_hat))\n",
    "print(\"Accuracy (scikit-learn)\", accuracy_score(Y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our first evaluation metric, our model seems to exhibit good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Precision__ is another commonly used evaluation metric.\n",
    "\n",
    "> Precision is the ratio of correctly predicted positives to the total number of predicted positives.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
    "\n",
    "Precision is the answer to the question: 'When a model predicts TRUE, how often is it correct?'\n",
    "\n",
    "In the breast-cancer context, precision answers the question: 'Of all the times we predicted a breast tumour to be malignant, how many times was it actually malignant?' \n",
    "\n",
    "It is an important measure for ensuring that the performance of a model is evaluated appropriately. \n",
    "\n",
    "For instance, if we are building a system to predict if we should decrease the credit limit on a particular account, we want to be confident in our prediction or it may result in customer dissatisfaction. In this context, precision is a very relevant measure of performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Thought experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider our current dataset, and assume that `560` of the patients have a benign tumour, while 9 patients have a malignant tumour. \n",
    "\n",
    "If we create a model that always predicts the tumour to be benign (negative), we obtain the following:\n",
    "- An accuracy of $\\frac{560}{569} = 98.4\\%$, which suggests that our model performed well. We know that the model design is poor, which once again reflects the fact that accuracy is a poor metric in the case of a non-symmetric data distribution. Regarding the precision, since we have no true positives or false positives, the precision is undefined (equation divided by zero), which highlights the poor performance of the model. \n",
    "\n",
    "__Similar to the case with accuracy, we want the precision to be as close to 1 as possible.__\n",
    "\n",
    "Below, we compute the precision of our model using `numpy` and the in-built function in scikit-learn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Code a `precision` function that accepts `labels and predictions` as arguments (remember to cache the `true_positive` value to avoid repeating the calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Python): 0.9902912621359223\n",
      "Precision (scikit-learn) 0.9902912621359223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "# Computing precision\n",
    "def precision(labels, predictions):\n",
    "    tp = true_positive(labels, predictions)\n",
    "    return tp / (tp + false_positive(labels, predictions))\n",
    "\n",
    "print(\"Precision (Python):\", precision(Y_test, y_hat))\n",
    "print(\"Precision (scikit-learn)\", precision_score(Y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "Another useful evaluation metric for classification models is __recall__, also known as __sensitivity__. \n",
    "\n",
    "> Recall is the ratio of the correctly predicted positives to the total number of positives in the dataset. It is given by the following equation:\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
    "\n",
    "> Perfect recall occurs when there are no false negatives; thus, it is a useful metric to consider when false negatives are costly.\n",
    "\n",
    "Recall is the answer to the question: 'What proportion of the true labelled examples does the model correctly predict?'\n",
    "\n",
    "In the breast-cancer context, precision answers the question: 'Of all the people who had a malignant breast tumour, how many did the model correctly identify?'\n",
    "\n",
    "While precision measures how well a model deals with false positives, recall measures how well it deals with false negatives. \n",
    "\n",
    "> Combined, accuracy, recall and precision are robust metrics for performance evaluation. \n",
    "\n",
    "Recall is a useful measure to consider when false negatives are more costly than false positives. For instance, it is probably better that a tumour is classified as malignant even though it is not, as it will lead to further examination, than if a malignant tumour were classified as benign, leading to inappropriate or no medical intervention.\n",
    "\n",
    "#### Thought experiment\n",
    "\n",
    "Consider the same extreme example from earlier with 560 benign tumours and 9 malignant tumours. \n",
    "\n",
    "If we create a model that always predicts the tumour to be malignant (positive), we will obtain the following results: \n",
    "- The accuracy will be $\\frac{9}{569} = 2\\%$.\n",
    "- The precision will be $\\frac{9}{569} = 2\\%$.\n",
    "- The recall will be $\\frac{9}{9} =100\\%$. \n",
    "\n",
    "In the previous thought experiment, going with only accuracy would have led us to misjudge the model's performance, just as now using only recall would have the same effect.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Code a `recall` function that accepts `labels and predictions` as arguments (remember to cache the `true_positive` value to avoid repeating the calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (Python): 0.9444444444444444\n",
      "Recall (scikit-learn) 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def recall(labels, predictions):\n",
    "    tp = true_positive(labels, predictions)\n",
    "    return tp / (tp + false_negative(labels, predictions))\n",
    "\n",
    "print(\"Recall (Python):\", recall(Y_test, y_hat))\n",
    "print(\"Recall (scikit-learn)\", recall_score(Y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the results reflect that our model exhibits a strong performance. Using recall and precision in parallel is already a strong strategy for evaluating the performance of models. \n",
    "\n",
    "> However, as they are two separate measures, we cannot use them directly to compare the performance of one model with another.\n",
    "\n",
    "Therefore, instead, we must come up with a metric that accounts for both the recall __and__ the precision of our model simultaneously. To do that, we will introduce a new metric called the F1 score.\n",
    "\n",
    "### Summary\n",
    "\n",
    "<p align=center><img src=images/precision-recall-side-by-side.png width=600></p>\n",
    "\n",
    "<p align=center><img src=images/precision_recall.png width=500></p>\n",
    "\n",
    "[Source](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score\n",
    "\n",
    "The $\\mathbf{F_{1}}$ __score__, also known as the __F-score__ or __F-measure,__ is a metric that takes the harmonic mean of the precision and recall. \n",
    "\n",
    "Therefore, by maximising the F1 score, we can account for both the precision and the recall simultaneously. It is given as follows:\n",
    "\n",
    "$$\n",
    "F_{1} = 2\\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision + recall}} = \n",
    "\\frac{\\text{TP}}{\\text{TP} + \\frac{1}{2}(\\text{FP} + \\text{FN})}\n",
    "$$\n",
    "\n",
    "This metric enables the robust evaluation of the performance of models. It affords insights into the lacking areas and the performances of specific models relative to others. An extension of the $F_{1}$ score is known as the $F_{\\beta}$ score; for a given value, the $\\beta$ is given as follows:\n",
    "\n",
    "$$\n",
    "F_{\\beta} = (1+\\beta^{2})\\frac{\\text{precision} \\cdot \\text{recall}}{(\\beta^{2}\\cdot\\text{precision) + recall}}\n",
    "$$\n",
    "\n",
    "While we will not implement this version of the metric in this course, it can be useful as it enables you to assign different weightings to the two metrics depending on the chosen parameter value for $\\beta$. \n",
    "\n",
    "Depending on the context under which the model is applied, you will need to optimise for different metrics, e.g. when aiming to diagnose whether a breast tumour is malignant (positive) or benign (negative).\n",
    "\n",
    "It is much better to misdiagnose it as malignant (`False Positive`), which would result in further testing, than to misdiagnose it as benign (`False Negative`), which would result in inappropriate or no medical intervention. In this context, you would choose to minimise the number of false negatives, thereby assigning a higher weighting to the recall than the precision.\n",
    "\n",
    "Below, we implement the $F_{1}$ score with Python as well as with the in-built scikit-learn function.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Code an `f1` function that accepts `labels and predictions` as arguments (remember to cache the `precision` and `recall`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score (Python): 0.966824644549763\n",
      "F1 score (scikit-learn) 0.966824644549763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Computing the F1 score\n",
    "def f1(labels, predictions):\n",
    "    p = precision(labels, predictions)\n",
    "    r = recall(labels, predictions)\n",
    "    return 2 * (p*r) / (p+r)\n",
    "\n",
    "print(\"F1 score (Python):\", f1(Y_test, y_hat))\n",
    "print(\"F1 score (scikit-learn)\", f1_score(Y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model exhibits a relatively high performance across all the four different metrics used thus far, which reflects its robustness.\n",
    "\n",
    "Next, we provide an answer to the question: 'How does any of this apply to the multiclass classification case?' The same framework, as seen above, can also be applied to non-binary cases. We will demonstrate this using the iris dataset from scikit-learn, which we upload below and fit to a multiclass logistic-regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Loading the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic-regression model to the iris dataset\n",
    "model = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, Y_train)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, we need to expand upon the confusion matrix so that it accounts for multiple classes rather than two. \n",
    "\n",
    "> We do this by treating each class as a simple case of binary classification.\n",
    "\n",
    "Fortunately, the in-built tools in scikit-learn allow us to plot the confusion matrix of the iris dataset and the corresponding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation of the confusion matrix of the iris dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "class_names = iris.target_names\n",
    "\n",
    "title = \"Confusion matrix\"\n",
    "disp = plot_confusion_matrix(\n",
    "    model, X_test, Y_test, display_labels=class_names, cmap=plt.cm.Blues\n",
    ")\n",
    "disp.ax_.set_title(title)\n",
    "print(title)\n",
    "print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the confusion matrix as a visual aid, we can __'binarise'__ the problem and treat each class as a binary-classification problem. For instance, we can compute the precision when classifying an observation as 'versicolor' or not as $\\frac{17}{17} = 100\\%$, to be $\\frac{16}{16} = 100\\%$ and $\\frac{11}{11 + 1} = 91.7\\%$ for 'setosa' and 'virgina', respectively. \n",
    "\n",
    "Using these three metrics, we can compute the average of the individual precisions to obtain the precision of the multiclassification model. Furthermore, we can generalise this concept and apply it to the other metrics discussed. This is the simplest form of computing the multiclass precision and is known as __macro averaging,__ where all metrics have the same weight. For information on other forms of metric averaging, see [here](https://scikit-learn.org/stable/modules/model_evaluation.html). If we consider a multiclassification model with $N$ possible classes,\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{correct predictions}}{\\text{all predictions}}$$,\n",
    "\n",
    "$$\\text{Precision} = \\frac{1}{N}\\sum_{i=i}^{N}(\\text{Binary Precision})_{i} $$,\n",
    "\n",
    "$$\\text{Recall} = \\frac{1}{N}\\sum_{i=i}^{N}(\\text{Binary Recall})_{i} $$.\n",
    "\n",
    "The $F_{1}$ score metric can still be computed in terms of the recall and precision. Below, we compute the four metrics encountered for the 'irisLogisticModel'. To prevent this from becoming a 'black-box' concept and aid your understanding, we have computed, by hand, the precision of our model based on the values on the confusion matrix.\n",
    "\n",
    "$$\\text{Precision} = \\frac{1}{N}\\sum_{i=i}^{N}(\\text{Binary Precision})_{i} = \\frac{1 + 1 + 0.917}{3} = 0.972 $$\n",
    "\n",
    "> In `sklearn`, multiclass and binary metrics work as a single function/class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9814814814814815\n",
      "F1 score: 0.975983436853002\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(Y_test, y_hat))\n",
    "print(\"Precision:\", precision_score(Y_test, y_hat, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(Y_test, y_hat, average=\"macro\"))\n",
    "print(\"F1 score:\", f1_score(Y_test, y_hat, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: ROC & AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we discuss one of the most powerful evaluation metrics used in classification: the __ROC curve__ and the __AUC.__\n",
    "\n",
    "By 'fitting' a logistic-regression model to our binary classification data, we have already found the optimal __threshold__ for the model. \n",
    "\n",
    "> Furthering the breast-cancer context, the threshold is the probability, above which the tumour can be considered malignant, and below which the tumour can be considered benign.\n",
    "\n",
    "However, the 'optimal' threshold may not necessarily give the optimal model for the problem being addressed, which is the primary purpose of evaluation metrics. \n",
    "\n",
    "As a solution, we present the ROC curve, which was originally developed for operators of military radar receivers, hence the name. It provides a visual representation of the model's performance while operating at different thresholds.\n",
    "\n",
    "The ROC curve uses __recall__, referred to in this context as __sensitivity__ or __true positive rate__, as well as __specificity,__ which is the ratio of the number of observations that were correctly predicted negative to the number of observations that were actually negative:\n",
    "\n",
    "$$ \n",
    "\\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "Given this quantity, we can define the __false positive rate__, which informs on the proportion of observations that were predicted to be malignant when they were actually benign:\n",
    "\n",
    "$$ \n",
    "\\text{FPR} = 1-\\text{Specificity} = \\frac{\\text{FP}}{\\text{TN} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "Using these quantities, we can plot a ROC curve for our binary classification model, which is the true positive rate versus the false positive rate for all the threshold values tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # doctest: +SKIP\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "\n",
    "X, y = datasets.make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, random_state=0\n",
    ")\n",
    "\n",
    "clf = svm.SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "metrics.plot_roc_curve(clf, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for FPR and TPR are taken at different thresholds and computed as points.\n",
    "\n",
    "Additionally, we can observe the __AUC__:\n",
    "\n",
    "> AUC is a measure of the area under the rectangle.\n",
    "\n",
    "Intuitively, __the larger the area under the rectangle, the more favourable the result.\n",
    "\n",
    "This value allows us to easily compare models, with the maximum value being `1.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of the following:\n",
    "\n",
    "- [Evaluation metrics](#Evaluation-metrics:-why-do-we-need-them?)\n",
    "- [Classification metrics](#Classification-Metrics)\n",
    "- [Regression metrics](#Regression-Metrics)\n",
    "- [Extra: ROC & AUC](#Extra:-ROC-&-AUC)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9ca20eb9903ec819ce8e3057ea2baedc00ab0db33ca8a9c7ce80c5c8a90afde"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('AiCore': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
