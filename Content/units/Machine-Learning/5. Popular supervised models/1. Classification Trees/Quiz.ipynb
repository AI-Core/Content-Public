{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about decision trees? Select all that apply.\n",
    "\n",
    "- Decision trees are a type of supervised learning algorithm ***\n",
    "- Decision trees are a type of unsupervised learning algorithm\n",
    "- Decision tress can be used for classification problems ***\n",
    "- Decision trees can be used for regression problems ***\n",
    "- Decision trees have a single root node ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the _Gini Impurity_ measure?\n",
    "\n",
    "- The probability that a randomly chosen element from the set will be incorrectly labeled if it is randomly labeled according to the distribution of labels in the entire set\n",
    "- The probability that a randomly chosen element from the set will be correctly labeled if it is randomly labeled according to the distribution of labels in the entire set\n",
    "- The probability that a randomly chosen element from the set will be correctly labeled if it is randomly labeled according to the distribution of labels in the subset\n",
    "- The probability that a randomly chosen element from the set will be incorrectly labeled if it is randomly labeled according to the distribution of labels in the subset ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is true about entropy in a decision tree? Select all that apply.\n",
    "\n",
    "- Entropy is a measure of the uncertainty in a decision tree ***\n",
    "- Entropy can be replaced by _Information Gain_\n",
    "- Entropy can be replaced by _Gini Impurity_\n",
    "- Entropy is `0` if the sample is completely homogeneous ***\n",
    "- Entropy is `1` if the sample is completely homogeneous \n",
    "- Entropy is `0` if the sample is equally divided between different classes\n",
    "- Entropy is `1` if the sample is equally divided between different classes ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In terms of bias and variance, which of the following statements are true? Select all that apply.\n",
    "\n",
    "- Decision trees have high bias and low variance\n",
    "- Decision trees have low bias and high variance ***\n",
    "- Reducing the depth of a decision tree reduces the variance ***\n",
    "- Reducing the depth of a decision tree reduces the bias\n",
    "- Increasing the depth of a decision tree reduces the variance\n",
    "- Increasing the depth of a decision tree reduces the bias ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In `sklearn`, what module is used to create a decision tree?\n",
    "\n",
    "- `sklearn.tree` ***\n",
    "- `sklearn.decisiontree`\n",
    "- `sklearn.decision_tree`\n",
    "- There is no module in `sklearn` for decision trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What parameters can you include in the `DecisionTreeClassifier` in `sklearn`? Select all that apply.\n",
    "\n",
    "- `criterion` ***\n",
    "- `max_depth` ***\n",
    "- `max_features` ***\n",
    "- `classes`\n",
    "- `n_classes`\n",
    "- `random_state` ***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
