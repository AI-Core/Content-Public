{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import List\r\n",
    "import random\r\n",
    "\r\n",
    "class RussianRoulette:\r\n",
    "    def __init__(self, students: List[str]):\r\n",
    "        self.students = students\r\n",
    "        self.__backup = students.copy()\r\n",
    "        random.shuffle(self.students)\r\n",
    "\r\n",
    "    def choose_victim(self):\r\n",
    "        victim = self.students.pop()\r\n",
    "        if len(self.students) == 0:\r\n",
    "            self._restart()\r\n",
    "        return victim\r\n",
    "        \r\n",
    "    \r\n",
    "    def _restart(self):\r\n",
    "        self.students = self.__backup.copy()\r\n",
    "        random.shuffle(self.students)\r\n",
    "\r\n",
    "\r\n",
    "rr = RussianRoulette(['Ishtyaq', 'Jason', 'Nishaal', 'Simeon', 'Tafadzwa'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. What is the main difference between Functional and Non-Functional Testing?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ishtyaq'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Give me two real world examples of wanting to use performance testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "rr.choose_victim()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Nishaal'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. You have a webscraper that extracts data using multiple functions working in sequence. How would you implement unit testing? How would you implement integration testing?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Tafadzwa'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. For a TestCase class you are defining, you are always using the same example. Instead of repeating the same lines of code in each method, what other method can you use?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Jason'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Why would you want to use the tearDown() method?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. You create a test that intentionally causes an error in the function you are testing. What assertion do you have to use?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Simeon'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. How many assertions can you write in a single test?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Tafadzwa'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Why and how do you implement a strategy using hypothesis?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "rr.choose_victim()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Jason'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. You have the following code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class Friend:\r\n",
    "    def __init__(self, name: str):\r\n",
    "        self.name = name\r\n",
    "    def go_partying(self):\r\n",
    "        return f\"Hey {self.name}, let's get wasted!\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "victim = rr.choose_victim()\r\n",
    "print(victim)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nishaal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import unittest\r\n",
    "\r\n",
    "class PartyTestCase(unittest.TestCase):\r\n",
    "    def setUp(self):\r\n",
    "        self.party_person = Friend(victim)\r\n",
    "\r\n",
    "    def test_party(self):\r\n",
    "        expected_value = f\"Hey {self.party_person.name}, let's behave and study Python!\"\r\n",
    "        actual_value = self.party_person.go_partying()\r\n",
    "        self.assertAlmostEqual(5.0000000000000001, 5)\r\n",
    "        \r\n",
    "\r\n",
    "unittest.main(argv=[''], verbosity=0, exit=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x25f19954490>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ad8bebc098a042dc0df4e42fc2ecc8fff0bd7b8741641ce29007c29766dadbe0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}