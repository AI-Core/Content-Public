{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l: typing.List[typing.Any]):\n",
    "        self.l = l\n",
    "\n",
    "    # Not dependent on index\n",
    "    def __getitem__(self, index):\n",
    "        return self.l[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l)\n",
    "\n",
    "\n",
    "dataset = DummyDataset([0, 1, 2, 3, 4, 5])\n",
    "len(dataset), dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(torch.randn(300, 10), torch.randint(0, 5, size=(300,)))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "\n",
    "for (X, y) in dataloader:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    # Training dataset as torch.utils.data.Dataset instance\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=tmp_dir,  # where data is stored\n",
    "        transform=torchvision.transforms.ToTensor(),  # how each sample will be transformed\n",
    "        train=True,  # we want training data\n",
    "        download=True,  # should i download it if it's not already here?\n",
    "    )\n",
    "\n",
    "    # Test dataset as torch.utils.data.Dataset instance\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root=tmp_dir,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        train=False,\n",
    "    )\n",
    "    \n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dataset[0][0]\n",
    "print(x.shape)\n",
    "plt.imshow(x.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [50000, 10000]\n",
    ")  # split into 50K training & 10K validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    ),\n",
    "    \"validation\": torch.utils.data.DataLoader(\n",
    "        validation_dataset, batch_size=BATCH_SIZE, pin_memory=torch.cuda.is_available()\n",
    "    ),\n",
    "    \"test\": torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, pin_memory=torch.cuda.is_available()\n",
    "    ),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
