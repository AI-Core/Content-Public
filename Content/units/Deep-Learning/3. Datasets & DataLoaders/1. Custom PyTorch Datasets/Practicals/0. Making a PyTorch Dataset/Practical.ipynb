{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a PyTorch Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import `torch` and `pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a class called `BostonHousingDataset` that inherits from `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Inside the class constructor, read in the dataset csv file using `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Assign two attributes, `self.X` and `self.Y`, and assign them to your features and labels.\n",
    "The labels are in the column called \"medv‚Äù, all the other columns are features. Convert the data to torch tensor format as you assign them, and set the datatype to float32. You can look at the docs for `torch.tensor()` for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Now define the second crucial method of the dataset class: `__getitem__`.\n",
    "\n",
    "This needs to take in an index of your dataset and return the features and label corresponding to that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Finally, define the `__len__` method, which defines how your dataset responds to the len() method in python.\n",
    "\n",
    "It should print the number of rows in your dataset when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 7. Finally, let's load our data into a dataloader as if we were going to perform minibatch optimisation. \n",
    "\n",
    "Create an instance of your BostonHousingDatset class, and pass it as an argument to an instance of the `DataLoader` class (found in `torch.utils.data`). Specify a batch size of 4 and set shuffle to `True`, and call the instance `train_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. We can now test our dataloader by running the command `next(iter(train_loader)`\n",
    "\n",
    "Print the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-projects_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b961f8166aad6ccb4cf65d0f9c742ef9c6c23ffe83ad932438cd83ed96aebaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
