{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification in PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is wrong with the following code that creates a multiclass classifier? Assume that you have 10 classes. Select all that apply.\n",
    "\n",
    "```python\n",
    "class MulticlassClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MulticlassClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.sigmoid(self.linear(x))\n",
    "        return out\n",
    "```\n",
    "\n",
    "- The output layer should have 10 units, not 1 ***\n",
    "- There is no `backward` method\n",
    "- The `forward` method does not specify the input size\n",
    "- The `forward` method shouldn't have a sigmoid activation function ***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True or False: A multiclass classifier always needs a softmax activation function in the output layer.\n",
    "\n",
    "- True, otherwise the output won't sum to 1\n",
    "- False, the cross-entropy loss function already has a softmax activation function embedded in it ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the following training loop, what do you have to change in order to make it work with a multiclass classifier?\n",
    "\n",
    "```python\n",
    "def train_model(model, train_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.mse_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "```\n",
    "\n",
    "- We need to define the optimiser\n",
    "- We need to give a value to the number of epochs\n",
    "- We don't know how many batches there are in the dataset\n",
    "- We need to change the loss function to `cross-entropy` ***\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
