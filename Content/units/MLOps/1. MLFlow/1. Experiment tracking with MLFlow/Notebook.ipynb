{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fe18e4",
   "metadata": {},
   "source": [
    "# Experiment Tracking\n",
    "## Introduction\n",
    "> __MLFlow offers an experiment-tracking component in the form of an API and a UI. This component enables the logging and visualisation of experimental data.__\n",
    "\n",
    "## Benefits\n",
    "With this component, it is possible to log the following:\n",
    "- model parameters\n",
    "- code versions (git commit hashes)\n",
    "- metrics\n",
    "- generated artifacts\n",
    "\n",
    "__`MLFlow` tracking is organised around runs, which are simply an approach for executing programs__.\n",
    "\n",
    "`mlflow` records each run in \n",
    "- the local files, \n",
    "- an SQLAlchemy database, or \n",
    "- remote storage (via the [`mlflow.set_tracking_uri()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri) function).\n",
    "\n",
    "For more information on storage, check out the documentation [here](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded).\n",
    "\n",
    "> __Via `MLFlow`, we can track, version and create comprehensive experiments, starting with ETL and ending with deployment.__\n",
    "\n",
    "## Important Concepts\n",
    "There are a few main concepts to understand when using MLFlow.\n",
    "- __experiment__: mainly [`mlflow.set_experiment(UNIQUE_NAME_OF_EXPERIMENT)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_experiment), which sets the current experiments and optionally creates them if they do not exist.\n",
    "- __run__: an experiment can consist of multiple single runs. Context manager [`mlflow.start_run()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run).\n",
    "- __logging__: essentially logging data from an experiment. Here are the related functions:\n",
    "    - [`mlflow.log_param(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param) logs hyperparameters and other settable parameters under the current run.\n",
    "    - [`mlflow.log_metric(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric).\n",
    "    - [`mlflow.log_artifact(local_path)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact) logs the created file(s) (e.g. models, generated text, etc.) under the current run.\n",
    "    \n",
    "Next, as a demonstration, we run and log a __non-flavoured__ (i.e. without specific integrations) dummy experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ca53175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:43:32.171088Z",
     "start_time": "2021-04-25T21:43:32.013188Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "def create_dummy_file():\n",
    "    features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
    "    with open(\"features.txt\", \"w\") as f:\n",
    "        f.write(features)\n",
    "\n",
    "\n",
    "create_dummy_file()\n",
    "\n",
    "# Create experiment (artifact_location=./ml_runs by default)\n",
    "mlflow.set_experiment(\"Dummy Experiments\")\n",
    "\n",
    "# By default experiment we've set will be used\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"features.txt\")\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    for i in range(10):\n",
    "        mlflow.log_metric(\"Iteration\", i, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97e898",
   "metadata": {},
   "source": [
    "To visualise and explore the saved data, we run the `mlflow ui` command and visit [`http://localhost:5000 `](http://localhost:5000) in a web browser (__the data will be saved in `./mlruns`__).\n",
    "\n",
    "Run the following in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96cdf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:31:33.674264Z",
     "start_time": "2021-04-25T21:31:32.591694Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mlflow ui --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d5324",
   "metadata": {},
   "source": [
    "After navigating to the experiment, we can observe the `Iteration` being logged as shown below:\n",
    "\n",
    "![](images/mlflow_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2d24e",
   "metadata": {},
   "source": [
    "## Model Format\n",
    "\n",
    "> MLFlow provides a standard format for saving ML models (from various libraries), which aids the usage of models (e.g. inference on REST API, cloud, etc.). \n",
    "\n",
    "MLFlow models consist of the following:\n",
    "- a directory with arbitrary files defined by the model.\n",
    "- an `MLmodel` file (written in yaml) that specifies the contents of the model.\n",
    "\n",
    "Below, we demonstrate how to save a model (in this case, `sklearn`) in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf8eba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a07f86677dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.save_model(model, \"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4854efc",
   "metadata": {},
   "source": [
    "The above code creates the following directory in our `cwd`:\n",
    "\n",
    "```bash\n",
    "my_model/\n",
    "├── MLmodel\n",
    "└── model.pkl\n",
    "```\n",
    "\n",
    "The contents of the `MLModel` are equally easy to understand:\n",
    "\n",
    "```yml\n",
    "---\n",
    "time_created: 2021-04-03T17:28:53.35\n",
    "\n",
    "flavours:\n",
    "  sklearn:\n",
    "    sklearn_version: 0.24.1\n",
    "    pickled_model: model.pkl\n",
    "  python_function:\n",
    "    loader_module: mlflow.sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df04c5",
   "metadata": {},
   "source": [
    "### Model signature\n",
    "\n",
    "To deploy and occasionally run a model (e.g. in `tensorflow`), the __model signature__ must be specified.\n",
    "\n",
    "> __Model signature specifies the type and shape of inputs going through the model.__\n",
    "\n",
    "*Things to note*\n",
    "- Standard casting rules apply (upcasting is fine; however, downcasting will raise an error).\n",
    "- The model signature aids the reading of inputs when they are sent in JSON format via REST API or the like.\n",
    "\n",
    "It can be added to the `MLModel` file via any of the two modes: column signature or tensor signature.\n",
    "\n",
    "#### Column signature\n",
    "\n",
    "> In this mode, the user specifies the input signature by specifying every possible column input.\n",
    "\n",
    "This mode is supported by all flavours (frameworks); however, it might be difficult to achieve in some cases.\n",
    "\n",
    "Consider the example below, which uses the `iris` dataset:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"sepal length (cm)\", \"type\": \"double\"}, {\"name\": \"sepal width\n",
    "      (cm)\", \"type\": \"double\"}, {\"name\": \"petal length (cm)\", \"type\": \"double\"}, {\"name\":\n",
    "      \"petal width (cm)\", \"type\": \"double\"}]'\n",
    "    outputs: '[{\"type\": \"integer\"}]'\n",
    "```\n",
    "\n",
    "#### Tensor signature\n",
    "\n",
    "> In this mode, the user specifies the input for deep-learning inputs (e.g. images) via the tensor shape.\n",
    "\n",
    "Consider the image-oriented example:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"images\", \"dtype\": \"uint8\", \"shape\": [-1, 28, 28, 1]}]'\n",
    "    outputs: '[{\"shape\": [-1, 10], \"dtype\": \"float32\"}]'\n",
    "```\n",
    "\n",
    "#### Inferring input shapes\n",
    "\n",
    "Generally, it is relatively easy (and less error-prone) to infer `dtype` and the shape through our code. These can easily be achieved via [`mlflow.models.infer_signature`](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.infer_signature).\n",
    "\n",
    "An example is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1089eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "clf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "clf.fit(iris_train, iris.target)\n",
    "signature = infer_signature(iris_train, clf.predict(iris_train))\n",
    "\n",
    "mlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f30026",
   "metadata": {},
   "source": [
    "For `infer_signature`,\n",
    "- pass the input data (conventionally `torch.Tensor`, `pd.DataFrame`, `np.ndarray` or other standard types).\n",
    "- pass data through the model as the second argument, which will create `outputs` automatically.\n",
    "\n",
    "\n",
    "The `mlflow.sklearn.log_model` command saves the model to the file in the `cwd` named `iris_rf` with the specified signature.\n",
    "Note that we can load it later from the disk (__it must be customised to the flavour in which it was saved__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63119ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sklearn model\n",
    "\n",
    "sklearn_model = mlflow.sklearn.load_model(\"iris_rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21263441",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of \n",
    "- MLFlow experiment tracking and the important associated concepts.\n",
    "- model formats."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06c1e258a470a687113bfba03f207c092b27379067ada2d83b8b31269ab641fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
