{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presto Overview\n",
    "\n",
    "## What is Presto?\n",
    "\n",
    "> Presto is an open-source, distributed SQL query engine that can connect to multiple data sources simultaneously\n",
    "\n",
    "When Hadoop become popular, Hive was Hadoop's de-facto standard tool for data warehousing and SQL-like queries. However, some limitations of Hive started to appear over time, and alternative tools began emerging. Among these tools were Presto (sometimes referred to as Trino) and Impala.\n",
    "\n",
    "Presto was released in 2013 by Facebook. In 2015, Teradata joined the Presto community and started offering support and software updates to the tool. \n",
    "\n",
    "Presto can be defined as a data virtualisation or interactive querying tool that runs on a distributed cluster of machines which can connect to various different data stores (for both structured and unstructured data) and access data within these different stores using a single, integrated query. \n",
    "\n",
    "For example, if we have data stored in HDFS, Amazon S3 and Postgres, we can access all 3 of them in the _same SELECT query_. This is a very powerful feature that distinguishes Presto from other tools.\n",
    "\n",
    "Below is an image demonstrating where Presto fits in relation to the various data stores:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/presto-overview3.png\" width=450>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of Presto\n",
    "\n",
    "- Open-source tool that can connect to a wide variety of back-end data stores simultaneously (including HDFS, SQL databases, NoSQL data stores, S3 and Snowflake)\n",
    "- Uses SQL for data querying. It's dubbed as the \"SQL on Anything\" engine.\n",
    "- It can be considered as a \"Hive 2.0\" tool that excels in fast, interactive queries (rather than long-running batch data processing queries)\n",
    "- Designed from the ground-up to mainly perform low-latency interactive analytics on massive datasets (Petabytes in size)\n",
    "- Uses in-memory processing (similar to Apache Spark)\n",
    "- Seperates data storage activities from computational logic, and can scale each of them independently\n",
    "- Provides industry-grade reliability. It's currently deployed by many well known companies such as: Facebook, Airbnb, Netflix, Dropbox and Groupon\n",
    "- Presto views data from a columnar perspective, hence file formats that are columnar-based are the ones the tool can handle most efficiently (for instance, RC files, ORC files, Parquet or SequenceFiles)\n",
    "    - Columnar compression helps to save up to 75% of disk storage space over regular file storage methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of Presto\n",
    "\n",
    "> Presto is a distributed application which consists of 3 main components: Coordinators (the tool's central brain), workers (which implement the actual data querying tasks) and clients (who submit query requests and get the results)\n",
    "\n",
    "Below is a diagram showing how the 3 components fit together:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/presto-architecture2.png\" width=600>\n",
    "</p>\n",
    "\n",
    "Next, let's take a closer look at each component:\n",
    "\n",
    "### Coordinator\n",
    "\n",
    "- Plays the role of the \"central brain\" for the tool\n",
    "- All clients must connect to the coordinator in order to send query requests\n",
    "- Coordinates the data transfer between the worker nodes and the client\n",
    "- Communicates with all remote data sources to access _metadata_ and identify what tables and files are stored\n",
    "- Responsible for parsing, analysing, planning and scheduling all client requests\n",
    "- Contains 3 sub-components that assist in all of the above tasks:\n",
    "  - Parser/analyser\n",
    "  - Planner\n",
    "  - Scheduler\n",
    "\n",
    "### Worker\n",
    "- Implements all the tasks that have been approved and scheduled by the coordinator\n",
    "- Communicates with the remote data sources (such as HDFS) to read and access the data\n",
    "- Performs all instructed tasks and submits feedback/results to the coordinator\n",
    "\n",
    "### Client\n",
    "- There are different tools used to communicate with Presto and tell it which queries to run\n",
    "- We call these _clients_, they send the query request to the coordinator and recieve the final result\n",
    "- Some include:\n",
    "  - Presto's command line interface. Read more about it [here](https://prestodb.io/docs/current/installation/cli.html)\n",
    "  - PopSQL, which is a graphical user interface client. Read more about it [here](https://popsql.com/presto-client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Presto Queries run?\n",
    "\n",
    "From a high-level, Presto queries go through 8 steps. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/presto-query-steps.png\" width=900>\n",
    "</p>\n",
    "\n",
    "\n",
    "#### 1. Client submits a query\n",
    "- The query automatically goes to the coordinator\n",
    "\n",
    "#### 2. Coordinator analyses the query\n",
    "- This analysis identifies which data sources are required, and what exactly needs to be done with that data\n",
    "\n",
    "#### 3. Coordinator goes to those data sources\n",
    "- It checks the metadata, available tables, column names, and whether or not the user has access to those tables\n",
    "\n",
    "#### 4. Coordinator creates the _query plan_\n",
    "- This is done by determining the required steps, checking which workers contain data pertaining to those steps, and scheduling the execution of those steps\n",
    "\n",
    "#### 5. Coordinator communicates the plan with workers\n",
    "- Once the plan is finalised, it is communicated to the appropriate worker nodes for execution\n",
    "\n",
    "#### 6. Workers fetch required data\n",
    "- Once the query plan is communicated, the workers are instructed to go fetch the data from the data sources identified earlier to prepare for data related tasks\n",
    "\n",
    "#### 7. Workers implement data transformations\n",
    "- Next, the workers perform required tasks (such as data aggregation), and send the results back to the coordinator\n",
    "\n",
    "#### 8. Coordinator sends results to the client\n",
    "- Once the coordinator has recieved all required results from all workers, the final output is returned to the client/user\n",
    "\n",
    "#### A few things to note about how query execution is implemented:\n",
    "- All tasks run in parallel\n",
    "    - If one task fails, all other tasks fail (meaning the entire query fails)\n",
    "- Uses memory-to-memory transfer\n",
    "    - No use of hard disk storage at all\n",
    "- Leverages pipelined execution across all nodes in a massive parallel processing (MPP) manner\n",
    "- Uses multi-threading to ensure all CPU cores are utilized effectively\n",
    "\n",
    "\n",
    "_Note: For a detailed list of available connectors that integrate Presto with various data stores, take a look at the [official documentation](https://prestodb.io/docs/current/connector)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths of Presto\n",
    "\n",
    "> The core strength of Presto is a feature called _data federation_, meaning that in a single query, Presto can connect to and combine data from multiple sources \n",
    "\n",
    "- There are a variety of readily-available plugins which help to smoothly connect to various big data sources such as: HDFS, Kafka, and NoSQL data stores \n",
    "- Can connect to both structured (such as Postgres) and unstructured data sources (like Cassandra)\n",
    "- Presto leverages in-memory data processing\n",
    "    - Which is very fast compared to hard disk data processing used by other tools like Hive\n",
    "    - Uses distributed massive parellel processing techniques to optimise memory processing\n",
    "    - Implements efficient utilisation of CPU cores via multi-threading\n",
    "    - As memory usage never spills over outside of the RAM, Presto can run without a storage layer. This means that there is no vendor lock-in for any Hadoop distribution, no storage engine technology limitations, and no hidden costs for other storage services\n",
    "- Data engineers can create their own customer connectors easily\n",
    "- Authentication and database table access can be configured in the plugins to allow customised access to certain users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Presto\n",
    "\n",
    "> The main limitation of Presto is that it does not have its own data storage layer. Accordingly, Presto must rely on other tools to store and access data. Moreover, machines running Presto require high RAM as it doesn't use a \"spill to hard disk\" approach when the RAM is full\n",
    "\n",
    "Other limitations include:\n",
    "- Performance-wise, the tool is not suitable for long-running/complex batch queries as it doesn't support \"data spill to disk\" \n",
    "- Security features for the tool are still maturing\n",
    "- In large queries, if one part of the query fails and all other parts are successful, the entire query still fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presto Vs. Hive Comparison\n",
    "\n",
    "> Presto is viewed as a more modern and advanced version of Hive. However, this doesn't mean that Presto is better in every situation. Let's examine how these 2 tools compare\n",
    "<p>\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th style=\"width:auto;text-align:center\"></th>\n",
    "            <th style=\"width:auto;text-align:center\">Hive</th>\n",
    "            <th style=\"width:auto;text-align:center\">Presto</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "       <tr>\n",
    "            <th>Processing Speed</th>\n",
    "            <td><li> Hive has a higher latency in general\n",
    "                <li> Optimised for query throughput - thus is well suited for complex, long-running batch queries on big data\n",
    "\t\t\t\t</td>\n",
    "            <td><li> Presto uses memory-to-memory transfer, which is much faster for simple queries\n",
    "                <li> Ideal for analytical queries \n",
    "            </td>\n",
    "       </tr>\n",
    "       <tr>\n",
    "            <th>Data Processing Method</th>\n",
    "            <td><li>  Hive uses MapReduce, which is a disk-based data processing approach \n",
    "            <li> Slower for analytical queries, but efficient for long running batch jobs  \n",
    "            </td>\n",
    "            <td><li> In-memory data processing\n",
    "                <li> Faster for interactive queries\n",
    "                <li> However, memory has a limit after which the query will fail if it's too complex\n",
    "            </td>\n",
    "      </tr>  \n",
    "\t  <tr>\n",
    "            <th>Community Support</th>\n",
    "            <td><li> Open-source tool\n",
    "\t\t\t\t<li> Community support is dwindling\n",
    "\t\t\t</td>\n",
    "            <td><li> Open-source tool\n",
    "                <li> Much more active and dynamic community support\n",
    "            </td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "            <th>Data Management</th>\n",
    "            <td><li> Hive uses a \"pull\" approach to pull data from various sources and store it in Hive\n",
    "                <li> Hive can then implement required transformations\n",
    "            </td>\n",
    "            <td><li> Presto uses a \"push\" approach to push data execution steps to the data sources themselves\n",
    "                <li> This is because Presto does not have its own data storage infrastructure\n",
    "            </td>\n",
    "      </tr>\n",
    "\t\t  <tr>\n",
    "            <th>Integration Complexity</th>\n",
    "            <td><li> Hive can integrate with other tools such as Amazon S3 and HBase\n",
    "                <li> However, the integration can be complex and require customisations\n",
    "            </td>\n",
    "            <td><li> Presto is easier to integrate with various tools such as HDFS, Amazon S3, MongoDB, MySQL and Postgres\n",
    "                <li> Comes with a wide array of readily available plugins\n",
    "            </td>\n",
    "      </tr>  \n",
    "\t  <tr>\n",
    "            <th>Scalability</th>\n",
    "            <td><li> Hive can scale up or down as required\n",
    "                <li> It's best suited for big data stored in large clusters\n",
    "\t\t\t</td>\n",
    "            <td><li> Presto can also scale up or down, and has been designed for use in the cloud\n",
    "\t\t\t\t<li> Can be used with small to medium sized clusters efficiently\n",
    "\t\t\t</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "            <th>Query Fault-Tolerance</th>\n",
    "            <td><li> Hive can tolerate some errors in query execution\n",
    "                <li> Even if some errors occur, the query can still run until completion\n",
    "\t\t\t</td>\n",
    "            <td><li> Presto does not tolerate any errors in query execution\n",
    "\t\t\t\t<li> If one part of the query fails, the entire query instantly fails\n",
    "\t\t\t</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "            <th>Best Used For</th>\n",
    "            <td><li> Large data aggregations (such as JOINs) on big data with a vast number of tables\n",
    "                <li> Long-running scheduled batch jobs that require a lot of time (hours or days)\n",
    "\t\t\t</td>\n",
    "            <td><li> Quickly exploring data interactively\n",
    "\t\t\t</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presto Vs. Hive Experiment\n",
    "\n",
    "- In one experiment implemented by a company called Treasure Data involving 3 aggregate queries that were executed on the same data, Presto outperformed Hive significantly as we can see in the below diagram showing the query processing times\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/presto-hive-experiment3.png\" width=600>\n",
    "</p>\n",
    "\n",
    "Based on this study, we can see that:\n",
    "- For each of the first 8 minutes (elapsed minutes), we can see the total number of queries each tool ran in order to reach the final result\n",
    "- Notice that, as time goes by, almost 10X more Hive queries compared to Presto to get the same result\n",
    "- The main takeaway is that, Presto is faster, and more efficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses Cases for Presto\n",
    "\n",
    "> Presto has been gaining wider popularity over the past few years and is being adopted by an increasing number of global companies\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./images/companies-using-presto.png\" width=600>\n",
    "</p>\n",
    "\n",
    "### Facebook Use Case\n",
    "- Facebook uses multiple on-premise production clusters with hundreds of nodes in total\n",
    "- They had a massive Hadoop HDFS data warehouse with over 300 petabytes of data\n",
    "- Thousands of daily internal active users running hundreds of queries concurrently\n",
    "- Presto was created and used to query the data interactively\n",
    "- Hive was more suited for large-scale reliable data computation\n",
    "\n",
    "### Netflix Use Case\n",
    "- Netflix had over 200 nodes in an Amazon EC2 cluster\n",
    "- Nodes had over 25 Petabytes of data stored in Parquet files\n",
    "- Over 350 users querying the data with approximately 3,000 queries daily\n",
    "- Presto was used to enable efficient interactive data querying\n",
    "- Results indicate that queries which took 1 or 2 MapReduce phases in Hadoop ran 10 to 100 times faster in Presto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "- Presto is an open-source, distributed SQL data querying engine that can connect to various sources of structured and unstructured data simultaneously\n",
    "- It's a more modern variation of Apache Hive that is faster in data querying, and can easily integrate with data stores such as: HBase, HDFS, Amazon S3 and Postgres\n",
    "- Presto uses in-memory data processing and thus seperates the data storage activities from computational logic. This makes it flexible, scalable, and highly-efficient in the cloud\n",
    "- The tool is composed of three main components: Coordinator (central brain), the Worker (which performs the actual tasks) and the Client (which sends queries)\n",
    "- The core strength of Presto is its ability to combine data from multiple data sources in one query. This feature is called _data federation_. \n",
    "- The main limitation of Presto is that it does not have its own data storage layer - it must rely on other tools to store and access data.\n",
    "- Presto and Hive each have their own pros and cons. Presto is more efficient in interactive data querying while Hive excels at long-running batch jobs on massive datasets\n",
    "- Major global companies are currently using Presto as part of their data engineering foundation. It's mainly leveraged to perform interactive data querying for reporting purposes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
