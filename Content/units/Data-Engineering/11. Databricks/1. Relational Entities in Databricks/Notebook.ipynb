{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Entities in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relational entities form the backbone of data organization and analysis within Databricks. These entities, such as *tables* and *views*, provide a structured way to store and retrieve data. The relational model allows for the representation of complex relationships between datasets, facilitating efficient querying, reporting, and analysis. By understanding and effectively utilizing relational entities, you will be able to use the full power of Databricks to derive valuable insights from your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Relational Entities\n",
    "\n",
    "> Relational entities are structures that store and organize data in a way that reflects the relationships between different datasets. These entities enable users to manage and analyze data efficiently.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/Primary Objects.png\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "### 1. Metastore\n",
    "\n",
    "The *Metastore* in Databricks serves as a central repository for storing metadata related to tables, views, and other data structures. It stores information such as table schema, location, and properties, enabling efficient query planning and execution. The Metastore is essential for managing the metadata associated with relational entities.\n",
    "\n",
    "### 2. Catalogs\n",
    "\n",
    "A *catalog* is named collection of databases. It is a top-level organizational unit that helps in categorizing and managing various databases. Each catalog can contain multiple databases, providing a way to structure and segregate data based on different projects, teams, or use cases.\n",
    "\n",
    "### 3. Schemas (Databases)\n",
    "\n",
    "Within a catalog, *schemas* (or *databases*) are logical containers that hold tables, views, and other relational entities. Schemas provide a way to organize data within a catalog, by defining the structure of tables and views.\n",
    "\n",
    "### 4. Tables\n",
    "\n",
    "**Tables** are structured collections of data stored within a specific schema. They represent the fundamental entities for data storage and retrieval, organized into rows and columns. Tables are used to store and manage large datasets efficiently, supporting various data manipulation and analysis operations.\n",
    "\n",
    "### 5. Views\n",
    "\n",
    "**Views** are virtual tables derived from one or more existing tables or views. They provide a dynamic perspective on the underlying datasets without storing the data themselves. Views are beneficial for simplifying complex queries, aggregations, and transformations, offering a logical abstraction layers for users interacting with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Databases in Databricks\n",
    "\n",
    "To effectively organize and manage data, Databricks provides the ability to create and utilize databases, acting as logical containers for tables.\n",
    "\n",
    "Databases can be created using the `CREATE DATABASE` or `CREATE SCHEMA` statement, with terms used interchangeably in Databricks:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE database_name\n",
    "```\n",
    "> Remember, if you want to run these commands you have to run them in a Databricks Notebook. You will need to make sure you have a working cluster in your Community Edition account that's attached to your current Notebook. You will also need to change the default language to SQL. \n",
    "\n",
    "To ensure a database is only created if it doesn't already exist, you can use:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE IF NOT EXISTS database_name\n",
    "```\n",
    "As an example, we will create a new database called `my_first_db` using the command above. The `SHOW DATABASES` command allows you to view a list of existing databases:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/ShowDatabases.png\" width=\"750\" height=\"250\"/>\n",
    "</p>\n",
    "\n",
    "As you can see, besides our previously created database, we also have a `default` database. The default database is automatically present in every Databricks workspace and serves as the default context when a particular database is not specified in SQL queries. For example, if any table is created without explicitly specifying the databases, it will be created in the default database.\n",
    "\n",
    "For detailed information about a specific database use the `DESCRIBE DATABASE database_name` command.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/DescribeDatabase.png\" width=\"800\" height=\"300\"/>\n",
    "</p>\n",
    "\n",
    "This command will display important information about the databases, including its catalog, name, location and owner. \n",
    "\n",
    "> By default, when you create a database, it is stored in the *Hive Metastore* (a central repository that stores metadata information about databases, tables, and partitions) with a default physical storage location in the **Databricks File System (DBFS)**.\n",
    "\n",
    "Let's breakdown the location:\n",
    "\n",
    "- `dbfs:/` refers to the Databricks File System\n",
    "- `user/hive/metastore` is the default base directory for Hive databases in DBFS\n",
    "- `my_first_db.db` is the specific directory corresponding to the `my_first_db` database\n",
    "\n",
    "Once you have created a database, you can also visualize it in the **Data** explorer tab.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/DataExplorer.png\" width=\"700\" height=\"400\"/>\n",
    "</p>\n",
    "\n",
    "> You can customize the location at which a database is created by explicitly specifying the `LOCATION` clause when creating the database:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE IF NOT EXISTS my_second_db\n",
    "LOCATION 'dbfs:/your/custom/location/';\n",
    "```\n",
    "\n",
    "For example, that might look like this:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE IF NOT EXISTS my_second_db\n",
    "LOCATION 'dbfs:/custom/databases/my_second_db/';\n",
    "```\n",
    "If you now use the `DESCRIBE DATABASE` command you should see the custom location under the location field.\n",
    "\n",
    "Two commands to be aware of when working with databases are:\n",
    "\n",
    "- `USE database_name`: For setting a specific database as the current context, simplifying subsequent table creating and querying\n",
    "- `DROP DATABASE IF EXISTS database_name CASCADE`: For deleting a database and removing all its associated tables. Remember to exercise caution when dropping databases to avoid data loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tables in Databricks\n",
    "\n",
    "Tables in Databricks serve as structured containers for organizing and storing data. When working with tables, there are two primary types: *managed tables* and *external tables*.\n",
    "\n",
    "### Managed Tables\n",
    "\n",
    "> **Managed tables** are fully handled and maintained by tDatabricks. Databricks takes care of storing both the data and its associated metadata. Managed tables are stored in the default Hive Metastore location within DBFS.\n",
    "\n",
    "To create a managed table, you can use the `CREATE TABLE` statement and specify the table name along with its schema. The schema defines the structure of the table, including the names and data types of its columns. For example:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE my_managed_table (\n",
    "    id INT,\n",
    "    name STRING,\n",
    "    age INT\n",
    ");\n",
    "```\n",
    "In this example, we've created a table named `my_managed_table` with three columns: `id` of type `INT`, `name` of type `STRING`, and `age` of type `INT`. This defines the schema of the table, indicating the structure and data types of the columns.\n",
    "\n",
    "### External Tables\n",
    "\n",
    "> **External tables** reference data stored in a location specified by the `LOCATION` clause during table creation. This location is outside the default directory structure.\n",
    "\n",
    "To create an external table you can use the following syntax:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE table_name\n",
    "LOCATION 'path'\n",
    "```\n",
    "\n",
    "So, for example:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE my_external_table (\n",
    "    id INT,\n",
    "    name STRING,\n",
    "    age INT\n",
    ")\n",
    "LOCATION 'your/external/location/';\n",
    "```\n",
    "\n",
    "An external table could have its data files stored within Databricks (in a different directory than the database directory in DBFS) or in an entirely external storage system, such as Azure Blob Storage or AWS S3. \n",
    "\n",
    "The key differences between managed and external tables are:\n",
    "\n",
    "- Managed tables store both data and metadata in the default Hive Metastore location within DBFS\n",
    "- External tables reference data stored externally, and the location is specified using the `LOCATION` clause\n",
    "- Databricks fully manages the lifecycle of a managed table, meaning that dropping a managed table will delete the underlying data files\n",
    "- Dropping an external table will not delete the underlying data files, as Databricks only manages its metadata\n",
    "\n",
    "### Inserting Data into Tables\n",
    "\n",
    "Once you have created a table, you can use the `INSERT INTO` statement to add data to it. This is a common and straightforward method to populate tables with meaningful information.\n",
    "\n",
    "The `INSERT INTO` statement allows you to insert specific values or data from another source into a table. Here's a simple example:\n",
    "\n",
    "```sql\n",
    "-- Inserting data into a managed table\n",
    "INSERT INTO my_managed_table (id, name, age)\n",
    "VALUES\n",
    "  (1, 'John Doe', 25),\n",
    "  (2, 'Jane Smith', 30),\n",
    "  (3, 'Bob Johnson', 28);\n",
    "```\n",
    "\n",
    "In this example, data is being inserted into the `my_managed_table`. The specified columns (`id`, `name`, and `age`) are matched with corresponding values. Ensure the order of columns in the `VALUES` clause aligns with the order of columns in the table. \n",
    "\n",
    "As with any relational entity, not only should you now be able to see this new table using the **Data** explorer page, but by double-clicking on the table name, you should also be able to see its schema and sample data:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/DataExplorerTables.png\" width=\"700\" height=\"475\"/>\n",
    "</p>\n",
    "\n",
    "Note, that `INSERT INTO` is just one of the many ways you can populate tables with data. As you become more familiar with Databricks, you can explore additional methods for data insertion and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Views\n",
    "\n",
    "*> *Views** provide a powerful way to organize and present data without physically duplicating it. They are virtual tables based on the result of a `SELECT` query. They do not store the data themselves but provide a way to represent the data from one or more tables.\n",
    "\n",
    "### Creating Views in Databricks\n",
    "\n",
    "To create a view in Databricks, you can use the `CREATE VIEW` statement. There are different types of views:\n",
    "\n",
    "1. Stored Views\n",
    "\n",
    "   - *Stored views* are persistent and stored in the mMtastore. They can be referenced across different sessions and notebooks.\n",
    "   - An example of creating a stored view:\n",
    "\n",
    "```sql\n",
    "CREATE VIEW my_stored_view AS\n",
    "SELECT id, name\n",
    "FROM my_table\n",
    "WHERE age > 25;\n",
    "```\n",
    "\n",
    "2. Temporary Views\n",
    "\n",
    "   - *Temporary views* are session-scoped and will be available only during the duration of the current session\n",
    "   - An example of creating a temporary view:\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW my_temporary_view AS\n",
    "SELECT id, name\n",
    "FROM my_table\n",
    "WHERE age > 25;\n",
    "```\n",
    "\n",
    "3. Global Temporary Views\n",
    "\n",
    "   - *Global temporary views* are similar to temporary views but can be shared across different sessions within the same cluster\n",
    "   - An example of creating a global temporary view:\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE GLOBAL TEMPORARY VIEW my_global_temporary_view AS\n",
    "SELECT id, name\n",
    "FROM my_table\n",
    "WHERE age > 25;\n",
    "```\n",
    "\n",
    "### Differences Between Views and Tables\n",
    "\n",
    "While both views and tables represent structured data, there are key differences:\n",
    "\n",
    "- Views do not store data themselves; they are based on the result of a `SELECT` query. Tables, on the other hand, physically store data.\n",
    "\n",
    "- Views do not have a schema of their own; they inherit the schema from the underlying tables. Tables have a defined schema that specifies the structure of the data.\n",
    "\n",
    "- Data cannot be directly modified through a view. If you want to modify data, you need to modify the underlying tables\n",
    "\n",
    "- When you modify or delete the underlying table, the view is affected. Since views are essentially queries over tables, changes to the underlying table directly impact the data presented by the view. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- The Metastore serves as a central repository storing metadata related to tables, views, and data structures in Databricks, crucial for efficient query planning and execution\n",
    "- Catalogs are named collections of databases that provide top-level organizational units, aiding in the categorization and management of various databases within Databricks\n",
    "- Databases, or Schemas, are logical containers within catalogs that hold tables, views, and other relational entities, enabling organized data storage and retrieval\n",
    "- You can create databases using the `CREATE DATABASE` or `CREATE SCHEMA` statements. You can also create databases with custom locations using the `LOCATION` clause.\n",
    "- Managed tables are fully handled and maintained by Databricks. These tables store both data and metadata in the default Hive Metastore location within DBFS.\n",
    "- External tables reference data stored externally, allowing for flexibility in data storage locations, either within Databricks or in external storage systems like Azure Blob Storage or AWS S3\n",
    "- You can create tables using the `CREATE TABLE` statement\n",
    "- Tables can be populated using the `INSERT INTO` statement, a common and straightforward method for adding meaningful information to tables\n",
    "- Views are virtual tables derived from `SELECT` queries, providing a dynamic perspective on underlying datasets without storing the data themselves\n",
    "- Stored views are persistent views stored in the Metastore, referenced across different sessions and notebooks\n",
    "- Temporary views are session-scoped views available only during the current session\n",
    "- Global temporary views are similar to temporary views but can be shared across different sessions within the same cluster"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
