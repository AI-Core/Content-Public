{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databricks Essentials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Databricks?\n",
    "\n",
    "- A data warehouse solution\n",
    "- A big data processing and analytics platform ***\n",
    "- A programming language for data analysis\n",
    "- A data visualization tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What AWS service is used to provision and manage the underlying infrastructure for Databricks workloads on AWS?\n",
    "\n",
    "- Amazon S3\n",
    "- Amazon EC2 ***\n",
    "- Amazon RDS\n",
    "- Amazon Redshift\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Databricks account?\n",
    "\n",
    "- A user account that allows access to the Databricks platform ***\n",
    "- A data storage service provided by Databricks\n",
    "- A data visualization tool for Databricks users\n",
    "- A type of Databricks workspace used for collaborative data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Databricks workspace?\n",
    "\n",
    "- An environment for developing and running Apache Spark applications ***\n",
    "- A data storage service provided by Databricks\n",
    "- A data visualization tool for Databricks users\n",
    "- A user account that allows access to the Databricks platform\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Databricks notebook?\n",
    "\n",
    "- An interactive document that combines code, text, and visualizations ***\n",
    "- A data storage service provided by Databricks\n",
    "- A Databricks cluster node\n",
    "- A type of Databricks cluster used for distributed data processing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between an All-purpose cluster and a Job cluster in Databricks?\n",
    "\n",
    "- All-purpose clusters are used for interactive workloads, while Job clusters are used for batch processing\n",
    "- All-purpose clusters have a fixed set of nodes, while Job clusters are dynamically provisioned\n",
    "- All-purpose clusters are optimized for CPU-intensive workloads, while Job clusters are optimized for memory-intensive workloads\n",
    "- All-purpose clusters support concurrent users and multiple workloads, while Job clusters are designed for single-use jobs ***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Databricks Runtime?\n",
    "\n",
    "- An open-source framework for calculating the time taken for Spark jobs to run\n",
    "- A cloud-based service for building, training, and deploying machine learning models\n",
    "- A managed, versioned, and optimized runtime environment for running Apache Spark and other big data frameworks on Databricks ***\n",
    "- A data storage service provided by Databricks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Databricks workflow?\n",
    "\n",
    "- A set of rules and policies that govern the access and usage of Databricks resources\n",
    "- A collection of jobs, notebooks, and data pipelines that automate data processing and analysis in Databricks ***\n",
    "- A type of Databricks cluster used for machine learning and deep learning workloads\n",
    "- A data storage service provided by Databricks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Delta Table in Databricks?\n",
    "\n",
    "- A data storage format for structured data that supports ACID transactions and time-travel queries ***\n",
    "- A type of Databricks cluster used for running Apache Spark streaming applications\n",
    "- A visualization tool for exploring and analyzing data stored in Databricks\n",
    "- A type of Databricks notebook that supports advanced data science and machine learning workflows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some key features of Unity Catalog in Databricks?\n",
    "\n",
    "- Searchable metadata store, customizable schemas, data lineage tracking, data quality monitoring, data access policies ***\n",
    "- Real-time data processing, stream processing, graph processing, machine learning workflows\n",
    "- Automated data discovery, data profiling, data classification, data masking, data encryption\n",
    "- Interactive notebooks, dashboards, collaboration tools, version control\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between Unity Catalog, Hive Metastore, and External Metastore in Databricks?\n",
    "\n",
    "- Unity Catalog is a Databricks-native data catalog that provides a unified view of data assets across different data sources and platforms, while Hive Metastore and External Metastore are third-party metadata stores that can be integrated with Databricks ***\n",
    "- Unity Catalog is used for managing data pipelines and workflows, while Hive Metastore and External Metastore are used for storing and managing metadata related to Hive tables and databases\n",
    "- Unity Catalog supports only Databricks-specific data formats, while Hive Metastore and External Metastore support a wider range of data formats\n",
    "- Unity Catalog provides a centralized metadata store for all data assets in Databricks, while Hive Metastore and External Metastore provide separate metadata stores for different data sources and platforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Databricks, what is the correct order of hierarchy for catalogs, schemas, tables, views, and functions?\n",
    "\n",
    "- Catalog > Schema > View > Table > Function\n",
    "- Catalog > Schema > Table > View > Function ***\n",
    "- Schema > Catalog > Table > View > Function\n",
    "- Schema > Catalog > View > Table > Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between the Databricks control plane and data plane?\n",
    "\n",
    "- The control plane is responsible for managing user access to Databricks resources, while the data plane is responsible for storing and processing data\n",
    "- The control plane is responsible for scaling and managing Databricks clusters, while the data plane is responsible for running user workloads\n",
    "- The control plane is responsible for managing Databricks infrastructure and resources, while the data plane is responsible for data processing and storage ***\n",
    "- The control plane is responsible for providing a user interface for interacting with Databricks resources, while the data plane is responsible for running automated tasks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
