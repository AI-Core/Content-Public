{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Essentials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Kafka? Select all that apply.\n",
    "\n",
    "- Kafka can handle both real-time and batch data processing ***\n",
    "- Producers are used to capture and consume data\n",
    "- Events represent a data record or something that happened in the real world ***\n",
    "- Producers and Consumers are inter-dependent on each other and must wait for each other to finish data processing\n",
    "- Events stored in Topics are deleted immediately after they are consumed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Kafka topics? Select all that apply.\n",
    "\n",
    "- They are used to store events ***\n",
    "- A topic can only connect to exactly one producer\n",
    "- Data in a topic is deleted as soon as it's consumed\n",
    "- Storing data in topics for a long time is one of the major problems that Kafka users complain from\n",
    "- Topics store data in partitions ***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Kafka Consumers?\n",
    "\n",
    "- Consumers are an optional part of Kafka\n",
    "- There can only be one consumer at a given point in time\n",
    "- Consumers can specify both the topic and the partition to consume data from ***\n",
    "- They can only be one consumer per Kafka topic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Kafka producers?\n",
    "\n",
    "- There can be multiple Producers in a Kafka cluster ***\n",
    "- Each Producer must have an equivalent consumer ready\n",
    "- There can only be one Producer per Kafka Topic\n",
    "- When running the producer command in Linux, we don't need to specify the topic name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When using `kafka-topics.sh` what are some of the useful arguments to provide when creating of configuring topics? Select all that apply.\n",
    "\n",
    "- `--destroy`: Used to destroy a topic\n",
    "- `--replication-factor`: Used to tell Kafka how many copies of your data to store on the cluster for fault tolerance ***\n",
    "- `--bootstrap-server`: Defines the Kafka broker to connect to ***\n",
    "- `--jumble`: Tells Kafka to jumble up the messages in the topic\n",
    "- `--dump`: Tells Kafka to dump the topic to disk "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some of the useful configuration properties which can be updated in the `producer.properties` file? Select all that apply.\n",
    "\n",
    "- `bootstrap.servers`: Define a list of brokers which can be used to bootstrap knowledge about the Kafka cluster ***\n",
    "- `partitioner.class`: Define a class which will be used to partition events in a custom fashion ***\n",
    "- `compression.type`: Define a compression codec to compress generated data ***\n",
    "- `topic.list`: A list of topics in the Kafka broker\n",
    "- `hard.drive.space`: The amount of hard drive space a producer can use\n",
    "- `fault.tolerance`: An integer value that defines the value of the producers fault tolerance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some useful arguments which can be provided when using the `kafka-console-consumer.sh` script? Select all that apply.\n",
    "\n",
    "- `bootstrap-server`: The Kafka server to connect to ***\n",
    "- `from-beginning`: Tells the consumer to start reading messages from the beginning if it doesn't have an established offset already ***\n",
    "- `offset`: To specify exactly what offset to start reading records from ***\n",
    "- `re-partition`: Used to repartition the topic\n",
    "- `default-consumer-name`: Sets the default name for the consumer\n",
    "- `default-consumer-size`: Sets the default size of the consumer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some the configurable broker properties in the `server.properties` file? Select all that apply.\n",
    "\n",
    "- `broker.id`: An integer id of the broker unique to each broker ***\n",
    "- `num.partitions`: The number of partitions per topic ***\n",
    "- `log.retention.hours`: Configure the amount of hours a log will be held for before being deleted ***\n",
    "- `zookeeper.ip.address`: The IP address to connect to the Zookeeper server\n",
    "- `zookeeper.number.of.brokers`: A list of Zookeeper brokers\n",
    "- `number.of.consumers`: A list of Kafka consumers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2592652612463181e69ac003232387e3e9a99279aa6b168e76f5df16d5110f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
