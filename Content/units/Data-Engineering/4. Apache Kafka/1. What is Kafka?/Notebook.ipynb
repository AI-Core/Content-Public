{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Overview and Architecture\n",
    "\n",
    "## What is Apache Kafka?\n",
    "\n",
    "Apache Kafka is a relatively new open-source technology for distributed data storage optimized for __ingesting__ and __processing__ streaming data in real-time. \n",
    "\n",
    "Streaming data is data that is continuously generated by potentially numerous data sources.  An example of this are Internet of Thing (IoT) devices such as sensors and smartphones. Such devices are usually numerous and typically send the data records simultaneously. Accordingly, in order to properly capture and process this constant influx of data, a streaming tool is needed.\n",
    "\n",
    "Kafka provides three main functions to its users:\n",
    "\n",
    "1.\tPublish and subscribe to streams of records\n",
    "2.\tEffectively store streams of records in the order in which records were generated\n",
    "3.\tProcess streams of records in real-time\n",
    "\n",
    "Kafka is primarily used to build real-time streaming data pipelines and applications that adapt to the data streams. It combines __messaging__, __storage__, and __stream processing__ to allow storage and analysis of both historical and real-time data.  \n",
    "\n",
    "\n",
    "## Why is it important?\n",
    "\n",
    "Apache Kafka is one of the fastest growing, open-source messaging solutions in the market today. This is mainly due to the architectural design pattern that provides a superior logging mechanism for distributed systems.\n",
    "\n",
    "Kafka's importance has skyrocketed in recent years due to the widespread proliferation of Big Data, particularly real-time streaming data.\n",
    "\n",
    "Being purpose-built for real-time log streaming, Apache Kafka is ideally suited for applications that need:\n",
    "\n",
    "- Reliable data exchange between disparate components\n",
    "- The ability to partition messaging workloads as application requirements change\n",
    "- Real-time streaming for data processing\n",
    "- Native support for data/message replay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Industry Use-Cases Kafka\n",
    "\n",
    "Due to Kafka’s powerful features, a vast number of well-known Fortune 500 companies leverage the tool in their technology stack. Kafka has become the corporation tool of choice for essentially any type of situation that involves real-time data streaming  and real-time data processing at scale.\n",
    "\n",
    "Netflix, Spotify, Uber, Lyft, Linkedin, Twitter, Goldman Sachs, New York Times, Emirates Airlines, Paypal, Intel, Tesla, Walmart, Airbnb, Adidas and Barclays are just some of the popular companies that use Kafka every day.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Kafka_System.png\" width=900>\n",
    "</p>\n",
    "\n",
    "For a detailed list of organisations powered by Kafka, take a look at the following link:\n",
    "\n",
    "- [Global Companies Powered by Kafka](https://kafka.apache.org/powered-by)\n",
    "\n",
    "The top Industries that use Kafka include the following:\n",
    "\n",
    "1.\tFinancial Services (Banks, Fintechs…)\n",
    "2.\tTechnology and Social Media\n",
    "3.\tAutomotive\n",
    "4.\tTelecommunications\n",
    "5.\tRetail\n",
    "6.\tHealthcare\n",
    "7.\tGaming\n",
    "8.\tAirlines\n",
    "\n",
    "Some of the most popular Use Cases for Kafka include:\n",
    "\n",
    "- Fraud Detection\n",
    "- Customer Satisfaction\n",
    "- Risk Modelling\n",
    "- Predictive Analytics\n",
    "- Trading\n",
    "- Machine Failure Prediction\n",
    "- Dynamic Energy Management\n",
    "- Recommendation Engines\n",
    "- Data Streaming\n",
    "\n",
    "\n",
    "For a detailed explanation of the top Kafka Use Cases by industry, please watch the following 40 minute video (you will need to sign up and provide an email address):\n",
    "\n",
    "- [Top Kafka Use Cases in Industry](https://videos.confluent.io/watch/5AA8GugNNDgdSs8acTHQFB?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Architecture and Concepts\n",
    "\n",
    "Kafka is a distributed system consisting of __servers__ and __clients__ that communicate via a high-performance TCP network protocol. It can be deployed on bare-metal hardware, virtual machines, and containers in on-premise as well as cloud environments.\n",
    "\n",
    "Below is a high-level overview of a typical Kafka architecture:\n",
    "<p align=\"center\">\n",
    " <img src=\"images/Kafka_Overview.png\" width=500>\n",
    "</p>\n",
    "\n",
    "\n",
    "__Servers__: Kafka is operated as a cluster of one or more servers that can span multiple datacenters or cloud regions. Some of these servers form the storage layer, called the __Brokers__. Other servers run Kafka Connect to continuously import and export data as event streams to integrate Kafka with your existing systems such as Relational Databases as well as other Kafka clusters. \n",
    "\n",
    "To let you implement mission-critical use cases, a Kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.\n",
    "\n",
    "__Clients__: They allow you to write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures. Kafka comes with such clients included, which are augmented by dozens of clients provided by the Kafka open-source community: clients are available for Java and Scala including the higher-level Kafka Streams library, for Go, Python, C/C++, and many other programming languages as well as REST APIs.\n",
    "\n",
    "The important components in Kafka are:\n",
    "- __Producers__ - which write (produce) the data\n",
    "- __Consumers__ - which read (consume) the data\n",
    "- __Topics__ - which is used as a storage mechanism for data records\n",
    "\n",
    "More details can be found in the below video and guide\n",
    "\n",
    "[Kafka Introduction Video](https://kafka.apache.org/intro) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Zookeeper and why is it important?\n",
    "\n",
    "Zookeeper is a top-level, 3rd party software maintained by the Apache Foundation.  It's not part of the Kafka ecosystem directly, but  rather acts as a centralised service and is used to maintain naming and configuration data and to provide flexible and robust synchronization within distributed systems. Zookeeper keeps track of status of the Kafka cluster nodes and it also keeps track of Kafka Topics, Partitions etc.\n",
    "\n",
    "Zookeeper itself allows multiple clients to perform simultaneous reads and writes and acts as a shared configuration service within the system. The Zookeeper Atomic Broadcast (ZAB) protocol is the brains of the entire system, making it possible for Zookeeper to act as an Atomic Broadcast system and issue orderly updates.\n",
    "\n",
    "Zookeeper is mainly responsible for the following tasks in a Kafka system:\n",
    "\n",
    "### Controller election\n",
    "The controller is one of the most important Broking entities in a Kafka ecosystem, and it also has the responsibility to maintain the leader-follower relationship across all the nodes. If a node for some reason is shutting down, it’s the controller’s responsibility to tell all the replicas to act as leader nodes in order to fulfill the duties of the leaders on the node that is about to fail. So, whenever a node shuts down, a new controller can be elected and it can also be made sure that at any given time, there is only one controller and all the follower nodes have agreed on that. The reason this is done is that there always has to be one node that is the leader.  The leader node is required to manage the cluster in a Master/Worker style architecture.\n",
    "\n",
    "### Configuration Of Topics\n",
    "The configuration regarding all the topics including the list of existing topics, the number of partitions for each topic, the location of all the replicas, list of configuration overrides for all topics and which node is the preferred leader, etc.\n",
    "\n",
    "### Access Control Lists\n",
    "Access Control Lists (or ACLs) for all the topics are also maintained within Zookeeper. An ACL is essentially a table which defines the access privilages that each user in a system has (for instance, who has read-only access).\n",
    "\n",
    "### Membership of the cluster\n",
    "Zookeeper also maintains a list of all the Brokers that are functioning at any given moment and are a part of the cluster. \n",
    "\n",
    "Zookeeper is also required in order to properly run Apache Kafka especially in a real-world production system.\n",
    "\n",
    "For details regarding Zookeeper, please visit the following link:\n",
    "\n",
    "- [What is Zookeeper](https://dattell.com/data-architecture-blog/what-is-zookeeper-how-does-it-support-kafka/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Apache Kafka locally\n",
    "\n",
    "To download Kafka locally on your machine, follow the instructions based on your operating system. If you plan on using Kafka on a service from a cloud provider such as AWS or Azure, you won't need to install Kafka on the cloud, as this will be provided from the respective service.\n",
    "\n",
    "### Linux\n",
    "\n",
    "#### Install Java 8\n",
    "\n",
    "1. Open a terminal on your Linux machine. Run the following command to update the package lists for upgrades and new installations: `sudo apt update`.\n",
    "\n",
    "2. Install Java 8 by running the following command: `sudo apt install openjdk-8-jdk`.\n",
    "\n",
    "3. During the installation process, you may be prompted to accept the terms of the Oracle Java license. Use the arrow keys to navigate and press Enter to accept the license.\n",
    "\n",
    "4. After the installation is complete, verify that Java 8 is installed by running the command: `java -version`. \n",
    "\n",
    "You should see the version information of Java 8 displayed in the terminal.\n",
    "\n",
    "#### Add Java 8 to PATH\n",
    "\n",
    "1. To find the installation location of Java 8, you can use the update-alternatives command. Run the following command in the terminal: `sudo update-alternatives --config java`.\n",
    "\n",
    "2. You will see a list of installed Java versions. Identify the entry for Java 8 and note the corresponding path listed next to it.\n",
    "\n",
    "3. Open a text editor and create or edit the shell configuration file using the following command: `nano ~/.bashrc`. \n",
    "\n",
    "4. Add the following line at the end of the file to set the `JAVA_HOME` environment variable:\n",
    "\n",
    "`export JAVA_HOME=\"/path/to/java8\"`\n",
    "\n",
    "Replace `/path/to/java8` with the actual installation path of Java 8 that you obtained in the previous step.\n",
    "\n",
    "5. Save the file and exit the text editor. To apply the changes to the current session, run the command: `source ~/.bashrc`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mac OS\n",
    "\n",
    "#### Install Java 8\n",
    "\n",
    "1. Check if Java 8 is already installed on your Mac by opening a terminal and running the command: `java -version`. If Java 8 is installed, you will see the version information. If not, proceed to the next step.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/MacJava8.png\" height=\"400\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "2. Open a web browser and go to the official Oracle website for Java SE downloads: https://www.oracle.com/java/technologies/javase-jdk8-downloads.html.\n",
    "\n",
    "3. Scroll down to the \"Java SE Development Kit 8 Downloads\" section.\n",
    "\n",
    "4. Select the appropriate installer for macOS by clicking on the download link next to it. The file will look like this: `jdk-8uXXX-macosx-x64.dmg`. You may need to sign in or create an Oracle account to access the download.\n",
    "\n",
    "5. Once the download is complete, locate the downloaded file (e.g., jdk-8uXXX-macosx-x64.dmg).\n",
    "\n",
    "6. Double-click the downloaded file to mount the disk image. Double-click the mounted disk image (JDK xxx.pkg) to start the installation.\n",
    "\n",
    "7. Follow the on-screen instructions to complete the Java 8 installation. After successfully installing Java 8, you can verify the installation by opening a terminal and running the command `java -version`. You should see the version information for Java 8 displayed in the terminal.\n",
    "\n",
    "#### Add Java 8 to PATH\n",
    "\n",
    "If you downloaded and installed Java from the Oracle website, you can find the installation location by following these steps:\n",
    "\n",
    "1. Open a terminal on your Mac. Run the following command to display the installed versions of Java on your system:\n",
    "\n",
    "`/usr/libexec/java_home -V`\n",
    "\n",
    "2. The output will list the installed versions of Java along with their corresponding installation paths. Look for the version you installed, such as `1.8.x_xx`, and note down the installation path associated with it. The installation path will typically look similar to this:\n",
    "\n",
    "`/Library/Java/JavaVirtualMachines/jdk1.8.0_XXX.jdk/Contents/Home`\n",
    "\n",
    "Please note that the exact installation path may vary depending on the specific version of Java and macOS you have. Once you have identified the installation path, you can use it to set the `JAVA_HOME` environment variable or include it in your `PATH` configuration, if necessary, for applications like Apache Kafka.\n",
    "\n",
    "3. Now that you have the installation path, open your user profile configuration file in a text editor: `nano ~/.zshrc`\n",
    "\n",
    "4. In the text editor, add the following line to the file: `export JAVA_HOME=\"/Library/Java/JavaVirtualMachines/jdk1.8.0_XXX.jdk/Contents/Home\"`\n",
    "\n",
    "Replace `/Library/Java/JavaVirtualMachines/jdk1.8.0_XXX.jdk/Contents/Home` with the actual installation path of Java that you obtained from the previous step.\n",
    "\n",
    "5. Save your changes and run the following command to apply the changes to your current session: `source ~/.zshrc`.\n",
    "\n",
    "6. To verify that `JAVA_HOME` is set correctly, run the command: `echo $JAVA_HOME`. It should display the installation path of Java you set in the `.zshrc` file.\n",
    "\n",
    "With `JAVA_HOME` set in your `.zshrc` file, any applications or scripts that rely on the `JAVA_HOME` environment variable will be able to locate your Java installation correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows\n",
    "\n",
    "> For Windows follow the same process as for Linux for downloading Java 8 and adding it to your `PATH`, but make sure to run all of this after launching your WSL instance on Windows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Kafka\n",
    "\n",
    "1. Open a web browser and go to the official Apache Kafka website at https://kafka.apache.org/downloads.\n",
    "\n",
    "2. Click on the link to download the latest stable release of Apache Kafka for Scala 2.13.\n",
    "\n",
    "3. Once the download is complete, open a terminal. Navigate to the directory where you downloaded Kafka. For example, if the file is in your Downloads folder, you can use the following command to navigate to that location: `cd ~/Downloads`.\n",
    "\n",
    "4. Extract the downloaded Kafka archive by running the following command: `tar -xzf kafka_<version>.tar`. Replace `<version>` with the actual version number you downloaded.\n",
    "\n",
    "5. Move into the Kafka directory by running the command: `cd kafka_<version>`. Again, replace `<version>` with the appropriate version number.\n",
    "\n",
    "6. Now if you run `ls -al`, the output of this command should look similar to:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/MacKafka.png\" height=\"400\" width=\"500\"/>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered the basics on what Apache Kafka is, let's get hands-on.\n",
    "\n",
    "You'll need:\n",
    "- A Linux environment setup with a suitable distribution (such as Ubuntu).  \n",
    "- Java 8 or higher installed and properly set up\n",
    "\n",
    "There are two different ways to download Kafka:\n",
    "\n",
    "1. Install Kafka via a Package Manager\n",
    "2. Download the Kafka tarball directly and extract it to your local machine\n",
    "\n",
    "Run the following terminal command below to install Kafka from the tarball directly using Apache Kafka version 2.12:\n",
    "\n",
    "_Note: Please ensure you are downloading the Kafka __Binary__ not the Source tar_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the command completes successfully, you should see output similar to this:\n",
    "\n",
    "![](images/kafka-download2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to unpack the tarball to be able to access the Kafka files.  Use the following command to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tar -xzf kafka_2.13-3.0.0.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/kafka-untar2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to go into the new folder and check the contents.  As I'm sure you know, we can run the following commands to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd kafka_2.13-3.0.0\n",
    "\n",
    "ls -al\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look similar to:\n",
    "\n",
    "![](images/kafka-folder3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, you've successfully downloaded Kafka and unzipped the files locally into their respective folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take a deeper dive into the Kafka topology and components, and we'll also start using Kafka hands-on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2592652612463181e69ac003232387e3e9a99279aa6b168e76f5df16d5110f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
