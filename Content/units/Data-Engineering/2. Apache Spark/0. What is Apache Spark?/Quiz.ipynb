{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Apache Spark?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following is true about Apache Spark?\n",
    "\n",
    "- Spark is a distributed computing system for processing big data ***\n",
    "- Spark can only be used with the Hadoop Distributed File System (HDFS)\n",
    "- Spark is a relational database management system\n",
    "- Spark is primarily used for transactional processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements are true about Apache Spark? Select all that apply.\n",
    "\n",
    "- Spark is a distributed computing system for processing large amounts of data ***\n",
    "- Spark supports multiple programming languages such as Python, Java, and Scala ***\n",
    "- Spark provides high-level APIs for machine learning and graph processing ***\n",
    "- Spark is designed to run only on a single machine\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following are key features of Apache Spark? Select all that apply.\n",
    "\n",
    "- In-memory computing ***\n",
    "- Fault-tolerance ***\n",
    "- Ease of use and compatibility with multiple programming languages ***\n",
    "- Batch processing only\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following programming languages are officially supported by Apache Spark? Select all that apply.\n",
    "\n",
    "- Python ***\n",
    "- Java ***\n",
    "- Scala ***\n",
    "- Ruby\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following cluster managers can be used with Apache Spark? Select all that apply.\n",
    "\n",
    "- Apache Hadoop YARN\n",
    "- Apache Mesos\n",
    "- Spark Standalone\n",
    "- All of the above ***\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following statements is true about Spark clusters?\n",
    "\n",
    "- A Spark cluster is a group of interconnected computers that work together to process large datasets in a distributed and parallel manner ***\n",
    "- Spark clusters are limited to a single data center\n",
    "- Spark clusters require a dedicated network infrastructure to function properly\n",
    "- Spark clusters can only be managed by the Spark Standalone cluster manager\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Spark driver?\n",
    "\n",
    "- The Spark driver is the part of the Spark application that runs on the worker nodes and performs the actual data processing\n",
    "- The Spark driver is a process that runs the main() function of the Spark application and coordinates the execution of tasks on the cluster ***\n",
    "- The Spark driver is a component that manages the storage and retrieval of data in Spark\n",
    "- The Spark driver is a cluster manager that is responsible for allocating resources to Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following is a function of a Spark cluster manager?\n",
    "\n",
    "- Allocating resources to Spark applications ***\n",
    "- Running the `main()` function of the Spark application \n",
    "- Coordinating the execution of tasks on the worker nodes\n",
    "- Performing the data processing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the `SparkSession`?\n",
    "\n",
    "- The SparkSession is the entry point to programming Spark with the Dataset and DataFrame API ***\n",
    "- The SparkSession is a component of the Spark cluster manager\n",
    "- The SparkSession is responsible for allocating resources to Spark applications\n",
    "- The SparkSession is the part of the Spark application that performs the actual data processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `spark-submit` in Apache Spark?\n",
    "\n",
    "- `spark-submit` is a command-line tool used to start the Spark driver program for a Spark application by submitting the Spark application code to a cluster ***\n",
    "- `spark-submit` is a component of the Spark cluster manager used to allocate resources to Spark applications\n",
    "- `spark-submit` is a Spark package used to interface with external data sources\n",
    "- `spark-submit` is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Spark Application in Apache Spark?\n",
    "\n",
    "- A Spark Application is a standalone application that runs on the Spark cluster and performs data processing tasks ***\n",
    "- A Spark Application is a component of the Spark cluster manager used to manage the resources allocated to Spark applications\n",
    "- A Spark Application is a Spark package used to interface with external data sources\n",
    "- A Spark Application is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Spark executor in Apache Spark?\n",
    "\n",
    "- A Spark executor is a node on the Spark cluster that runs tasks for a Spark application ***\n",
    "- A Spark executor is a component of the Spark cluster manager used to manage the resources allocated to Spark applications\n",
    "- A Spark executor is a Spark package used to interface with external data sources\n",
    "- A Spark executor is a web-based graphical user interface used to monitor and manage Spark applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `MapReduce` in Hadoop?\n",
    "\n",
    "- `MapReduce` is a programming model and software framework for processing large datasets in parallel across a Hadoop cluster ***\n",
    "- `MapReduce` is a distributed storage system that provides high-throughput access to data stored on Hadoop Distributed File System (HDFS)\n",
    "- `MapReduce` is a command-line interface tool used to manage and monitor Hadoop clusters\n",
    "- `MapReduce` is a distributed coordination service used to manage and synchronize the execution of Hadoop jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the main steps involved in a `MapReduce` job?\n",
    "\n",
    "- Map, Filter, Reduce\n",
    "- Load, Shuffle, Merge\n",
    "- Split, Map, Reduce ***\n",
    "- Input, Output, Storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if a task fails in a `MapReduce` job?\n",
    "\n",
    "- The MapReduce job fails and the entire job needs to be restarted from scratch\n",
    "- The MapReduce framework automatically retries the failed task a fixed number of times ***\n",
    "- The failed task is skipped and the MapReduce job continues with the remaining tasks\n",
    "- The output of the failed task is ignored and the MapReduce job continues with the remaining tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the main difference between Spark and Hadoop?\n",
    "\n",
    "- Hadoop is a distributed storage system, while Spark is a distributed data processing system ***\n",
    "- Hadoop is a batch processing system, while Spark is a real-time processing system\n",
    "- Hadoop is written in Java, while Spark is written in Scala\n",
    "- Hadoop and Spark are interchangeable and can be used interchangeably in all use cases"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
