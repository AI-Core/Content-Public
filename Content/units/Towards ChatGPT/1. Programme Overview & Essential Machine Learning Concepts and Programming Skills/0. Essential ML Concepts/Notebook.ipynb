{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential ML concepts\n",
    "\n",
    "## What is machine learning?\n",
    "\n",
    "Almost any problem can be framed as mapping from some input to some output\n",
    "\n",
    "![](./images/Input%20to%20Output.png)\n",
    "\n",
    "Some problems are easy to solve because we have managed to find the function that maps between them.\n",
    "\n",
    "![](./images/Easy%20Problems.png)\n",
    "\n",
    "For other problems of interest, it is extremely hard to find out what that function is.\n",
    "\n",
    "![](./images/Hard%20Problems.png)\n",
    "\n",
    "> Machine learning is the task of having a computer find this function for itself.\n",
    "\n",
    "A more technical definition is that machine learning is: any computer system that can improve on a task (T) as measured by a performance metric (P) with experience (E)\n",
    "\n",
    "As we will see, the most important functions in machine learning are parametric - that is, they have parameters which change the input-output relationship of the function.\n",
    "\n",
    "The learning in machine learning, is the adjusting of these parameters so that the function changes\n",
    "\n",
    "\n",
    "![](./images/How%20parameters%20affect%20predictions.gif)\n",
    "\n",
    "## The 4 typical components of any machine learning algorithm\n",
    "\n",
    "1. The data\n",
    "1. The model\n",
    "1. The criterion\n",
    "1. The optimiser\n",
    "\n",
    "### Component 1: Data\n",
    "\n",
    "> The data is a set of _examples_ that appear in your dataset\n",
    "\n",
    "Examples in a dataset usually consist of 2 things: \n",
    "1. _Features_\n",
    "    - The inputs\n",
    "    - The thing you are using to predict the output\n",
    "    - Also referred to as:\n",
    "        - Inputs\n",
    "1. _Labels_\n",
    "    - The output\n",
    "    - Also referred to as \n",
    "        - Outputs\n",
    "        - Targets\n",
    "\n",
    "Example datasets:\n",
    "- A large body of text, where the examples are different sentences\n",
    "- A set of examples containing images and their classification\n",
    "- A set of examples containing features of different houses and the price of that house\n",
    "\n",
    "In the most usual case, features of an example can be represented as a vector, and the labels as a scalar.\n",
    "\n",
    "![](./images/Features%20%26%20Labels.png)\n",
    "\n",
    "All of the features can be represented in a single matrix, where the rows are examples, and the columns are different features of each of those examples. We call this the _feature matrix_ or _design matrix_.\n",
    "\n",
    "![](./images/Feature%20Matrix.png)\n",
    "\n",
    "In the typical feature matrix, each row represents a particular example, and each column represents a particular feature\n",
    "\n",
    "> Unless specified otherwise, the first dimension represents the _batch dimension_ That is, each item along that dimension is a different example in the batch of examples.\n",
    "\n",
    "\n",
    "Whether your targets are continuous or categorical values determines whether you have a _regression_ or _classification_ problem\n",
    "- Regression: Targets are continuous\n",
    "    - E.g. House price prediction\n",
    "- Classification: Targets are categorical\n",
    "    - E.g. Which word should come next following the input text?\n",
    "\n",
    "> Your data defines your problem, and what your model learns\n",
    "\n",
    "### Component 2: Model\n",
    "\n",
    "> The model takes an input, and uses it to predict an output.\n",
    "\n",
    "![](./images/Features%20-Model-_%20Labels.png)\n",
    "\n",
    "For example:\n",
    "- Your model might take in a set of text and predict the next word\n",
    "- Your model might take in the joint positions and accelerations of a robot and use it to predict the next move\n",
    "- Your model might take in the features of a house and use it to predict the price\n",
    "\n",
    "Because in most important cases, the model is a mathematical function, the data needs to be represented numerically. \n",
    "This can be a challenge for some common data types like text.\n",
    "\n",
    "### Component 3: The Criterion\n",
    "\n",
    "> The criterion is a function that measures how bad your model is\n",
    "\n",
    "A criterion may commonly also be referred to as:\n",
    "- The loss function\n",
    "- The error function\n",
    "\n",
    "The value returned from the criterion is a measure of how _bad_ your model is, which may also be known as:\n",
    "- The loss\n",
    "- The error\n",
    "\n",
    "#### Mean Squared Error\n",
    "\n",
    "The most important loss function for regression is the _mean squared error_.\n",
    "\n",
    "![](./images/MSE%20Loss.png)\n",
    "\n",
    "![](./images/MSE%20Graph.png)\n",
    "\n",
    "#### Cross Entropy Loss\n",
    "\n",
    "The most important loss function for classification is the _cross entropy loss_.\n",
    "\n",
    "For classification tasks, your model will output a probability for each possible class. \n",
    "The cross entropy loss function is designed to take in the probability predicted for _the true class label_, and return:\n",
    "- a low loss if that probability is high\n",
    "    - The best probability to predict for the true label would be 1, which will give you a loss of zero\n",
    "- a high loss if that probability is low.\n",
    "    - The worst probability to predict for the true label would be 0, which will give you an infinite loss\n",
    "\n",
    "![](./images/Cross%20Entropy%20Loss.png)\n",
    "\n",
    "![](./images/Cross%20Entropy%20Graph.png)\n",
    "\n",
    "#### Model Optimisation\n",
    "\n",
    "As you optimise your model, you should see the loss decrease. Graphically, this produces what is known as a _loss curve_.\n",
    "\n",
    "![](./images/Loss%20Curve.png)\n",
    "\n",
    "\n",
    "### Component 4: The Optimiser\n",
    "\n",
    "> The optimiser is an algorithm used to update the model so that it improves\n",
    "\n",
    "The parameters of most models are initialised randomly. For the model to usefully map inputs to outputs, these parameters need to be adjusted by the optimiser.\n",
    "\n",
    "> The \"learning\" in \"machine learning\" refers to optimising model parameters\n",
    "\n",
    "#### Gradient descent\n",
    "\n",
    "The most important optimiser to be aware of is called _stochastic gradient descent_.\n",
    "\n",
    "Overall, it works like this:\n",
    "1. Get an example\n",
    "1. Make a prediction from the inputs by passing them through the function\n",
    "1. Compare the prediction with the target to compute the error\n",
    "1. Update the function parameters in such a way that reduces the error\n",
    "1. Repeat\n",
    "\n",
    "More intuitively, you can picture it doing this:\n",
    "\n",
    "![](./images/gradient-descent-visualisation.gif)\n",
    "\n",
    "It works as follows:\n",
    "- Take a batch of examples and predict their targets\n",
    "- Compute the gradient of the objective (the thing you want to minimise - in our case, the loss) with respect to the model parameters \n",
    "    - This tells you \"for each parameter, if I were to increase it slightly, how quickly would the objective increase\n",
    "    - The gradient is a scalar value for each model parameter\n",
    "- Update the parameters in the direction that would reduce the loss\n",
    "    - This direction is the opposite sign of the gradient\n",
    "        - If the parameter gradient is positive, then that means that increasing it would increase the loss, so it should be decreased\n",
    "        - If the parameter gradient is negative, then that means that decreasing it would increase the loss, so it should be increased\n",
    "    - We shift each parameter by an amount proportional to the gradient, scaled by a value we call the learning rate, $\\alpha$\n",
    "        - The learning rate controls the step size of each update\n",
    "            - Too small and the model will take too long to converge\n",
    "            - Too large and the model will diverge\n",
    "\n",
    "Mathematically, this is repeated until the stopping condition is met:\n",
    "\n",
    "## $\\hat{y} = model(x, w)$\n",
    "## $ L = loss(\\hat{y}, y)$\n",
    "## $ w \\leftarrow w - \\alpha \\frac{\\partial{L}}{\\partial w}$ \n",
    "\n",
    "Gradient descent requires that:\n",
    "- The model and loss function are continuous differentiable functions\n",
    "- The model is parametric\n",
    "\n",
    "\n",
    "## Other Machine learning jargon and essential concepts to understand\n",
    "\n",
    "### Supervised & Unsupervised data\n",
    "\n",
    "Supervised data is a set of data where each example contains both an input and an output.\n",
    "- House features -> House price label\n",
    "\n",
    "Unsupervised data, on the other hand, is a set of data where you only have features - no labels.\n",
    "- Corpus of unlabelled text\n",
    "\n",
    "### Thinking about high dimensional data\n",
    "\n",
    "![](./images/nD%20Space.png)\n",
    "\n",
    "Because we live in a 3-D world, we can visualise arrows with 1 dimension, 2 dimensions, and 3 dimensions. Each of these, is equivalent to a vector containing the coordinates of the end of the arrow.\n",
    "\n",
    "For higher dimensional objects, like a vector with 4 or more elements, you can still think of it like an arrow, but you can't quite visualise what it looks like.\n",
    "\n",
    "> 'To visualise 13 dimensional space, simply think of 3 dimensional space, and say \"13\" loudly' - Geoff Hinton\n",
    "\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Gradient descent optimises some parameters that control the function which the model represents directly, by directly changing their values during the training process where the model iteratively makes predictions and improves.\n",
    "\n",
    "> Hyperparameters are parameters that cannot be optimised directly, or that are difficult to optimise because they need to be set before training\n",
    "\n",
    "Hyperparameters include:\n",
    "- The type of function that represents the model e.g. neural network vs decision tree\n",
    "- The learning rate of the optimiser\n",
    "- The architecture of the neural network model\n",
    "\n",
    "\n",
    "### The training set, the validation set, and the test set\n",
    "\n",
    "When we train machine learning algorithms, we typically split the data into 3 sets, each with a different use.\n",
    "- The training set\n",
    "    - Used for updating model parameters that can be optimised directly\n",
    "- The validation set\n",
    "    - Used for evaluating trained models' generalisation capability\n",
    "    - Used to compare between different models and different model hyperparameters and make choices about which to use\n",
    "    - NOT used for evaluating final performance\n",
    "- The test set\n",
    "    - Used ONLY to determine a final measure of performance of the model on totally unseen data\n",
    "    - Never used to make any decision about which model or model parameters are better \n",
    "        - doing so would be cheating - picking the best model based on data its final performance will be evaluated on\n",
    "    - Different to the validation set. The validation set is used to make choices about the model \n",
    "\n",
    "### Overfitting & underfitting\n",
    "\n",
    "> Underfitting is when your model is not able to learn to perform well enough on the training set.\n",
    "\n",
    "![](./images/Underfitting.png)\n",
    "\n",
    "> Overfitting is when your model learns to fit the training set too closely.\n",
    "\n",
    "![](./images/Overfitting.png)\n",
    "\n",
    "Both overfitting and underfitting can lead to poor performance on unseen examples.\n",
    "\n",
    "Symptoms of overfitting and underfitting can appear in your loss curves, which can be helpful for debugging.\n",
    "\n",
    "<!-- ### Important Performance Metrics -->\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "> Regularisation is any method used to reduce the generalisation error of a model\n",
    "\n",
    "![](./images/Generalisation%20Gap.png)\n",
    "\n",
    "There are many approaches to regularisation, but we won't go into them here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3e643153f50b336c1c7a9d4d544c5113a86fd55c72312d55d3acd153a8b13ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
