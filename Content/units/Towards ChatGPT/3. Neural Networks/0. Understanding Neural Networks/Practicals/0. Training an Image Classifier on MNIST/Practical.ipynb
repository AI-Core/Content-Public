{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Image Classifier on the MNIST Dataset\n",
    "\n",
    "Two sentence description of the MNIST dataset.\n",
    "\n",
    "Run the cell below to import the necessary modules and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create our classifier. \n",
    "- Create a class called `ImageClassifier` that inherits from `torch.nn.Module`.\n",
    "- Make a simple two-layer network inside the class constructor. The input linear layer should have input size appropriate to a 28x28 pixel image, and an output size of 128.\n",
    "- The output linear layer should have an output size of 10, reflecting the number of classes in the `MNIST` dataset.\n",
    "- The two linear layers should be connected by an activation layer.\n",
    "- Don't forget to add inheritance from `nn.Module` by calling the `super` constructor.\n",
    "- Create the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO Call super.\n",
    "        # TODO Define input, activation and output layers\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO define forward method.\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create our image transform, and load the dataset. We can quickly load the dataset from the `torchvision.datasets` module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='mnist', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to perform a split on the data so that we can train our model and evaluate it. \n",
    "\n",
    "- Split the dataset into a training set comprising 80% of the data, and a test set comprising 20% of the data. Call these subsets `train_set` and `test_set`.\n",
    "- Assign each split to its own dataloader, called `train_loader` and `test_loader` respectively. Set `shuffle=True` for the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Define the sizes of the train and test set\n",
    "# TODO - Use the `random_split()` method to create a `train` and `test` dataset\n",
    "# TODO - Create the training dataloader\n",
    "# TODO - Create the test dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get everything ready for training, we need to initialise the model, an optimiser and a criterion. In the code block below, initialise an instance of your model class, as well as an optimiser for Stochastic Gradient Descent (SGD), and an appropriate loss criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "# TODO - Initisalise the model.\n",
    "# TODO - Initialise the SGD optimiser, setting learning rate to 0.01\n",
    "# TODO - Initialise the criterion, using a loss function appropriate for multi-class classification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training loop inside a function called `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def train(train_loader, optimiser, criterion):\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # TODO - Zero the grad\n",
    "            # TODO - Perform the forward pass\n",
    "            # TODO - Calculate the loss\n",
    "            # TODO - Backpropagate the loss\n",
    "            # TODO - Step the Optimiser\n",
    "            # TODO - Update the running_loss variable by adding the current loss.item() to the running_loss variable.\n",
    "        print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "train(train_loader, optimiser, criterion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the model performs on an example from the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Get a single example from the test dataset\n",
    "# TODO - Set model to eval()\n",
    "# TODO - Pass the example to the model to get the prediction logits.\n",
    "# TODO - Take the softmax of the logits\n",
    "# TODO - Print the class label for the prediction of highest likelihood.\n",
    "# TODO - Print the real target label for the example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36d4b688d7e3685ae8ad6703c0e99019531dd9f05b6e8f8c82292a1f759bcdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
