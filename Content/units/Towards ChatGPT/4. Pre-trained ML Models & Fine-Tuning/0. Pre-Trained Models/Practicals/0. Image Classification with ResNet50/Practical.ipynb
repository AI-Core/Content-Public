{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with ResNet50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pre-trained image classifier is a quick and efficient way to classify images by content .It involves loading a pretrianed model that has been trained on a large dataset, and then using it to make predictions on new images. Models such as ResNet have already been trained to classify a large range of objects, and so the pretrained model can often be used without any additional training for basic classification tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from google.colab import files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Transforms\n",
    "\n",
    "To use the pre-trained model, it is important to transform the image so as to present it to the model in a format which is compatible with the model's architecture, and also reflects the feature engineering used to train the model. For this we can use  the `torchvision.transforms` module.\n",
    "\n",
    "The following codeblock uses the `transforms.compose` class to compose a sequence of transforms. Important considerations when using transforms for pre-trained images include ensuring that the image is of the correct size to match the input layer, and applying any transforms used on the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image from your directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = utils_image.open_user_image(transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sense of the model's output, it is necessary to have a decoder - essentially a dictionary where the keys are the integer labels used by the classifier, and the values are the human-readable class nammes. The codeblock below loads in the classes as a list, with the keys implicit in the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get imagenet classes\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "classes[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy, pred = torch.max(output, 1)\n",
    "print(\"Prediction label: \", pred)\n",
    "class_label = classes[pred]\n",
    "print(\"Prediction category: \", class_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-projects_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b961f8166aad6ccb4cf65d0f9c742ef9c6c23ffe83ad932438cd83ed96aebaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
