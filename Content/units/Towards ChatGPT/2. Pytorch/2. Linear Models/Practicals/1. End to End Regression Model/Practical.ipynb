{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Regression Model Training in Pytorch\n",
    "\n",
    "Let's train a regression model from start to finish on some example data. For this practical we will use the Boston Housing dataset. The Boston Housing dataset is a widely used dataset for regression analysis and machine learning, consisting of 13 feature variables describing various aspects of residential homes in the Boston suburbs and a target variable indicating the median value of owner-occupied homes in $1000s. It was collected by the U.S Census Service in 1978 and has been used for benchmarking and evaluation of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the packages we need and load the dataset\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "boston_data = load_boston()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to print the keys of the dataset dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data['data']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the codeblock below, create a `pandas` dataframe called `df` from the array in the `data` field of the dictionary, assiging column names from the `feature_names` field.\n",
    "Then add a column called `Price` to the dataframe, consisting of the values in the `target` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here!\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are quite diverse, with very different absolute value ranges for each feature. In order to give the features equivalent weight in the model, it is good practice to normalise the features data. Run the code block below to normalise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.columns[:-1]]\n",
    "data = data.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "data['Price'] = df.Price\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data are now arranged around a mean of approximately zero, with an SD of 1. \n",
    "\n",
    "We can now use this data to build a `Dataset` class  - essentially a container that stores the data, along with a set of inbuilt functions (methods) which allow us to pass the data to our model in a format that it can use. You don't need to worry too much about the details of the `Dataset` class at this stage, but you can read a brief description of its structure below.\n",
    "\n",
    "There are three key methods in a Pytorch dataset:\n",
    "\n",
    "- The first is the class constructor, which is a method that every Python class has. It tells the python interpreter what to do when it makes an instance of the class.\n",
    "\n",
    "- Second, we need a method called `__getitem__`. This method defines what happens when we ask the dataset for a single example datapoint - ie. a set of features and a label. \n",
    "\n",
    "- Finally we have the `__len__` method. This describes what to do when we call python's `len()` method on the dataset, and returns the number of samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x=data.drop('Price', axis=1).to_numpy()\n",
    "        self.y=data['Price'].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        features = torch.tensor(self.x[idx,:],dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(self.y[idx], dtype=torch.float32 )\n",
    "        return features,label\n",
    "\n",
    "dataset=BostonDataset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now get a single sample of the data by indexing. Add some code to the cell below to print the shape of the features and the label from a single sample of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,label=dataset[1]\n",
    "# write code here to print the shape of the features and label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define a data loader. The `dataloader` is a tool for collating a batch of samples from the dataset, and passing it to the model. Look online at the docs for `torch.utils.data.DataLoader` and see if you can work out how to get the dataloader to give us an example batch of data, and print the shape of the batch of features and the batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "# Add code to get the next iteration of the dataloader, and print the shape of the labels and features "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined how to pass the data to our model, we can build the model itself. You don't need to worry about all the details of how the model is constructed at this stage, just note that it is built from an alternating sequence of linear and nonlinear (`ReLu`) layers. Also note that it contains an inbuilt function (known as a  `method`) called `forward`. The `forward` method defines what happens when we pass the data to the model during the forward pass, and all the detail is handled under the surface by `Pytorch` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel,self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(13, 13),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(13, 13),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(13, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set things up ready for training. The definition in the previous code block is called a `class`, and is a general description of the model, whereas the variable called `model` below is an instance of that class, a single example of it.\n",
    "\n",
    "The `criterion` is the function we use to calculate the loss between the predictions and the labels, in this case we are doing regression so we use mean-squared-error (`MSE`).\n",
    "\n",
    "Finally we need an `optimiser`, that's the function that determines how to update the model's connection weights based on the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0003)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to construct the training loop. The cell below contains a basic outline for the training loop. Fill in the python code to make it work correctly, per the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(800)\n",
    "\n",
    "epoch_idx = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        \n",
    "        # reset the gradients in the optimiser\n",
    "        # pass the inputs to the model and assing to a variable called 'outputs'\n",
    "        # calculate the loss between the outputs and the targets using the criterion\n",
    "        # perform the backward pass\n",
    "        # step the optimiser\n",
    "        pass\n",
    "    print(f'Epoch: {epoch + 1}/100, Loss: {loss.item():.4f}')\n",
    "    # add some code here to concatenate the loss for each epoch into a list, so that the data can be plotted.\n",
    "    epoch_idx+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot our loss curve. Use the matplotlib library to make a scattergraph of your list of loss values (y-axis) against epoch number (x-axis). What can you say about the training? Has the model converged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36d4b688d7e3685ae8ad6703c0e99019531dd9f05b6e8f8c82292a1f759bcdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
