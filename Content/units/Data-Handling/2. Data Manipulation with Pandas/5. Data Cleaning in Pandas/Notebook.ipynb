{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This lesson outlines some of the techinques for cleaning different data types in Pandas. It will draw on the methods discussed in previous lessons, but with a focus on how to apply them to specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Data\n",
    "\n",
    "### Common Text Operations\n",
    "\n",
    "> In data cleaning, one often deals with text data that requires standardisation and formatting. Pandas offers several built-in methods that make these tasks straightforward. \n",
    "\n",
    "#### 1. String Trimming \n",
    "The `.str.strip()` method is used to remove whitespace from the beginning and end of a string. It's particularly useful when your dataset contains extra spaces that may affect data quality or analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Horse\n",
       "1    Horse   \n",
       "2       HORSE\n",
       "3     HORSE  \n",
       "4       H@RSE\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "example_series = pd.Series([' Horse', 'Horse   ', '   HORSE', 'HORSE  ', 'H@RSE'])\n",
    "example_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Horse\n",
       "1    Horse\n",
       "2    HORSE\n",
       "3    HORSE\n",
       "4    H@RSE\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_series = example_series.str.strip()\n",
    "example_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Converting Case\n",
    "\n",
    ">When handling categorical variables it is often necessary to standardise the case of your text data. In such instances, it's not uncommon to find the same category represented in varying cases - some in uppercase, others in lowercase, or even a mix. A common solution is to force the text into either upper or lower case, and this can be achieved with the `.str.lower()` and `.str.upper()` methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    HORSE\n",
       "1    HORSE\n",
       "2    HORSE\n",
       "3    HORSE\n",
       "4    H@RSE\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all to Uppercase\n",
    "example_series.str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    horse\n",
       "1    horse\n",
       "2    horse\n",
       "3    horse\n",
       "4    h@rse\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all to Lowercase\n",
    "example_series = example_series.str.lower()\n",
    "example_series.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fixing Incorrect Values with the `replace()` Method\n",
    "> Another common scenario is a column containing values that are systematically incorrect in some way, for example a word that is often mis-spelled. This is heavily data dependent, and will require an understanding of what the column is supposed to contain. \n",
    "\n",
    "The simplest usage of `replace()` is to simply replace one character string with another:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    horse\n",
       "1    horse\n",
       "2    horse\n",
       "3    horse\n",
       "4    horse\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_series = example_series.str.replace('@', 'o')\n",
    "example_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced String Manipulation\n",
    ">Aside from the simple examples described above, Pandas is capable of much more advanced string manipulations. Let's consider some situations and how they are handled.\n",
    "\n",
    "### Scenario: Cleaning a Boolean Column\n",
    "In this example, we will look at a column called `CANCELLED`, which is intended to be a Boolean column indicating whether a service or order has been cancelled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CANCELLED\n",
       "False        19\n",
       "0            13\n",
       "F            13\n",
       "True          3\n",
       "1             1\n",
       "T             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancelled = pd.read_csv('https://cdn.theaicore.com/content/lessons/b17e0a6b-68db-4a1f-9433-04ab57d6da3a/cancellations.csv')\n",
    "\n",
    "cancelled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the column is intended as a Boolean, but the values have been expressed in a variety of ways. There are a couple of techniques to fix this situation. The first is to use the `.replace()` method to replace one value with another. For example, we can replace all the `0` values with `False` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CANCELLED\n",
       "False        19\n",
       "False        13\n",
       "F            13\n",
       "True          3\n",
       "1             1\n",
       "T             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancelled.replace({'0': False}, inplace=True)\n",
    "cancelled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `False` appears twice in the `value_counts` result. This is because Pandas is distinguishing between the string  `\"False\"` and the Boolean value `False`. If we want to convert the column to a Boolean type, we will need to ensure that all values in it are of Boolean type.\n",
    "\n",
    "The `.replace()` method can also accept a dictionary, where the dictionary keys are the values to match, and the dictionary values are the replacement values, e.g. `df.replace({'0': False, '1' : True})` to replace all instances of `0` or `1` with `False` and `True` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CANCELLED\n",
       "False        45\n",
       "True          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dictionary = {'0': False, '1': True, 'F': False, 'T': True, 'True': True, 'False': False}\n",
    "cancelled.replace(mapping_dictionary, inplace=True)\n",
    "cancelled = cancelled.astype('bool')\n",
    "cancelled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario: Forcing Values to Adhere to a Pattern\n",
    "\n",
    "In some cases, it might be clear from the data in a column that a particular pattern should be expected for all values, in which case it may make sense to remove or replace any values that do not adhere to this pattern. An example might be a column containing UK phone numbers. There are multiple ways to represent a UK phone number, for example `+44 7555 555 555` or `07555 555555`. To handle the situation where multiple possible formats exist, the solution is to apply a *regular expression* to handle as many cases as possible. \n",
    "\n",
    ">A **regular expression**, often abbreviated as *regex*, is a sequence of characters that defines a search pattern that can be used for matching, allowing for complex search, replace, and validation operations.\n",
    "\n",
    "**Regex** is an extensive topic, and the details of constructing **regex** patterns are beyond the scope of this lesson, but as with much in the world of data, the work has often already been done for you, and can be found on various internet websites such as [Stack Overflow](https://stackoverflow.com/), or in various searchable **regex** repositories such as [regexlib](https://regexlib.com/). Searching **regexlib** for `UK Phone Number` provides this option:\n",
    "\n",
    " `^((\\(?0\\d{4}\\)?\\s?\\d{3}\\s?\\d{3})|(\\(?0\\d{3}\\)?\\s?\\d{3}\\s?\\d{4})|(\\(?0\\d{2}\\)?\\s?\\d{4}\\s?\\d{4}))(\\s?\\#(\\d{4}|\\d{3}))?$`\n",
    "\n",
    "Which covers the majority of UK phone number variants, including area codes with brackets (e.g. `(020)`), and extensions following a `#` symbol. \n",
    "\n",
    "Let's try it out on an example column of phone numbers. In the code block below, we will create an example `DataFrame` of phone numbers, including some invalid numbers, and then write code to apply the **regex** to each row in the column, and replace any values that do not comply with `NaN`. We will use the `str.match()` method to apply the **regex** expression, and then use logical indexing to replace the non-matching values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>0123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>01234 567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>+441234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>0123-456-789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>(0123) 456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>1234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace</td>\n",
       "      <td>0123456789a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hank</td>\n",
       "      <td>01234-567-890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ivy</td>\n",
       "      <td>+44 1234 567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jack</td>\n",
       "      <td>01234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name            Phone\n",
       "0    Alice       0123456789\n",
       "1      Bob     01234 567890\n",
       "2  Charlie    +441234567890\n",
       "3    Diana     0123-456-789\n",
       "4      Eva    (0123) 456789\n",
       "5    Frank       1234567890\n",
       "6    Grace      0123456789a\n",
       "7     Hank    01234-567-890\n",
       "8      Ivy  +44 1234 567890\n",
       "9     Jack            01234"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a sample dataframe\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eva', 'Frank', 'Grace', 'Hank', 'Ivy', 'Jack'],\n",
    "    'Phone': ['0123456789', '01234 567890', '+441234567890', '0123-456-789', \n",
    "              '(0123) 456789', '1234567890', '0123456789a', '01234-567-890', \n",
    "              '+44 1234 567890', '01234']\n",
    "}\n",
    "\n",
    "phone_df = pd.DataFrame(data)\n",
    "\n",
    "phone_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>0123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>01234 567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>+441234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>0123-456-789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>(0123) 456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hank</td>\n",
       "      <td>01234-567-890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ivy</td>\n",
       "      <td>+44 1234 567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name            Phone\n",
       "0    Alice       0123456789\n",
       "1      Bob     01234 567890\n",
       "2  Charlie    +441234567890\n",
       "3    Diana     0123-456-789\n",
       "4      Eva    (0123) 456789\n",
       "5    Frank              NaN\n",
       "6    Grace              NaN\n",
       "7     Hank    01234-567-890\n",
       "8      Ivy  +44 1234 567890\n",
       "9     Jack              NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # We will need the `nan` constant from the numpy library to apply to missing values\n",
    "\n",
    "regex_expression = '^(?:(?:\\(?(?:0(?:0|11)\\)?[\\s-]?\\(?|\\+)44\\)?[\\s-]?(?:\\(?0\\)?[\\s-]?)?)|(?:\\(?0))(?:(?:\\d{5}\\)?[\\s-]?\\d{4,5})|(?:\\d{4}\\)?[\\s-]?(?:\\d{5}|\\d{3}[\\s-]?\\d{3}))|(?:\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4})|(?:\\d{2}\\)?[\\s-]?\\d{4}[\\s-]?\\d{4}))(?:[\\s-]?(?:x|ext\\.?|\\#)\\d{3,4})?$' #Our regular expression to match\n",
    "phone_df.loc[~phone_df['Phone'].str.match(regex_expression), 'Phone'] = np.nan # For every row  where the Phone column does not match our regular expression, replace the value with NaN\n",
    "phone_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario: Cleaning Numeric Columns with `.replace()`\n",
    "\n",
    "The `.replace()` method can also be used to clean up numeric data, for example if you have a column of prices that contain the `Â£` symbol, thereby preventing the column from being cast to a numeric data type. \n",
    "\n",
    "In the example of the phone numbers `DataFrame`, we still have a variety of non-numeric characters in the data which should be replaced in order to regularise the numbers. To rectify this the following actions are needed:\n",
    "\n",
    "- Replace any instances of `+44` with `0`, as this is how to write the number for calling within the UK\n",
    "- Replace the `(` and `-` characters with nothing (i.e. remove them)\n",
    "- Remove all spaces\n",
    "\n",
    "The code block below shows how to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>0123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>01234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>01234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>0123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>0123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hank</td>\n",
       "      <td>01234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ivy</td>\n",
       "      <td>01234567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name        Phone\n",
       "0    Alice   0123456789\n",
       "1      Bob  01234567890\n",
       "2  Charlie  01234567890\n",
       "3    Diana   0123456789\n",
       "4      Eva   0123456789\n",
       "5    Frank          NaN\n",
       "6    Grace          NaN\n",
       "7     Hank  01234567890\n",
       "8      Ivy  01234567890\n",
       "9     Jack          NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do each step one by one, for example with the following syntax for the `+44`: 0 replacement:\n",
    "\n",
    "phone_df['Phone'] = phone_df['Phone'].str.replace('+44', '0', regex=False)\n",
    "phone_df\n",
    "\n",
    "# Or by setting `regex=True`, you can do it all in one step:\n",
    "\n",
    "phone_df['Phone'] = phone_df['Phone'].replace({r'\\+44': '0', r'\\(': '', r'\\)': '', r'-': '', r' ': ''}, regex=True)\n",
    "phone_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Values\n",
    "\n",
    "\n",
    "\n",
    "It is sometimes necessary to find the number of unique values in a column. For example, we might be working with a column of product IDs, where it would negatively affect our analysis to have multiple products with the same ID. To check whether an issue like this exists, we can use the methods `unique` and `nunique`.\n",
    "\n",
    "- The `unique` method returns all the unique (i.e. distinct) values in the data series. For example, given a series of `[ 1, 1, 2, 3, 4]` it would return `[1, 2, 3, 4]`.\n",
    "- The `nunique` method returns the **count** of unique values in the series. For example, from a series of `[ 1, 1, 2, 3, 4]` it would return `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "  product_ids\n",
      "0        P001\n",
      "1        P002\n",
      "2        P003\n",
      "3        P001\n",
      "4        P004\n",
      "5        P005\n",
      "6        P003\n",
      "7        P006\n",
      "8        P002\n",
      "\n",
      "Unique product IDs:\n",
      "['P001' 'P002' 'P003' 'P004' 'P005' 'P006']\n",
      "\n",
      "Number of unique product IDs:\n",
      "6\n",
      "\n",
      "Total number of rows in the dataframe:\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample dataframe with a column of product IDs\n",
    "data = {'product_ids': ['P001', 'P002', 'P003', 'P001', 'P004', 'P005', 'P003', 'P006', 'P002']}\n",
    "products_df = pd.DataFrame(data)\n",
    "\n",
    "# Using `unique` to get unique product IDs\n",
    "unique_ids = products_df['product_ids'].unique()\n",
    "\n",
    "# Using `nunique` to get the number of unique product IDs\n",
    "num_unique_ids = products_df['product_ids'].nunique()\n",
    "\n",
    "# Displaying the original DataFrame\n",
    "print(\"Original dataframe:\")\n",
    "print(products_df)\n",
    "\n",
    "# Displaying the unique product IDs\n",
    "print(\"\\nUnique product IDs:\")\n",
    "print(unique_ids)\n",
    "\n",
    "# Displaying the number of unique product IDs and the total number of rows in the DataFrame\n",
    "print(\"\\nNumber of unique product IDs:\")\n",
    "print(num_unique_ids)\n",
    "\n",
    "\n",
    "print(\"\\nTotal number of rows in the dataframe:\")\n",
    "print(len(products_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Duplicates\n",
    "\n",
    "\n",
    "> *Duplicates* in data refer to two or more rows that are identical across all columns, or, depending on the context, identical in a subset of columns, which can lead to redundancy and inaccuracies in data analysis and interpretation. The presence of duplicates is a common data cleaning issue, as duplicated data can distort descriptive statistics and data visualisations, leading to inaccurate insights and misinformed decisions. For instance, duplicate entries can artificially inflate the count of a category, skewing measures of central tendency like the mean and median, and affecting the distribution of data in visual representations.\n",
    "Duplicates can either be *exact*, where a row is identical to another row across all columns, or *fuzzy*, which is where the two rows differ in some columns, but appear to describe the same entity. \n",
    "\n",
    "Exact duplicates are trivial to handle in `Pandas`. You can find all the duplicated rows in a `DataFrame` using the `.duplicated()` method, or drop them using the `drop_duplicates()` method. Run the two code blocks below to generate some example duplicate data, and then use the `drop_duplicates()` method to drop the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>28</td>\n",
       "      <td>123-456</td>\n",
       "      <td>alice@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>34</td>\n",
       "      <td>456-789</td>\n",
       "      <td>bob@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>45</td>\n",
       "      <td>789-012</td>\n",
       "      <td>charlie@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>28</td>\n",
       "      <td>123-456</td>\n",
       "      <td>alice@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>23</td>\n",
       "      <td>345-678</td>\n",
       "      <td>eva@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>45</td>\n",
       "      <td>789-012</td>\n",
       "      <td>charlie@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Phone              Email\n",
       "0    Alice   28  123-456    alice@email.com\n",
       "1      Bob   34  456-789      bob@email.com\n",
       "2  Charlie   45  789-012  charlie@email.com\n",
       "3    Alice   28  123-456    alice@email.com\n",
       "4      Eva   23  345-678      eva@email.com\n",
       "5  Charlie   45  789-012  charlie@email.com"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating a sample dataframe\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eva', 'Charlie'],\n",
    "    'Age': [28, 34, 45, 28, 23, 45],\n",
    "    'Phone': ['123-456', '456-789', '789-012', '123-456', '345-678', '789-012'],\n",
    "    'Email': ['alice@email.com', 'bob@email.com', 'charlie@email.com', \n",
    "              'alice@email.com', 'eva@email.com', 'charlie@email.com']\n",
    "}\n",
    "duplicate_df = pd.DataFrame(data)\n",
    "duplicate_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find and remove the exact duplicates in the `DataFrame` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of duplicate_df.duplicated():\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "dtype: bool\n",
      "\n",
      "dataframe After Removing Duplicates:\n",
      "      Name  Age    Phone              Email\n",
      "0    Alice   28  123-456    alice@email.com\n",
      "1      Bob   34  456-789      bob@email.com\n",
      "2  Charlie   45  789-012  charlie@email.com\n",
      "4      Eva   23  345-678      eva@email.com\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates based on all columns\n",
    "print(\"result of duplicate_df.duplicated():\")\n",
    "print(duplicate_df.duplicated())\n",
    "\n",
    "# Identifying and dropping exact duplicates\n",
    "df_no_duplicates = duplicate_df.drop_duplicates()\n",
    "\n",
    "# Displaying the dataframe after removing duplicates\n",
    "print(\"\\ndataframe After Removing Duplicates:\")\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible existence of **fuzzy** duplicates can present a greater challenge. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Smith</td>\n",
       "      <td>28</td>\n",
       "      <td>123-456</td>\n",
       "      <td>alice@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Smith</td>\n",
       "      <td>34</td>\n",
       "      <td>456-789</td>\n",
       "      <td>alice@smith.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Smith</td>\n",
       "      <td>45</td>\n",
       "      <td>123-456</td>\n",
       "      <td>alice@theinternet.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Smith</td>\n",
       "      <td>45</td>\n",
       "      <td>123-456</td>\n",
       "      <td>Alice@theinternet.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First_Name Last_Name  Age    Phone                  Email\n",
       "0      Alice     Smith   28  123-456        alice@email.com\n",
       "1      Alice     Smith   34  456-789        alice@smith.com\n",
       "2      Alice     Smith   45  123-456  alice@theinternet.com\n",
       "3      Alice     Smith   45  123-456  Alice@theinternet.com"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'First_Name': ['Alice', 'Alice', 'Alice',  'Alice'],\n",
    "    'Last_Name': ['Smith', 'Smith', 'Smith', 'Smith'],\n",
    "    'Age': [28, 34, 45, 45],\n",
    "    'Phone': ['123-456', '456-789', '123-456', '123-456'],\n",
    "    'Email': ['alice@email.com', 'alice@smith.com', \n",
    "              'alice@theinternet.com',  'Alice@theinternet.com']\n",
    "}\n",
    "\n",
    "fuzzy_duplicates_df = pd.DataFrame(data)\n",
    "fuzzy_duplicates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, each column is a partial match for all the other columns. Handling this kind of partial (**fuzzy**) matching requires consideration of what each column represents. For example the name `Alice Smith` is relatively common in English-speaking countries, so we should not assume that all of the entries are the same person. Meanwhile ages can be mistyped, and it's even possible that there are multiple people called Alice Smith at the same address, sharing the same phone number. On the other hand row IDs `2` and `3` are probably the same person, given that the only difference is the capitalisation in the `Email` column.\n",
    "\n",
    "How you choose to handle **fuzzy** duplicates depends on your analysis goals. In some cases it might make sense to take a conservative approach to avoid losing data unnecessarily, whereas in other cases it might be necessary to apply more stringent measures to avoid duplicates. You will also need to decide whether to simply drop the **fuzzy** duplicates you identify, or average the values of certain columns (e.g. a product price column).\n",
    "\n",
    "Generally, the more columns you have for reference, the easier it is to determine whether a partial match is a duplicate. There are also software tools to help you, for example this python [library](https://pypi.org/project/fuzzywuzzy/) that uses the [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) to calculate the differences between strings.\n",
    "### Using GroupBy to Handle Duplicates\n",
    "\n",
    "\n",
    "\n",
    "> In certain scenarios involving fuzzy duplicates, simply dropping the duplicates might not be sufficient. We may want to average the results of certain columns of interest to avoid biasing the data. This can be achieved using the `groupby()` method. It allows us to group data by certain criteria and then apply aggregate functions like `mean()`, `max()`, or `first()`.\n",
    "\n",
    "\n",
    "#### Example: Aggregating Customer Reviews\n",
    "\n",
    "Imagine a dataset of customer reviews where the same customer might have submitted multiple reviews for the same product, possibly with slight variations in their contact details. Our goal is to consolidate these reviews to maintain one entry per customer per product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ReviewScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <th>101</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <th>102</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C03</th>\n",
       "      <th>103</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ReviewScore\n",
       "CustomerID ProductID             \n",
       "C01        101                4.5\n",
       "C02        102                3.0\n",
       "C03        103                4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sample review data\n",
    "data = {\n",
    "    'CustomerID': ['C01', 'C01', 'C02', 'C02', 'C03'],\n",
    "    'ProductID': [101, 101, 102, 102, 103],\n",
    "    'ReviewScore': [4, 5, 3, 3, 4],\n",
    "    'CustomerEmail': ['customer1@email.com', 'customer1@domain.com', 'customer2@email.com', 'customer2@domain.com', 'customer3@email.com']\n",
    "}\n",
    "reviews_df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by CustomerID and ProductID, then taking the highest review score\n",
    "aggregated_reviews = reviews_df.groupby(['CustomerID', 'ProductID']).agg({'ReviewScore': 'mean'})\n",
    "\n",
    "aggregated_reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "In this code block, we've grouped the reviews by both `CustomerID` and `ProductID`. We then used the `agg()` function to keep only the highest review score for each customer-product pair. This approach ensures that we have a unique, representative review score for each product from each customer, reducing redundancy while preserving crucial information.\n",
    "\n",
    "\n",
    "### Understanding the `agg` Function\n",
    "\n",
    ">The `agg` function is a tool for performing aggregate operations on data. It stands for 'aggregate' and is used to apply one or more operations over the specified axis. This function is particularly useful in scenarios involving `groupby` operations. It allows you to apply a function or a list of function names to be executed along one axis of the `DataFrame` (by default the `0` or row axis).\n",
    "\n",
    "\n",
    "\n",
    "When used with a single function, `agg` applies that function to all columns. Here we use it with the keyword argument `'sum'` , to apply the `sum` method to all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "   A  B\n",
      "0  1  2\n",
      "1  3  4\n",
      "\n",
      "Result of using the `agg` function with `sum`:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A    4\n",
       "B    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=[\"A\", \"B\"])\n",
    "\n",
    "print(\"Original dataframe:\")\n",
    "print(df)\n",
    "# Applying a single aggregate function\n",
    "result = df.agg('sum')\n",
    "print(\"\\nResult of using the `agg` function with `sum`:\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data\n",
    "\n",
    "> Categorical columns are those in which the values are drawn from a predefined set of categories. Examples include the possible colour schemes of a product like a laptop, the country of residence of a customer, or the manufacturer of a car.  We will learn more about the different types of categories elsewhere in this course. \n",
    "\n",
    "The primary aim in cleaning categorical data is to modify the column so that each real world entity has only one corresponding unique value in the column. If you know something about the data the column is describing, you can get an idea of whether the column needs to be cleaned to meet this requirement.\n",
    "\n",
    "For example, when dealing with countries, there should be somewhere in the region of 193 to 237 possible entries, depending on the definition of the word \"country\" that is being used. It is possible for the same country to go by multiple names in your column, in which case it would be helpful to regularise the names such that each country is represented by only a single value in the column. \n",
    "\n",
    "Look at the `DataFrame` below. The column `postal region` contains the country names `UK`, `England`, `Wales`, `Cymru` and `Scotland`, among others. For the purposes of the cost of sending mail, these are all one region, the `United Kingdom`. It would therefore be preferable to set them all to the same value. As with missing values, we can fix this representation with the `.replace()` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "  Customer Name Postal Region\n",
      "0         Amina            UK\n",
      "1         Bahru       England\n",
      "2       Charlie         Wales\n",
      "3          Dion         Cymru\n",
      "4           Ebo      Scotland\n",
      "5         Frank           USA\n",
      "6         Giana        Canada\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample dataframe\n",
    "data = {\n",
    "    'Customer Name': ['Amina', 'Bahru', 'Charlie', 'Dion', 'Ebo', 'Frank', 'Giana'],\n",
    "    'Postal Region': ['UK', 'England', 'Wales', 'Cymru', 'Scotland', 'USA', 'Canada']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the original dataframe\n",
    "print(\"Original dataframe:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame After Cleaning 'Postal Country' Column:\n",
      "  Customer Name   Postal Region\n",
      "0         Amina  United Kingdom\n",
      "1         Bahru  United Kingdom\n",
      "2       Charlie  United Kingdom\n",
      "3          Dion  United Kingdom\n",
      "4           Ebo  United Kingdom\n",
      "5         Frank             USA\n",
      "6         Giana          Canada\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping dictionary to unify the country names\n",
    "country_mapping = {\n",
    "    'UK': 'United Kingdom',\n",
    "    'England': 'United Kingdom',\n",
    "    'Wales': 'United Kingdom',\n",
    "    'Cymru': 'United Kingdom',\n",
    "    'Scotland': 'United Kingdom'\n",
    "}\n",
    "\n",
    "# Replacing the country names in the 'Postal Country' column\n",
    "df['Postal Region'] = df['Postal Region'].replace(country_mapping)\n",
    "\n",
    "# Displaying the DataFrame after cleaning the 'Postal Country' column\n",
    "print(\"\\nDataFrame After Cleaning 'Postal Country' Column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Categorical Columns from Continuous Data\n",
    "\n",
    "Continuous variables are those which can take any value on a spectrum. For example the price of an item can potentially take any value greater than zero, usually with a granularity of 1 penny. You might meet instances in your dataset where you might want to generate new categories based on continuous data.  This can be achieved through a process called *binning*, which means dividing the spectrum of possible values into regions, known as **bins**. \n",
    "\n",
    "As an example, consider a `DataFrame` of flight routes, together with their distances in miles. An airline might want to divide them into `short haul`, `medium haul` and `long haul` based on threshold values. To achieve this, we can use the `cut()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "     Route  Distance\n",
      "0  NYC-LON      3461\n",
      "1  LON-PAR       214\n",
      "2  NYC-TOK      6749\n",
      "3  LON-SYD     10562\n",
      "4  PAR-BER       546\n",
      "\n",
      "dataframe with 'Flight Type' Column:\n",
      "     Route  Distance  Flight Type\n",
      "0  NYC-LON      3461  medium haul\n",
      "1  LON-PAR       214   short haul\n",
      "2  NYC-TOK      6749    long haul\n",
      "3  LON-SYD     10562    long haul\n",
      "4  PAR-BER       546   short haul\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a sample dataframe\n",
    "data = {\n",
    "    'Route': ['NYC-LON', 'LON-PAR', 'NYC-TOK', 'LON-SYD', 'PAR-BER'],\n",
    "    'Distance': [3461, 214, 6749, 10562, 546]\n",
    "}\n",
    "flights = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the original dataframe\n",
    "print(\"Original dataframe:\")\n",
    "print(flights)\n",
    "\n",
    "# Defining the bin edges and labels\n",
    "bin_edges = [0, 1500, 4000, 12000]  # in miles\n",
    "bin_labels = ['short haul', 'medium haul', 'long haul']\n",
    "\n",
    "# Creating a new categorical column 'Flight Type' by binning the 'Distance' column\n",
    "flights['Flight Type'] = pd.cut(flights['Distance'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "\n",
    "# Displaying the dataframe with the new 'Flight Type' column\n",
    "print(\"\\ndataframe with 'Flight Type' Column:\")\n",
    "print(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example example:\n",
    "- We create a `DataFrame` `flights` with columns `Route` and `Distance`, containing various flight routes and their distances in miles\n",
    "- We define the bin edges `bin_edges` and labels `bin_labels` to specify the ranges and labels for our new categorical data. Note that there is one more element in the `bin edges` list than the number of bins we need. The bin edges define the lower and upper bounds of each bin. So a short haul flight will be from `0` to `1500` miles in this case.\n",
    "- We use `pd.cut()` to create a new column `Flight Type` by binning the `Distance` column based on the defined bins and labels. The argument `right = False` is used to specify that the bins are *left-closed*, meaning that the left bin edge is included in the bin, but the right bin edge is not.\n",
    "- Finally, we display the original and modified `DataFrames` to observe the changes\n",
    "\n",
    "This approach allows you to categorise continuous data into discrete bins, simplifying analysis and enabling you to gain insights into the distribution and frequency of the data across different categories. This is particularly useful when you want to analyze or visualise your data at a higher or more generalised level than the raw, continuous data allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Use Pandas' `.str.strip()` method to remove whitespace from the start and end of strings in a dataset\n",
    "- Standardise case of categorical variables in Pandas using `.str.lower()` or `.str.upper()` methods\n",
    "- Use the `replace()` function in Pandas to correct incorrect values in a column\n",
    "- Use the `.replace()` method in Pandas to standardise values in a column, and `.astype('bool')` to convert the column to Boolean type\n",
    "- Regular expressions (regex) can be used in data cleaning to match and replace values in a column that don't adhere to a specific pattern\n",
    "- Use the `.replace()` method in Pandas to clean and regularise numeric data, including removing or replacing non-numeric characters\n",
    "- Use `unique` to get distinct values and `nunique` to count unique values in a Pandas series\n",
    "- In Pandas, use `.duplicated()` to find and `drop_duplicates()` to remove exact duplicates; handling fuzzy duplicates requires careful consideration of data context\n",
    "- Use Pandas' `groupby()` and `agg()` functions to consolidate fuzzy duplicates and reduce bias in data\n",
    "- The `agg` function in Pandas performs aggregate operations, often used with `groupby` on a specified axis of a `DataFrame`\n",
    "- Use the `.replace()` method to standardise categorical data, ensuring each category is represented by a single unique value\n",
    "- Binning in Pandas allows categorisation of continuous data into discrete bins using the `cut()` method, simplifying analysis and visualisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
