{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Once you have imported your data into a `DataFrame`, a common first step is to check the data type (`dtype`) of each column, and adjust any that aren't optimal for your analysis. Each Pandas data type supports different types of analysis, so selecting the correct option is an important step in the data preparation pipeline.\n",
    "\n",
    "\n",
    "Below is a table that shows various Pandas data types, their corresponding Python data types, and a brief description of each.\n",
    "\n",
    "| Pandas Dtype | Python Dtype        | Description                                           |\n",
    "|--------------|---------------------|-------------------------------------------------------|\n",
    "| object       | str                 | Used for text or mixed types of data                  |\n",
    "| int64        | int                 | Integer numbers                                       |\n",
    "| float64      | float               | Floating-point numbers                                |\n",
    "| bool         | bool                | Boolean values (True/False)                           |\n",
    "| datetime64   | datetime.datetime   | Date and time values                                  |\n",
    "| timedelta64  | datetime.timedelta  | Differences between two datetimes                     |\n",
    "| category     | (special type)      | Finite list of text values                            |\n",
    "| period       | pd.Period           | Periods of time, useful for time-series data          |\n",
    "| sparse       | (special type)      | Sparse array to contain mostly NaN values             |\n",
    "| string       | str                 | Text                                                  |\n",
    "\n",
    "Note that:\n",
    "\n",
    "- The `int64` and `float64` data types indicate 64-bit storage for integer and floating-point numbers, respectively. Pandas also supports other sizes (like `int32` and `float32`) to save memory when the larger sizes are not necessary. An `int` type column cannot contain `NaN` values.\n",
    "- The `category` data type is not a native Python data type but is provided by Pandas to optimise memory usage and performance for data with a small number of distinct values\n",
    "- The `sparse` data type is used for data that is mostly composed of `NaN` or missing values. To save memory, it only stores the non-missing values in the column.\n",
    "- The `period` data type is specific to Pandas and represents spans of time (like a month or a year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and Assigning Data Types\n",
    "\n",
    "When you import your raw data, Pandas will attempt to automatically assign a data type to each column, but it doesn't always make the best choice.\n",
    "\n",
    "Let's import some example data to a `DataFrame` and take a look at how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a simple DataFrame of names and ages\n",
    "data = {'Name': ['Alice', 'Bashar', 'Carlos', 'Diana', \"Ephraim\", \"Frank\", \"Gina\"],\n",
    "        'Age': [21, 22, 'n/a', 24, 25, 'missing', 27]}\n",
    "age_df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Data Type\n",
    "\n",
    "The data types of your columns can be accessed via the `.dtypes` attribute, or by calling the `.info()` method. \n",
    "\n",
    "- The `.dtypes` attribute only returns the data type of each column\n",
    "- The `.info()` method returns both the data type and some additional information: the number of rows and the memory usage of the `DataFrame`, as well as the number of non-null values in each column. We will deal with handling `NULL` values in another lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    object\n",
       "Age     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    7 non-null      object\n",
      " 1   Age     7 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output of `info()`, both columns have defaulted to the `object` data type. In this case, this is not quite what we want. The `Name` column should be of `string` type, as this uses less memory than `object`, and the `Age` column should be of a numeric type so that we can do numeric calculations on it.\n",
    "\n",
    "### Assigning Data Types\n",
    "\n",
    "\n",
    "The `.astype()` method can be used to manually assign a data type to a column. We can easily change the `Name` column to the `string` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    7 non-null      string\n",
      " 1   Age     7 non-null      object\n",
      "dtypes: object(1), string(1)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.Name = age_df.Name.astype('string')\n",
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to cast the `Age` column as `int64` though, the method throws a `ValueError`, because it encountered some values (`missing` and `n/a`) that it could not cast as an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'n/a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/timhowe/Documents/CODE/000_content/Content-Projects/Content/units/Data-Handling/2. Data Manipulation with Pandas/2. Pandas Data Types/Notebook.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/timhowe/Documents/CODE/000_content/Content-Projects/Content/units/Data-Handling/2.%20Data%20Manipulation%20with%20Pandas/2.%20Pandas%20Data%20Types/Notebook.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m age_df\u001b[39m.\u001b[39mAge \u001b[39m=\u001b[39m age_df\u001b[39m.\u001b[39mAge\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n",
      "\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n",
      "\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n",
      "\u001b[1;32m   6236\u001b[0m     ]\n",
      "\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n",
      "\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mastype(dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n",
      "\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n",
      "\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n",
      "\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n",
      "\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n",
      "\u001b[1;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n",
      "\u001b[1;32m    510\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n",
      "\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n",
      "\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n",
      "\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n",
      "\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n",
      "\u001b[1;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n",
      "\u001b[1;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n",
      "\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n",
      "\u001b[1;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n",
      "\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/content_repo/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n",
      "\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n",
      "\u001b[1;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n",
      "\u001b[0;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'n/a'"
     ]
    }
   ],
   "source": [
    "age_df.Age = age_df.Age.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle this error, we will need to use an alternative approach, the `pd.to_numeric()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `pd.to_numeric()` Function\n",
    "\n",
    "By default, the `astype()` method throws an error when it encounters a non-convertible value, as this prevents accidental data loss. We can override this behaviour by setting the `errors` flag to `ignore` rather than `raise`, but this would still not convert the datatype to a numeric value. The non-numeric values would still keep the column as an `object` data type.\n",
    "\n",
    "In this scenario, we are happy to lose the information in the non-numeric values, for the sake of being able to treat the column as integers. To do this, we can use a separate function, `pd.to_numeric()`, which we can use with the `errors` parameter set to `coerce` to force the conversion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    7 non-null      object \n",
      " 1   Age     5 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "age_df.Age = pd.to_numeric(age_df.Age, errors='coerce')\n",
    "age_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values which could not be converted to numeric have now been converted to `NaN` (Not a Number) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bashar</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ephraim</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age\n",
       "0    Alice  21.0\n",
       "1   Bashar  22.0\n",
       "2   Carlos   NaN\n",
       "3    Diana  24.0\n",
       "4  Ephraim  25.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that it is not possible to convert a numeric column to `int` type until you have handled the `NaN` values. This is because `NaN` is technically a floating point value. We will learn more about handling missing values like `NaN` in another lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data Types\n",
    "### The `datetime64` Data Type\n",
    "\n",
    "\n",
    ">The `datetime64` data type provides a memory-efficient structure for working with date and time data, allowing for operations like time-based indexing, slicing, and resampling to be performed. This data type is necessary for effective time-series data analysis, as it allows complex temporal computations and aggregations to be performed with relative ease.\n",
    "\n",
    "Date-time columns can be challenging to assign correctly, because there is a very large range of ways that date and time columns can be formatted, and there is no guarantee that each column will only use one of these formats, so it is important to determine which formats are used in your data before attempting to convert a column to `datetime64`.\n",
    "### Casting a Column to Datetime\n",
    "\n",
    "The `pd.to_datetime` function can be used to cast a column to `datetime64`. In order to ensure that the conversion is accurate, it is necessary to consider the format that the date/time values are in.\n",
    "\n",
    "Run the three code blocks below to perform a simple example conversion, and confirm that the `datetime64`-encoded dates are correct. In this case, the data are initially formatted as strings, and the date format is unambiguous, and so the conversion works without any additional work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date_strings  4 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 164.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'date_strings': ['2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01']\n",
    "}\n",
    "date_df = pd.DataFrame(data)\n",
    "\n",
    "date_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date_strings  4 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 164.0 bytes\n"
     ]
    }
   ],
   "source": [
    "date_df.date_strings = pd.to_datetime(date_df.date_strings)\n",
    "date_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_strings\n",
       "0   2023-01-01\n",
       "1   2023-02-01\n",
       "2   2023-03-01\n",
       "3   2023-04-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Common Issues: *Epoch* Time\n",
    "\n",
    "Date and time are typically represented in computers using a system known as *epoch time* or *Unix time*, which counts the number of seconds that have elapsed since a predefined point in time, known as the *epoch*. The **epoch** is set at `00:00:00 UTC on Thursday, January 1, 1970` and the count of seconds (or milliseconds in some applications) from this point is used to represent subsequent points in time, allowing for a standardised, system-independent representation of time that can be easily computed and converted into various human-readable formats.\n",
    "\n",
    "This convention is the source of common issue encountered when converting columns to datetime. For an example, let's load in this `DataFrame` of flight times, `flights_df`, and look at the `FLIGHTDATE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20110511\n",
       "1    20160520\n",
       "2    20040922\n",
       "3    20160527\n",
       "4    19970511\n",
       "Name: FLIGHTDATE, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # You can use this setting display all the columns in your `DataFrame`\n",
    "flights_df = pd.read_csv(\"https://cdn.theaicore.com/content/lessons/3d1ad53c-8b55-41f0-8772-08c39b437cfb/flights_sample.csv\") \n",
    "\n",
    "flights_df['FLIGHTDATE'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pandas has detected the data type of the  `FLIGHTDATE` column as `int64`, whereas it would be more helpful to have it as `datetime64`, so that it can be used in time-series analysis.\n",
    "\n",
    "Run the two code block below, to see what happens when we try using the function on the `FLIGHTDATE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1970-01-01 00:00:00.020110511\n",
       "1   1970-01-01 00:00:00.020160520\n",
       "2   1970-01-01 00:00:00.020040922\n",
       "3   1970-01-01 00:00:00.020160527\n",
       "4   1970-01-01 00:00:00.019970511\n",
       "Name: FLIGHTDATE, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.to_datetime(flights_df['FLIGHTDATE']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the first few values of the column are in January, 1970. This should arouse suspicion, given what we know about **Epoch time**. We can see from the head of the original column that the first 5 values should be between 1997 and 2016, not in 1970. The function has interpreted the integer values in `FLIGHTDATE` as a number of seconds after the **Epoch**, when actually it should be a date in the format`YYYmmdd`.\n",
    "\n",
    "To work around this, we can specify a format as an argument to the `to_datetime` function, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-05-11\n",
       "1        2016-05-20\n",
       "2        2004-09-22\n",
       "3        2016-05-27\n",
       "4        1997-05-11\n",
       "            ...    \n",
       "119175   2016-05-18\n",
       "119176   2014-09-25\n",
       "119177   2016-01-13\n",
       "119178   1997-01-04\n",
       "119179   2012-09-07\n",
       "Name: FLIGHTDATE, Length: 119180, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Assign date_format\n",
    "date_format = \"%Y%m%d\"\n",
    "pd.to_datetime(flights_df[\"FLIGHTDATE\"], format=date_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Issues: Mixed Date Formats\n",
    "\n",
    "Handling multiple date formats in a single column can be a bit tricky, but `pd.to_datetime` is quite flexible and can infer different formats automatically in most cases. Below is a simple example of a column called `mixed_dates`, which has dates in multiple formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "   mixed_dates\n",
      "0   01/02/2023\n",
      "1   2023-03-01\n",
      "2  04-Apr-2023\n",
      "3     20230505\n",
      "\n",
      "Data types:\n",
      "mixed_dates    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame with multiple date formats\n",
    "data = {\n",
    "    'mixed_dates': ['01/02/2023', '2023-03-01', '04-Apr-2023', '20230505']\n",
    "}\n",
    "mixed_date_df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the original DataFrame\n",
    "print(\"Original Dataframe:\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "   mixed_dates      dates\n",
      "0   01/02/2023 2023-01-02\n",
      "1   2023-03-01        NaT\n",
      "2  04-Apr-2023        NaT\n",
      "3     20230505        NaT\n",
      "\n",
      "Data types:\n",
      "mixed_dates            object\n",
      "dates          datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting the 'mixed_dates' column to datetime\n",
    "# Note: infer_datetime_format=True can help to infer different formats, but might not handle all cases\n",
    "mixed_date_df['dates'] = pd.to_datetime(mixed_date_df['mixed_dates'], infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "# Displaying the modified DataFrame\n",
    "print(\"\\nModified DataFrame:\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately in this case, automatic conversion has not been very effective, and we can see multiple values have been returned as `NaT` (Not a Time).\n",
    "\n",
    "A more effective approach is to use the `parse` function from the `dateutil` library, in conjunction with the `.apply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "\n",
      "   mixed_dates      dates\n",
      "0   01/02/2023 2023-01-02\n",
      "1   2023-03-01 2023-03-01\n",
      "2  04-Apr-2023 2023-04-04\n",
      "3     20230505 2023-05-05\n",
      "\n",
      "Data types:\n",
      "\n",
      "mixed_dates            object\n",
      "dates          datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "mixed_date_df['dates'] = mixed_date_df['mixed_dates'].apply(parse)\n",
    "mixed_date_df['dates'] = pd.to_datetime(mixed_date_df['dates'], infer_datetime_format=True, errors='coerce')\n",
    "print(\"\\nModified DataFrame:\\n\")\n",
    "print(mixed_date_df)\n",
    "print(\"\\nData types:\\n\")\n",
    "print(mixed_date_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `timedelta64` Data Type\n",
    "The `timedelta64` data type is used to represent differences in `datetime64` objects. While a `datetime64` object represents a specific point in time, with a defined year, month, day, hour, minute, and so on, a `timedelta64` object represents a duration that is not anchored to a specific start or end point. It tells you how much time is between two points, without specifying what those points are.\n",
    "\n",
    "The distinction between `timedelta64` and `datetime64` data types in Pandas (and similarly, `timedelta` and `datetime` in Python's `datetime` module) is crucial due to the inherent differences in representing and utilising points in time versus durations of time, which are fundamentally different concepts.\n",
    "\n",
    "**Arithmetic Operations:**\n",
    "   - When you perform arithmetic with two `datetime64` objects, the result is a `timedelta64` object because subtracting one point in time from another gives you a duration\n",
    "   - Conversely, when you add or subtract a `timedelta64` from a `datetime64` object, you get another `datetime64` object because you're shifting a point in time by a certain duration\n",
    "\n",
    "By having separate data types, Pandas (and Python more broadly) allows for clear, intuitive operations on time data, ensuring that the operations are semantically meaningful and that the results are what users expect when performing arithmetic or comparisons with time-related data. This distinction also helps prevent misinterpretation of the data and ensures that operations are performed with the appropriate level of precision and efficiency for each type of data.\n",
    "\n",
    "For example, the code block below creates a new `timedelta64` column by subtracting a specific timestamp from the `dates` column of the `mixed_dates_df` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified dataframe:\n",
      "   mixed_dates      dates date_difference\n",
      "0   01/02/2023 2023-01-02          1 days\n",
      "1   2023-03-01 2023-03-01         59 days\n",
      "2  04-Apr-2023 2023-04-04         93 days\n",
      "3     20230505 2023-05-05        124 days\n"
     ]
    }
   ],
   "source": [
    "# Subtracting a single date from the 'dates' column\n",
    "single_date = pd.Timestamp('2023-01-01')  # Creating a Timestamp object\n",
    "mixed_date_df['date_difference'] = mixed_date_df['dates'] - single_date  # Subtracting the single date\n",
    "\n",
    "# Displaying the modified DataFrame\n",
    "print(\"\\nModified DataFrame:\")\n",
    "print(mixed_date_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "\n",
    "- Checking and adjusting data types in a Pandas `DataFrame` is crucial for optimal analysis, as each data type supports different types of analysis\n",
    "- Pandas attempts to automatically assign data types to columns when importing raw data, but may not always choose optimally\n",
    "- Use `.dtypes` to see column data types and `.info()` for data types plus additional `DataFrame` details\n",
    "- The `.astype()` method in Pandas allows for manual data type assignment to a column\n",
    "- Attempting to cast non-numeric values to integers in Pandas will result in a `ValueError`\n",
    "- Use `pd.to_numeric()` with `errors='coerce'` to force convert non-numeric values to numeric, turning them into `NaN`s\n",
    "- Non-numeric values in a Pandas `DataFrame` are converted to `NaN` and must be handled before converting a column to `int` type\n",
    "- The `datetime64` data type allows efficient handling of date and time data, enabling time-based operations and facilitating time-series analysis.\n",
    "- Use `pd.to_datetime` to convert a column to `datetime64`, considering the date/time format for accuracy\n",
    "- The `to_datetime` function can convert various date formats to `datetime64`, but may need specific format or parsing help for complex cases\n",
    "- `timedelta64` represents durations, while `datetime64` represents specific points in time\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
