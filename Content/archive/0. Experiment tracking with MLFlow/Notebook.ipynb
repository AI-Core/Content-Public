{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow\n",
    "\n",
    "## Introduction\n",
    "> __MLflow is an open-source platform for managing the end-to-end ML lifecycle.__\n",
    "\n",
    "Its offerings for managing ML experiments and deployment include the following:\n",
    "\n",
    "- ML-code packaging for reproducibility/sharing (dependencies, models, etc.).\n",
    "- Experiment tracking (compare results between runs).\n",
    "- Model deployment to various inference platforms.\n",
    "- A central store for MLFlow models (model versioning, stage transitions and annotations).\n",
    "\n",
    "> __MLFlow integrates with popular frameworks, such as `sklearn`, `pytorch` and `spark`.__\n",
    "\n",
    "> __It also provides APIs not only for `python`, but also for `R` and `java`__, as well as REST APIs/CLIs for other languages.\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Here, we will focus on Python and shell usage."
=======
    "We will focus on Python and shell usage, but keep the above in mind"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation \n",
    "\n",
    "`MLFlow` is written in Python; thus, it can be installed using `pip`/`conda` or any other package manager.\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "If you have `pytorch` or any other integration installed, it will be picked up automatically by `mlflow`."
=======
    "If you have `pytorch` or other integration installed, it will be picked up automatically by `mlflow` (no need for extras this time)."
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (1.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (5.4.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: pytz in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (2021.1)\n",
      "Requirement already satisfied: sqlalchemy in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.4.15)\n",
      "Requirement already satisfied: alembic<=1.4.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.4.1)\n",
      "Requirement already satisfied: entrypoints in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: pandas in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (0.14.3)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (3.14.0)\n",
      "Requirement already satisfied: requests>=2.17.3 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (2.25.1)\n",
      "Requirement already satisfied: querystring-parser in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: Flask in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (20.9)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (0.4.1)\n",
      "Requirement already satisfied: gunicorn in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: docker>=4.0.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (5.0.0)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (3.1.18)\n",
      "Requirement already satisfied: numpy in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (1.20.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from mlflow) (0.18.2)\n",
      "Requirement already satisfied: Mako in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (1.1.4)\n",
      "Requirement already satisfied: python-dateutil in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from docker>=4.0.0->mlflow) (1.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from sqlalchemy->mlflow) (1.1.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from Flask->mlflow) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from Flask->mlflow) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from gunicorn->mlflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: prometheus-client in /Users/ice/miniconda3/envs/main/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects\n",
    "\n",
    "> __MLFlow projects refer to the CONVENTION (or standard) for organising and describing code to enable others (people, automation pipelines) easily run it.__\n",
    "\n",
    "Conventionally, projects are `git` repositories that allow you to specify, in varying levels of detail, the required environment (either `conda` or `docker`; note that `system`-specified environments are discouraged) via the\n",
    "- directory structure.\n",
    "- `MLproject` file in git's root directory.\n",
    "\n",
    "*Note*\n",
    "- `MLproject` should be a `yaml` file, without an extension (i.e. save it as `MLroject`, not `MLroject.yaml`).\n",
    "\n",
    "### Directories\n",
    "\n",
    "> Structuring code via directories is sufficient for creating a basic `MLFlow` project; however, __specifying `MLproject` is a better option.__\n",
    "\n",
    "If there is no `MLproject.yaml` file, note the following:\n",
    "- __Name of the project__: name of the project's root directory (e.g. git's root).\n",
    "- __Conda environment__: apply it if `conda.yaml` is available in the root.\n",
    "- __Any `.py`/`.sh` file in the project can be an entry point__ (the topic of running projects will be discussed in more detail later).\n",
    "\n",
    "One can obtain the `conda.yaml` file via a simple command, provided the command is run from within the conda environment:\n",
    "\n",
    "```bash\n",
    "conda env export [--from-history] > conda.yaml\n",
    "```\n",
    "\n",
    "`--from-history` requests only packages that have been explicitly installed. This has two effects:\n",
    "- Portability across OSs (as OS-specific packages will be installed this way).\n",
    "- Partial reproducibility (possibly due to the different dependencies).\n",
    "\n",
    "__Generally, it is safe to use the `--from-history` flag to improve the portability of projects.__\n",
    "\n",
    "### Using MLProject.yaml\n",
    "\n",
    "> As a better alternative, the entry points, structure, parameters, etc. can be explicitly specified via the `MLproject` file.\n",
    "\n",
    "Consider the example `MLproject` below:\n",
    "\n",
    "\n",
    "```yml\n",
    "---\n",
    "name: My Project\n",
    "\n",
    "conda_env: my_env.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      data_file: path\n",
    "      regularization: {type: float, default: 0.1}\n",
    "    command: \"python train.py -r {regularization} {data_file}\"\n",
    "  validate:\n",
    "    parameters:\n",
    "      data_file: path\n",
    "    command: \"python validate.py {data_file}\"\n",
    "```\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "For more examples, check out the documentation [here](https://github.com/mlflow/mlflow/tree/master/examples)."
=======
    "Check out some examples in the documentation [here](https://github.com/mlflow/mlflow/tree/master/examples)"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code, it is clear that the user can do the following:\n",
    "\n",
    "1. __specify the environment explicitly:__\n",
    "    - `conda` (simply a file with dependencies).\n",
    "    - `docker`:\n",
    "        - specify the image available on the OS\n",
    "        - if the image is unavailable, attempt to pull it from `DockerHub`.\n",
    "        - if the registry containing the image is specified, it will attempt to pull it, unless it is already available on the system.\n",
    "\n",
    "\n",
    "For the `docker` environment, one can also specify the\n",
    "- volumes to be mounted while the project runs.\n",
    "- environment variables passed to the container.\n",
    "\n",
    "Here is an example of `docker_env`:\n",
    "\n",
    "```yml\n",
    "---\n",
    "name: My Project\n",
    "\n",
    "docker_env:\n",
    "  image:  mlflow-docker-example\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      data_file: path\n",
    "      regularization: {type: float, default: 0.1}\n",
    "      p: float\n",
    "    command: \"python train.py -r {regularization} {data_file}\"\n",
    "  validate:\n",
    "    parameters:\n",
    "      data_file: path\n",
    "    command: \"python validate.py {data_file}\"\n",
    "```\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "More examples are provided [here](https://www.mlflow.org/docs/latest/projects.html#mlproject-file)."
=======
    "[See more here](https://www.mlflow.org/docs/latest/projects.html#mlproject-file)"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Specify parameters and entrypoints__\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "One can specify the\n",
    "- name of the parameter.\n",
    "- type of the parameter (the default is `str`; others are `float`, `path` and `uri`).\n",
    "- default value(s)."
=======
    "One can specify:\n",
    "- name of the parameter\n",
    "- type of the parameter (default is `str`, others are `float`, `path`, `uri`)\n",
    "- default value(s)"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are eventually passed to the `command` field and appropriately substituted.\n",
    "__For unspecified parameters, the values will be passed to the running command via the `--key value` syntax.__\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Two cells above all of the parameter specifications are shown."
=======
    "Those values are latter passed on to `command` field and appropriately substituted.\n",
    "__If we don't specify some parameter, it will be passed to the running command via `--key value` syntax__\n",
    "\n",
    "Two cells above all of the parameter specification are shown."
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running projects\n",
    "\n",
    "> `MLFLow` provides a terminal command, `mlflow`, which has a subcommand, `run`, that allows us to run the project.\n",
    "\n",
    "\n",
    "The syntax is quite simple:\n",
    "\n",
    "```bash\n",
    "mlflow run <directory>\n",
    "```\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "However, there are a few workarounds for running it effortlessly:"
=======
    "but there are a few useful tricks which allow us to run it with even less effort:"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T17:57:19.638058Z",
     "start_time": "2021-04-25T17:57:18.637616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow run [OPTIONS] URI\n",
      "\n",
      "  Run an MLflow project from the given URI.\n",
      "\n",
      "  For local runs, the run will block until it completes. Otherwise, the\n",
      "  project will run asynchronously.\n",
      "\n",
      "  If running locally (the default), the URI can be either a Git repository\n",
      "  URI or a local path. If running on Databricks, the URI must be a Git\n",
      "  repository.\n",
      "\n",
      "  By default, Git projects run in a new working directory with the given\n",
      "  parameters, while local projects run from the project's root directory.\n",
      "\n",
      "Options:\n",
      "  -e, --entry-point NAME        Entry point within project. [default: main].\n",
      "                                If the entry point is not found, attempts to\n",
      "                                run the project file with the specified name\n",
      "                                as a script, using 'python' to run .py files\n",
      "                                and the default shell (specified by\n",
      "                                environment variable $SHELL) to run .sh files\n",
      "\n",
      "  -v, --version VERSION         Version of the project to run, as a Git commit\n",
      "                                reference for Git projects.\n",
      "\n",
      "  -P, --param-list NAME=VALUE   A parameter for the run, of the form -P\n",
      "                                name=value. Provided parameters that are not\n",
      "                                in the list of parameters for an entry point\n",
      "                                will be passed to the corresponding entry\n",
      "                                point as command-line arguments in the form\n",
      "                                `--name value`\n",
      "\n",
      "  -A, --docker-args NAME=VALUE  A `docker run` argument or flag, of the form\n",
      "                                -A name=value (e.g. -A gpus=all) or -A name\n",
      "                                (e.g. -A t). The argument will then be passed\n",
      "                                as `docker run --name value` or `docker run\n",
      "                                --name` respectively.\n",
      "\n",
      "  --experiment-name TEXT        Name of the experiment under which to launch\n",
      "                                the run. If not specified, 'experiment-id'\n",
      "                                option will be used to launch run.\n",
      "\n",
      "  --experiment-id TEXT          ID of the experiment under which to launch the\n",
      "                                run.\n",
      "\n",
      "  -b, --backend BACKEND         Execution backend to use for run. Supported\n",
      "                                values: 'local', 'databricks', kubernetes\n",
      "                                (experimental). Defaults to 'local'. If\n",
      "                                running against Databricks, will run against a\n",
      "                                Databricks workspace determined as follows: if\n",
      "                                a Databricks tracking URI of the form\n",
      "                                'databricks://profile' has been set (e.g. by\n",
      "                                setting the MLFLOW_TRACKING_URI environment\n",
      "                                variable), will run against the workspace\n",
      "                                specified by <profile>. Otherwise, runs\n",
      "                                against the workspace specified by the default\n",
      "                                Databricks CLI profile. See\n",
      "                                https://github.com/databricks/databricks-cli\n",
      "                                for more info on configuring a Databricks CLI\n",
      "                                profile.\n",
      "\n",
      "  -c, --backend-config FILE     Path to JSON file (must end in '.json') or\n",
      "                                JSON string which will be passed as config to\n",
      "                                the backend. The exact content which should be\n",
      "                                provided is different for each execution\n",
      "                                backend and is documented at https://www.mlflo\n",
      "                                w.org/docs/latest/projects.html.\n",
      "\n",
      "  --no-conda                    If specified, will assume that\n",
      "                                MLmodel/MLproject is running within a Conda\n",
      "                                environment with the necessary dependencies\n",
      "                                for the current project instead of attempting\n",
      "                                to create a new conda environment.\n",
      "\n",
      "  --storage-dir TEXT            Only valid when ``backend`` is local. MLflow\n",
      "                                downloads artifacts from distributed URIs\n",
      "                                passed to parameters of type 'path' to\n",
      "                                subdirectories of storage_dir.\n",
      "\n",
      "  --run-id RUN_ID               If specified, the given run ID will be used\n",
      "                                instead of creating a new run. Note: this\n",
      "                                argument is used internally by the MLflow\n",
      "                                project APIs and should not be specified.\n",
      "\n",
      "  --help                        Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!mlflow run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T18:00:54.960912Z",
     "start_time": "2021-04-25T18:00:54.951128Z"
    }
   },
   "source": [
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "For example, we could run the following in the CLI or cell:"
=======
    "For example we could do this (run in your CLI or in your cell):"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T18:04:18.415562Z",
     "start_time": "2021-04-25T18:02:19.993642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/07/04 18:41:53 INFO mlflow.projects.utils: === Fetching project from https://github.com/mlflow/mlflow-example into /var/folders/3z/29w5rr9d0k3_p863hm40sdnc0000gn/T/tmpyo68dla4 ===\n",
      "2021/07/04 18:41:54 INFO mlflow.projects.utils: === Created directory /var/folders/3z/29w5rr9d0k3_p863hm40sdnc0000gn/T/tmp0f1l27x8 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2021/07/04 18:41:54 INFO mlflow.projects.backend.local: === Running command 'source /Users/ice/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b 1>&2 && python train.py 0.5 0.1' in run with ID '3fedea0d61ba42ecafd5ed87791d507c' === \n",
      "/Users/ice/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "/Users/ice/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/ice/miniconda3/envs/mlflow-1abc00771765dd9dd15731cbda4938c765fbb90b/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n",
      "Elasticnet model (alpha=0.500000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7947931019036529\n",
      "  MAE: 0.6189130834228138\n",
      "  R2: 0.18411668718221819\n",
      "2021/07/04 18:41:56 INFO mlflow.projects: === Run (ID '3fedea0d61ba42ecafd5ed87791d507c') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run https://github.com/mlflow/mlflow-example -P alpha=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking\n",
    "\n",
    "> __MLFlow offers an experiment-tracking component in the form of an API and a UI. This component enables the logging and visualisation of experimental data.__\n",
    "\n",
    "### Benefits\n",
    "With this component, it is possible to log the following:\n",
    "- model parameters\n",
    "- code versions (git commit hashes)\n",
    "- metrics\n",
    "- generated artifacts\n",
    "\n",
    "__`MLFlow` tracking is organised around runs, which are simply an approach for executing programs__.\n",
    "\n",
    "`mlflow` records each run in \n",
    "- the local files, \n",
    "- an SQLAlchemy database, or \n",
    "- remote storage (via the [`mlflow.set_tracking_uri()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri) function).\n",
    "\n",
    "For more information on storage, check out the documentation [here](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded).\n",
    "\n",
    "> __Via `MLFlow`, we can track, version and create comprehensive experiments, starting with ETL and ending with deployment.__\n",
    "\n",
    "### Important concepts\n",
    "There are a few main concepts to understand when using MLFlow.\n",
    "- __experiment__: mainly [`mlflow.set_experiment(UNIQUE_NAME_OF_EXPERIMENT)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_experiment), which sets the current experiments and optionally creates them if they do not exist.\n",
    "- __run__: an experiment can consist of multiple single runs. Context manager [`mlflow.start_run()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run).\n",
    "- __logging__: essentially logging data from an experiment. Here are the related functions:\n",
    "    - [`mlflow.log_param(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param) logs hyperparameters and other settable parameters under the current run.\n",
    "    - [`mlflow.log_metric(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric).\n",
    "    - [`mlflow.log_artifact(local_path)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact) logs the created file(s) (e.g. models, generated text, etc.) under the current run.\n",
    "    \n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Next, as a demonstration, we run and log a __non-flavoured__ (i.e. without specific integrations) dummy experiment:"
=======
    "Given the above, let's see how to run and log __non-flavored__ (e.g. without specific integrations) dummy experiment:"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:43:32.171088Z",
     "start_time": "2021-04-25T21:43:32.013188Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "def create_dummy_file():\n",
    "    features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
    "    with open(\"features.txt\", \"w\") as f:\n",
    "        f.write(features)\n",
    "\n",
    "\n",
    "create_dummy_file()\n",
    "\n",
    "# Create experiment (artifact_location=./ml_runs by default)\n",
    "mlflow.set_experiment(\"Dummy Experiments\")\n",
    "\n",
    "# By default, the experiment we have set will be used.\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"features.txt\")\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    for i in range(10):\n",
    "        mlflow.log_metric(\"Iteration\", i, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise and explore the saved data, we run the `mlflow ui` command and visit [`http://localhost:5000 `](http://localhost:5000) in a web browser (__the data will be saved in `./mlruns`__).\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Run the following in the terminal:"
=======
    "Run below in the terminal:"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:31:33.674264Z",
     "start_time": "2021-04-25T21:31:32.591694Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mlflow ui --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After navigating to the experiment, we can observe the `Iteration` being logged as shown below:\n",
    "\n",
    "![](images/mlflow_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Format\n",
    "\n",
    "> MLFlow provides a standard format for saving ML models (from various libraries), which aids the usage of models (e.g. inference on REST API, cloud, etc.). \n",
    "\n",
    "MLFlow models consist of the following:\n",
    "- a directory with arbitrary files defined by the model.\n",
    "- an `MLmodel` file (written in yaml) that specifies the contents of the model.\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Below, we demonstrate how to save a model (in this case, `sklearn`) in Python:"
=======
    "Let's see how to save our model (in this case `sklearn`) in Python..."
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a07f86677dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.save_model(model, \"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates the following directory in our `cwd`:\n",
    "\n",
    "```bash\n",
    "my_model/\n",
    "├── MLmodel\n",
    "└── model.pkl\n",
    "```\n",
    "\n",
    "The contents of the `MLModel` are equally easy to understand:\n",
    "\n",
    "```yml\n",
    "---\n",
    "time_created: 2021-04-03T17:28:53.35\n",
    "\n",
    "flavours:\n",
    "  sklearn:\n",
    "    sklearn_version: 0.24.1\n",
    "    pickled_model: model.pkl\n",
    "  python_function:\n",
    "    loader_module: mlflow.sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model signature\n",
    "\n",
    "To deploy and occasionally run a model (e.g. in `tensorflow`), the __model signature__ must be specified.\n",
    "\n",
    "> __Model signature specifies the type and shape of inputs going through the model.__\n",
    "\n",
    "*Things to note*\n",
    "- Standard casting rules apply (upcasting is fine; however, downcasting will raise an error).\n",
    "- The model signature aids the reading of inputs when they are sent in JSON format via REST API or the like.\n",
    "\n",
    "It can be added to the `MLModel` file via any of the two modes: column signature or tensor signature.\n",
    "\n",
    "#### Column signature\n",
    "\n",
    "> In this mode, the user specifies the input signature by specifying every possible column input.\n",
    "\n",
    "This mode is supported by all flavours (frameworks); however, it might be difficult to achieve in some cases.\n",
    "\n",
    "Consider the example below, which uses the `iris` dataset:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"sepal length (cm)\", \"type\": \"double\"}, {\"name\": \"sepal width\n",
    "      (cm)\", \"type\": \"double\"}, {\"name\": \"petal length (cm)\", \"type\": \"double\"}, {\"name\":\n",
    "      \"petal width (cm)\", \"type\": \"double\"}]'\n",
    "    outputs: '[{\"type\": \"integer\"}]'\n",
    "```\n",
    "\n",
    "#### Tensor signature\n",
    "\n",
    "> In this mode, the user specifies the input for deep-learning inputs (e.g. images) via the tensor shape.\n",
    "\n",
    "Consider the image-oriented example:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"images\", \"dtype\": \"uint8\", \"shape\": [-1, 28, 28, 1]}]'\n",
    "    outputs: '[{\"shape\": [-1, 10], \"dtype\": \"float32\"}]'\n",
    "```\n",
    "\n",
    "#### Inferring input shapes\n",
    "\n",
    "Generally, it is relatively easy (and less error-prone) to infer `dtype` and the shape through our code. These can easily be achieved via [`mlflow.models.infer_signature`](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.infer_signature).\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "An example is provided below."
=======
    "Check out code below for an example"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "clf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "clf.fit(iris_train, iris.target)\n",
    "signature = infer_signature(iris_train, clf.predict(iris_train))\n",
    "\n",
    "mlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `infer_signature`,\n",
    "- pass the input data (conventionally `torch.Tensor`, `pd.DataFrame`, `np.ndarray` or other standard types).\n",
    "- pass data through the model as the second argument, which will create `outputs` automatically.\n",
    "\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "The `mlflow.sklearn.log_model` command saves the model to the file in the `cwd` named `iris_rf` with the specified signature.\n",
    "Note that we can load it later from the disk (__it must be customised to the flavour in which it was saved__)."
=======
    "`mlflow.sklearn.log_model` saves the model to the file in `cwd` named `iris_rf` with our specified signature.\n",
    "We could later load it from the disk (__it has to be tailored to the flavor we saved it in!__):"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sklearn model\n",
    "\n",
    "sklearn_model = mlflow.sklearn.load_model(\"iris_rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Models\n",
    "\n",
    "Once the model has been saved, it can easily be deployed to various services:\n",
    "- [locally](https://www.mlflow.org/docs/latest/models.html#deploy-mlflow-models) with REST API (either inside a `docker` container or a `conda` environment).\n",
    "- [Microsoft's Azure ML](https://www.mlflow.org/docs/latest/models.html#deploy-a-python-function-model-on-microsoft-azure-ml).\n",
    "- [Amazon SageMaker](https://www.mlflow.org/docs/latest/models.html#deploy-a-python-function-model-on-amazon-sagemaker).\n",
    "- [Apache UDF](https://www.mlflow.org/docs/latest/models.html#export-a-python-function-model-as-an-apache-spark-udf).\n",
    "- Other services, maintained by community-driven deployment plugins (e.g. `torchserve`). Check [here](https://www.mlflow.org/docs/latest/plugins.html#deployment-plugins) for more information.\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "The `mlflow models` commands are shown below."
=======
    "Let's see `mlflow models` command:"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:36:46.388087Z",
     "start_time": "2021-05-01T14:36:45.003143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow models [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Deploy MLflow models locally.\n",
      "\n",
      "  To deploy a model associated with a run on a tracking server, set the\n",
      "  MLFLOW_TRACKING_URI environment variable to the URL of the desired server.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  build-docker  **EXPERIMENTAL**: Builds a Docker image whose default...\n",
      "  predict       Generate predictions in json format using a saved MLflow...\n",
      "  prepare-env   **EXPERIMENTAL**: Performs any preparation necessary to...\n",
      "  serve         Serve a model saved with MLflow by launching a webserver on...\n"
     ]
    }
   ],
   "source": [
    "!mlflow models --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The build-docker subcommand\n",
    "\n",
    "> This subcommand creates a docker image and places the model inside it.\n",
    "\n",
    "Thereafter, the model can be served by running the created image (by default, port `8080` is exposed; thus, it can easily be mapped).\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "To view more information on this subcommand, run the following:"
=======
    "Let's see this command in more details"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:37:21.282191Z",
     "start_time": "2021-05-01T14:37:20.242857Z"
    }
   },
   "outputs": [],
   "source": [
    "!mlflow models build-docker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The default is `python_flavor`, and it is compatible with every specific integration__ (more details are provided [here](https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html)).\n",
    "\n",
    "### The serve subcommand\n",
    "\n",
    "> This subcommand runs a basic web server (created via `flask`) which we can query (e.g. using `curl`).\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "The following can be specified, amongst other things:\n",
    "- `--model-uri`: the model resource (mandatory).\n",
    "- `--workers`: the number of parallel workers handling requests.\n",
    "- `--port`: the port that the server listens to for requests."
=======
    "We can specify (amongst other things):\n",
    "- `--model-uri` - model resource (mandatory)\n",
    "- `--workers` - number of parallel workers handling requests\n",
    "- `--port` - on which port the server will listen for requests"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T18:33:14.270664Z",
     "start_time": "2021-05-02T18:33:13.286867Z"
    }
   },
   "outputs": [],
   "source": [
    "!mlflow models serve --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The predict subcommand\n",
    "\n",
    "> This subcommand allows us to query the model with a file (`.csv` or `.json`) (__useful for testing__).\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "To view the possibilities, run the following command:"
=======
    "Let's see the possibilities:"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T18:42:23.981463Z",
     "start_time": "2021-05-02T18:42:23.007619Z"
    }
   },
   "outputs": [],
   "source": [
    "!mlflow models predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Deployed Models\n",
    "\n",
    "Once a model has been deployed (via `docker` or `flask` webserver), it can be queried (from other machines or `localhost`). \n",
    "\n",
    "Requests are made by sending `json` text strings to the `/invocations` endpoint. There are a few possibilities for sending the data:\n",
    "- JSON-serialised pandas DataFrames in the split orientation (`data = pandas_df.to_json(orient='split')`).\n",
    "- JSON-serialised pandas DataFrames in the record orientation (discouraged).\n",
    "- CSV-serialised pandas DataFrames (`data = pandas_df.to_csv()`).\n",
    "- Tensor input, formatted as described in TF Serving’s API docs; here, the provided inputs will be cast to Numpy arrays.\n",
    "\n",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Each of the above can be observed below (please note the `content/type` specification for the different versions):"
=======
    "Each of the above can be seen below (please notice `content/type` specification for different versions):"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split-oriented DataFrame input\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\n",
    "    \"columns\": [\"a\", \"b\", \"c\"],\n",
    "    \"data\": [[1, 2, 3], [4, 5, 6]]\n",
    "}'\n",
    "\n",
    "# record-oriented DataFrame input (fine for vector rows, loses ordering for JSON records)\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 1,\"b\": 2,\"c\": 3},\n",
    "    {\"a\": 4,\"b\": 5,\"c\": 6}\n",
    "]'\n",
    "\n",
    "# numpy/tensor input using TF serving's 'instances' format\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\n",
    "    \"instances\": [\n",
    "        {\"a\": \"s1\", \"b\": 1, \"c\": [1, 2, 3]},\n",
    "        {\"a\": \"s2\", \"b\": 2, \"c\": [4, 5, 6]},\n",
    "        {\"a\": \"s3\", \"b\": 3, \"c\": [7, 8, 9]}\n",
    "    ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
    "Moreover, we could encode more complex data before sending the request (e.g. images could be encoded using `base64` and automatically decoded by MLFlow):"
=======
    "We could also encode more complex data before sending the request (e.g. images could be encoded using `base64` and automatically decoded by MLFlow):"
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record-oriented DataFrame input with binary column 'b'\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 0, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAw\"},\n",
    "    {\"a\": 1, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAx\"},\n",
    "    {\"a\": 2, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAy\"}\n",
    "]'\n",
    "\n",
    "# record-oriented DataFrame input with datetime column 'b'\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 0, \"b\": \"2020-01-01T00:00:00Z\"},\n",
    "    {\"a\": 1, \"b\": \"2020-02-01T12:34:56Z\"},\n",
    "    {\"a\": 2, \"b\": \"2021-03-01T00:00:00Z\"}\n",
    "]'"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
   "id": "b13ab719",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of \n",
    "\n",
    "- MLFlow installation, projects and experiment tracking.\n",
    "- model formats.\n",
    "- how to deploy models.\n",
    "- how to query deployed models."
=======
   "metadata": {},
   "source": [
    "In summary, we've seen how MLFlow can be used to track experiments and deploy models."
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06c1e258a470a687113bfba03f207c092b27379067ada2d83b8b31269ab641fe"
  },
  "kernelspec": {
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
   "display_name": "Python 3.8.2 64-bit ('main': conda)",
=======
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:MLOps/1. MLFlow/0. Experiment tracking with MLFlow/Notebook.ipynb
   "version": "3.8.2"
=======
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
>>>>>>> dev:archive/0. Experiment tracking with MLFlow/Notebook.ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
