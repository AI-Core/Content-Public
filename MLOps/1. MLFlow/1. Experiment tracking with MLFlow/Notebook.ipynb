{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment tracking\n",
    "\n",
    "> __Tracking is an API and UI which allows us to log experiment's data and later visualizing it__\n",
    "\n",
    "Using it we can log:\n",
    "- model parameters\n",
    "- code versions (git commit hashes)\n",
    "- metrics\n",
    "- generated artifacts\n",
    "\n",
    "__`mlflow` tracking is organized around runs, which is simply some form of execution of our program__.\n",
    "\n",
    "Each run is recorded by `mlflow` either to:\n",
    "- local files\n",
    "- SQLAlchemy database\n",
    "- remote storage (via [`mlflow.set_tracking_uri()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri) function)\n",
    "\n",
    "For more information about storage [check out relevant part of documentation](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded).\n",
    "\n",
    "> __Via `MLFlow` we can track, version and create comprehensive experiment from everything, starting with ETL and ending with deployment__\n",
    "\n",
    "There are a few main concepts to keep in mind when using it:\n",
    "- __experiment__ - mainly [`mlflow.set_experiment(UNIQUE_NAME_OF_EXPERIMENT)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_experiment) which sets current experiments and optionally creates it if it doesn't exist.\n",
    "- __run__ - single run, experiment can consist of multiple of those. Context manager [`mlflow.start_run()`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run)\n",
    "- __logging__ - logging data from an experiment; here are the related function:\n",
    "    - [`mlflow.log_param(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param) - logs hyperparameters and other settable parameters under current run\n",
    "    - [`mlflow.log_metric(key, value)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric)\n",
    "    - [`mlflow.log_artifact(local_path)`](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact) - logs created file (e.g. models, generated text etc.) under the current run\n",
    "    \n",
    "Given the above, let's see how to run and log __non-flavored__ (e.g. without specific integrations) dummy experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:43:32.171088Z",
     "start_time": "2021-04-25T21:43:32.013188Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "def create_dummy_file():\n",
    "    features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
    "    with open(\"features.txt\", \"w\") as f:\n",
    "        f.write(features)\n",
    "\n",
    "\n",
    "create_dummy_file()\n",
    "\n",
    "# Create experiment (artifact_location=./ml_runs by default)\n",
    "mlflow.set_experiment(\"Dummy Experiments\")\n",
    "\n",
    "# By default experiment we've set will be used\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"features.txt\")\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    for i in range(10):\n",
    "        mlflow.log_metric(\"Iteration\", i, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize & explore saved data we can use `mlflow ui` command and open web browser under [`http://localhost:5000 `](http://localhost:5000) (__data will be saved inside `./mlruns`__)\n",
    "\n",
    "Run below in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T21:31:33.674264Z",
     "start_time": "2021-04-25T21:31:32.591694Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mlflow ui --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After navigating to the the experiment, we can see the `Iteration` being logged like below:\n",
    "\n",
    "![](images/mlflow_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model format\n",
    "\n",
    "> MLFlow provides standard format for saving machine learning models (from various libraries) which helps us with model usage (e.g. inference on REST API, cloud etc.) \n",
    "\n",
    "MLFlow models consist of:\n",
    "- directory with arbitrary files defined by the model)\n",
    "- `MLmodel` file (written in yaml) which specifies what is contained within the model\n",
    "\n",
    "Let's see how to save our model (in this case `sklearn`) in Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a07f86677dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.save_model(model, \"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which creates the following directory in our `cwd`:\n",
    "\n",
    "```bash\n",
    "my_model/\n",
    "├── MLmodel\n",
    "└── model.pkl\n",
    "```\n",
    "\n",
    "Contents of the `MLModel` are equally easy to grasp:\n",
    "\n",
    "```yml\n",
    "---\n",
    "time_created: 2021-04-03T17:28:53.35\n",
    "\n",
    "flavors:\n",
    "  sklearn:\n",
    "    sklearn_version: 0.24.1\n",
    "    pickled_model: model.pkl\n",
    "  python_function:\n",
    "    loader_module: mlflow.sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model signature\n",
    "\n",
    "In order to deploy (and sometimes even run, like in `tensorflow`) we need to specify __model signature__\n",
    "\n",
    "> __Model signature specifies type and shape of inputs going through the model__\n",
    "\n",
    "- Standard casting rules apply (upcasting is fine, downcasting would raise an error)\n",
    "- Helps reading inputs when those are send using JSON via REST API or a-like\n",
    "\n",
    "We can add it to `MLModel` file, two options to do so below:\n",
    "\n",
    "#### Column signature\n",
    "\n",
    "> Specify input signature by specifying each possible column input\n",
    "\n",
    "This mode is supported by all flavors (frameworks), yet those might not be the easiest in all cases.\n",
    "\n",
    "Example for `iris` dataset:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"sepal length (cm)\", \"type\": \"double\"}, {\"name\": \"sepal width\n",
    "      (cm)\", \"type\": \"double\"}, {\"name\": \"petal length (cm)\", \"type\": \"double\"}, {\"name\":\n",
    "      \"petal width (cm)\", \"type\": \"double\"}]'\n",
    "    outputs: '[{\"type\": \"integer\"}]'\n",
    "```\n",
    "\n",
    "#### Tensor signature\n",
    "\n",
    "> Specify input for deep learning inputs (e.g. images) via tensor shape\n",
    "\n",
    "Image oriented example:\n",
    "\n",
    "```yaml\n",
    "signature:\n",
    "    inputs: '[{\"name\": \"images\", \"dtype\": \"uint8\", \"shape\": [-1, 28, 28, 1]}]'\n",
    "    outputs: '[{\"shape\": [-1, 10], \"dtype\": \"float32\"}]'\n",
    "```\n",
    "\n",
    "#### Inferring input shapes\n",
    "\n",
    "Often it is easier (and less error-prone) to infer `dtype` and shape through our code. One can easily do this via [`mlflow.models.infer_signature`](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.infer_signature).\n",
    "\n",
    "Check out code below for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "clf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "clf.fit(iris_train, iris.target)\n",
    "signature = infer_signature(iris_train, clf.predict(iris_train))\n",
    "\n",
    "mlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`infer_signature` is really simple:\n",
    "- Pass input data (usually `torch.Tensor`, `pd.DataFrame`, `np.ndarray` or other standard types)\n",
    "- Pass data through the model as the second argument - this will create `outputs` automatically\n",
    "\n",
    "\n",
    "`mlflow.sklearn.log_model` saves the model to the file in `cwd` named `iris_rf` with our specified signature.\n",
    "We could later load it from the disk (__it has to be tailored to the flavor we saved it in!__):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sklearn model\n",
    "\n",
    "sklearn_model = mlflow.sklearn.load_model(\"iris_rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we've seen how MLFlow can be used to track experiments."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06c1e258a470a687113bfba03f207c092b27379067ada2d83b8b31269ab641fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
