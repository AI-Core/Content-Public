{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and File Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working in projects involved in AI, most likely you will need to deal with different data and file formats including:\n",
    "- CSV\n",
    "- JSON\n",
    "- YAML\n",
    "- images\n",
    "- videos\n",
    "- audio\n",
    "\n",
    "In this notebook, we are making a brief introduction to each one of them, as well as giving some comments on how and when to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with some files with the data formats we mentioned, so before start reading the notebook, make sure to run the following cell to download the necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-15 16:55:06--  https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/Salaries.csv\n",
      "Resolving aicore-files.s3.amazonaws.com (aicore-files.s3.amazonaws.com)... 52.217.134.81\n",
      "Connecting to aicore-files.s3.amazonaws.com (aicore-files.s3.amazonaws.com)|52.217.134.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75224 (73K) [text/csv]\n",
      "Saving to: ‘Salaries.csv’\n",
      "\n",
      "Salaries.csv        100%[===================>]  73.46K   362KB/s    in 0.2s    \n",
      "\n",
      "2022-02-15 16:55:07 (362 KB/s) - ‘Salaries.csv’ saved [75224/75224]\n",
      "\n",
      "--2022-02-15 16:55:07--  https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/employees.xml\n",
      "Reusing existing connection to aicore-files.s3.amazonaws.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 603 [text/xml]\n",
      "Saving to: ‘employees.xml’\n",
      "\n",
      "employees.xml       100%[===================>]     603  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-15 16:55:07 (11.7 MB/s) - ‘employees.xml’ saved [603/603]\n",
      "\n",
      "--2022-02-15 16:55:07--  https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/JSON_sample.json\n",
      "Reusing existing connection to aicore-files.s3.amazonaws.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 794 [application/json]\n",
      "Saving to: ‘JSON_sample.json’\n",
      "\n",
      "JSON_sample.json    100%[===================>]     794  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-15 16:55:08 (75.7 MB/s) - ‘JSON_sample.json’ saved [794/794]\n",
      "\n",
      "--2022-02-15 16:55:08--  https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/yaml_example.yaml\n",
      "Reusing existing connection to aicore-files.s3.amazonaws.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 224 [application/x-yaml]\n",
      "Saving to: ‘yaml_example.yaml’\n",
      "\n",
      "yaml_example.yaml   100%[===================>]     224  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-15 16:55:08 (16.4 MB/s) - ‘yaml_example.yaml’ saved [224/224]\n",
      "\n",
      "FINISHED --2022-02-15 16:55:08--\n",
      "Total wall clock time: 1.2s\n",
      "Downloaded: 4 files, 75K in 0.2s (369 KB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/Salaries.csv\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/employees.xml\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/JSON_sample.json\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/yaml_example.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1> CSV __(comma-separated values)__ files contain rows of data, with each value in a row separated by a comma\n",
    "\n",
    "- They are a very common way to store data. </font>\n",
    "- All of the data for a single record is on one line: each new line is a new record.\n",
    "- The comma in this case is called the __'delimiter'__ as it shows the difference (or limit) between one value and the next.\n",
    "- Other common delimiters are semi-colons and tabs (also called __tsv/tab-separated values__).\n",
    "- We must be careful to check what exactly the delimiter is, as a common error is reading in a file with the wrong delimiter, and so getting a weird representation in your data.\n",
    "- CSVs can also be read by Excel.\n",
    "<p style=\"font-size:10.5px\">\n",
    "Usually if you are using data from mainland European countries (France/Spain etc) they will use semi-colons, hence some people prefer <i>character</i>-separated values for CSV.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python counts with a library called `csv` that has the needed functionalities to read and write CSV files.\n",
    "\n",
    "We open an existing file (Salaries.csv) using a context manager, and the mode in the context manager is set to read (`r`). Then, use the reader class from csv, which will take the values in the csv and store them into a variable that becomes an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Salaries.csv', mode='r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for n, row in enumerate(reader):\n",
    "        print(','.join(row))\n",
    "        if n == 5: # Read only the first five entries\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same library can be used to generate csv files. The only thing you need to change is the mode argument in the context manager is write (`w`). If you want to append things to the csv, you can use the mode append (`a`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to reading a CSV file, if we write a CSV, we need to use the `writer` class, which will point to the file we want to create. Notice that the file we want to generate doesn't necessarily have to exist (if it exists, it will overwrite its content)\n",
    "\n",
    "The `writer` object has some methods to create a new file. The most common one is `writerows`, which accepts iterables as arguments, and parse them into a comma separated row\n",
    "\n",
    "So, if we define a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [['Sparky', 7, 'Brown', 'Corgi'], ['Fido', 4, 'White', 'Husky']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new csv file where each row contains the characteristic of each dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Dogs.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Name', 'Age', 'Colour', 'Breed'])\n",
    "    writer.writerows(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference between `writerow` and `writerows`. Try running the following cell and see if you see any difference between both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dogs_2.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Name', 'Age', 'Colour', 'Breed'])\n",
    "    writer.writerow(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1> JSON (JavaScript Object Notation) is a file format that stores data in a way that is easily readable by both humans and machines.</font>\n",
    "\n",
    "- It is as useful way for a browser and a server to exchange data, so it is used extensively in Web-based applications of coding.\n",
    "- In fact, Jupyter Notebook .ipynb files are actually stored in JSON format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON format is very similar to Python dictionaries, they contain a key and it has a corresponding value to that key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers a library called `json` that can read, write, or append elements from or to a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is very similar to the one for CSV files. We use a context manager, set the mode we want to use, and then use a method. In this case, for reading a file, we use the `load` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('JSON_sample.json', mode='r') as f:\n",
    "    json_dict = json.load(f)\n",
    "\n",
    "print(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that, whatever we read, is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create json files from dictionaries. Observe that the mode of the context manager is `w`. The method in this case is `dump`. The `dump` method accepts the data we want to use, and then the file we want to dump the data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "with open('JSON_test.json', mode='w') as f:\n",
    "    json.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe in your directory that now you have a `json` file called `JSON_test.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a string containing a json and parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = json.loads(x)\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with the double quotes! If your keys have single quotes, the json parser will not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  \"{'name': 'John', 'age': 30, 'city': 'New York'}\"\n",
    "y = json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the opposite (from dictionary to JSON string) using the `dumps` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'a': 3, 'b': 4}\n",
    "new_json = json.dumps(test_dict)\n",
    "print(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAML is a data serialization language, which means that it is a common language across different applications. In fact, you already saw a serialization language in this lesson: JSON.\n",
    "\n",
    "> <font size=+1> YAML (YAML Ain't Markup Language) is a data serialization language </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of YAML is that is highly human-readable. You can see a comparison between JSON and YAML containing the same information.\n",
    "### YAML:\n",
    "```\n",
    "simple-property: a simple value\n",
    "\n",
    "object-property:\n",
    "    first-property: first value\n",
    "    second-property: second value\n",
    "\n",
    "array-property:\n",
    "    - item-1-property-1: one\n",
    "      item-1-property-2: 2\n",
    "    - item-2-property-1: three\n",
    "      item-2-property-2: 4\n",
    "```\n",
    "\n",
    "### JSON\n",
    "```\n",
    "{\n",
    "  \"simple-property\": \"a simple value\",\n",
    "\n",
    "  \"object-property\": {\n",
    "      \"first-property\": \"first value\",\n",
    "      \"second-property\": \"second value\",\n",
    "  },\n",
    "\n",
    "  \"array-property\": [\n",
    "      { \"item-1-property-1\": \"one\",\n",
    "        \"item-1-property-2\": 2 },\n",
    "      { \"item-2-property-1\": \"three\",\n",
    "        \"item-2-property-2\": 4}\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the base of YAML files lies in the indentation and the linespaces.\n",
    "\n",
    "The most basic syntax in a YAML file is the __key:value__ pair\n",
    "```\n",
    "key: value\n",
    "```\n",
    "For example:\n",
    "```\n",
    "# This is a comment\n",
    "name: Ivan\n",
    "surname: 'Ying'\n",
    "role: \"Instructor\"\n",
    "IQ: 0\n",
    "```\n",
    "Notice that strings can be either into double quotes, single quotes or nothing, and they will work the same.\n",
    "\n",
    "Another useful way of using YAML files is leveraging __objects__ simply by indenting the key:value pairs:\n",
    "```\n",
    "# This is a comment\n",
    "Person:\n",
    "    name: Ivan\n",
    "    surname: 'Ying'\n",
    "    role: \"Instructor\"\n",
    "    IQ: 0\n",
    "```\n",
    "Same as with Python, indentation should be at the right level, and it would be a good idea to have a linter for checking it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look for `docs-yaml` in your Extensions tab on VSCode to install a linter to tell you whether your YAML file is well indented or not. Or you can also visit [this link](https://codebeautify.org/yaml-validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing you can use in YAML files are lists. List can contain single values, or it can also contain key:value pair values\n",
    "```\n",
    "Person:\n",
    "    - name: Ivan\n",
    "      surname: 'Ying'\n",
    "      role: \"Instructor\"\n",
    "      IQ: 0\n",
    "    - name: Not Ivan\n",
    "      surname: 'Gniy'\n",
    "      role: \"Doppelganger\"\n",
    "      IQ: 150\n",
    "Animals:\n",
    "    - Cat\n",
    "    - Dog\n",
    "    - Shoebill\n",
    "    - Kakapo\n",
    "```\n",
    "The last list can also be written as:\n",
    "```\n",
    "Animals: [Cat, Dog, Shoebill, Kakapo]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read YAML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python doesn't have a library for reading YAML files. But not to worry, you can install a library that allows you to do so. The library is named `PyYAML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, some libraries don't have the same name as they are published with. In this case, if you want to use the PyYAML library, you simply need to import `yaml`\n",
    "\n",
    "Like CSVs and JSONs, we might want to use a context manager with the read mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('yaml_example.yaml', 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "print(type(data_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that, same as with JSON files, we obtain a dictionary. Let's print it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loaded)\n",
    "print(data_loaded.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have two main keys, 'Person', and 'Animal'. The value corresponding to 'Person' is a list with dictionaries, and the value corresponding to 'Animal' is just a regular list\n",
    "\n",
    "So we can get the values of it by indexing the correct key and/or index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The first element of Person is: {data_loaded['Person'][0]}\")\n",
    "print(f\"The name of the first element of Person is: {data_loaded['Person'][0]['name']}\")\n",
    "print(f\"The second element of Person is: {data_loaded['Person'][1]}\")\n",
    "print(f\"The name of the second element of Person is: {data_loaded['Person'][1]['name']}\")\n",
    "print(f'The value corresponding to Animals is: {data_loaded[\"Animals\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create YAML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create YAML using the same library. The variable you need to use to create a YAML file is a dictionary. So, let's define a simple dictionary out of a JSON file we have, and then create a YAML from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('JSON_sample.json', mode='r') as f:\n",
    "    my_dict = json.load(f)\n",
    "\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `dump` method to save the dictionary as a yaml file. The `dump` method accepts the data we want to use, and then the file in which we want to dump our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YAML_from_JSON.yaml', 'w') as f:\n",
    "        yaml.dump(my_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows us to read these data formats in an easy way, so we don't have to think about the libraries or modules that we need to import\n",
    "\n",
    "The syntax is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_{format}('FILE_DIR')\n",
    "\n",
    "df.to_{format}('FILE_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and CSV\n",
    "The syntax for reading in a CSV to pandas is thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save the read_csv to a variable\n",
    "df = pd.read_csv('<filename>')\n",
    "\n",
    "# the to_csv method is a method off a data frame\n",
    "df.to_csv('<filename>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read in the csv file\n",
    "df = pd.read_csv('Salaries.csv', index_col='Id')\n",
    "\n",
    "# show as DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get only the first 5 rows and save that into a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.head(5)\n",
    "df_short\n",
    "df_short.to_csv('Salaries_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas can also read and write from and to JSON using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "df = pd.read_json('JSON_sample.json')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look good... We have to normalize each value in that column, so each key corresponds to a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nice = pd.json_normalize(df[\"Employees\"])\n",
    "df_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nice.to_json('JSON_sample_new.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML\n",
    "- XML (eXtensible Markup Language) is another way of exchanging data between browsers and servers (JSON is an alternative to XML).\n",
    "- Hence, like with JSON, we can use XML to obtain data from the web and they have the extension `.xml`.\n",
    "- XML is a markup language like HTML, so it contains data, and information on how to structure that data, but not how it is displayed.\n",
    "- Hence we need an API to extract data from an XML file.\n",
    "- You can use the following process although it is not the only possible way to do it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Structure\n",
    "\n",
    "XML Documents are structured much like HTML:\n",
    "- They are hierarchical in structure.\n",
    "- The document usually contains a prolog tag containing meta data, such as version, character encoding and associated style sheet.\n",
    "- The next tag will be the root(`data` in this case) tag which will contain all other tags of the document.\n",
    "- Each tag is completely flexible in it's naming unlike HTML which has a pre-defined set of tags.\n",
    "\n",
    "#### Components of XML\n",
    "\n",
    "- __Document:__ The root tag opens the document in this case `<data>` and the ending tag `</data>` closes it.\n",
    "- __Node:__ Each tag containing other tags is a node tag here `<employee>` is a node tag.\n",
    "- __Elements:__ Elements such as `<email>alpha@aicore.com</email>` and ` <age>36</age>` are considered elements.\n",
    "- __Content:__ The data between the elements tags are considered content. In the email element `<email>alpha@aicore.com</email>`, the string `alpha@aicore.com` is considered the content.\n",
    "\n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<data>\n",
    "    <employee name=\"Alpha\">\n",
    "        <email>alpha@aicore.com</email>\n",
    "        <department>HR</department>\n",
    "        <age>36</age>\n",
    "    </employee>\n",
    "    <employee name=\"Bravo\">\n",
    "        <email>bravo@aicore.com</email>\n",
    "        <department>sales</department>\n",
    "        <age>23</age>\n",
    "    </employee>\n",
    "    <employee name=\"Charlie\">\n",
    "        <email>charlie@aicore.com</email>\n",
    "        <department>accounts</department>\n",
    "        <age>44</age>\n",
    "    </employee>\n",
    "    <employee name=\"Delta\">\n",
    "        <email>delta@aicore.com</email>\n",
    "        <department>reception</department>\n",
    "        <age>51</age>\n",
    "    </employee>\n",
    "</data>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use this premade function to parse in XML files, which requires only 2 arguments:\n",
    "    - The XML filename\n",
    "    - The columns of the data frame (the fields in each observation in the XML file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_XML(xml_file, df_cols): \n",
    "    \"\"\"Parse the input XML file and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier \n",
    "    variable, which is an attribute of each node element in the \n",
    "    XML data; other features will be parsed from the text content \n",
    "    of each sub-element. \n",
    "    \"\"\"\n",
    "    \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        res.append(node.attrib.get(df_cols[0]))\n",
    "        for el in df_cols[1:]: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_XML(\"employees.xml\", [\"name\", \"email\", \"department\", \"age\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read `.xml` files using pandas `read_xml` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameter `attrs_only` we can specify only showing the tags with attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\", attrs_only=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `elems_only` parameter we can specify only showing the data from element tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\", elems_only=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert the dataframe easily back to an XML document with the `to_xml` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_xml(\"employees_df_export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "\n",
    "Computers don't see images the way we see them, when an image is stored on your computer it needs to be stored in a way in which the computer can understand. \n",
    "- They see images as a 2D matrix or 3D array where the third dimension represents the channels.\n",
    "- Each unit in that grid is a __pixel__.\n",
    "- Your resolution determines the size of this matrix. A resolution of 800 x 600 would be a grid of size 800 by 600 pixels.\n",
    "- Each pixel has a number associated with it determining its colour.\n",
    "\n",
    "For example, this is how a computer would represent a grayscale image:\n",
    "- __Grayscale__ images have one channel to represent the image(gray).\n",
    "- Colours on computers are usually represented using 8-bit numbers giving a set of 8 zeros and ones. This gives 2<sup>8</sup> or 256 possible representations of each pixel.\n",
    "- Each representation describes the intensity or brightness of that particular colour. In this case, 0 is black and 255 would represent white.\n",
    "\n",
    "![](./images/grayscale.png)\n",
    "\n",
    "\n",
    "With colour images they are normally represented by the RGB (Red, Green, Blue) model, for example:\n",
    "- __RGB__ is represented by three channels - __Red__, __Green__ and __Blue__.\n",
    "- The channels are combined together to create the image.\n",
    "- All red would be expressed as (255, 0, 0), green by (0, 255, 0) and blue by (0, 0, 255).\n",
    "- White can be  by (255, 255, 255) and black by (0, 0, 0).\n",
    "- Any other colour can be represented by a combination of all three. For instance (106, 13, 173) would represent the colour purple. \n",
    "- This gives us a possible combination of 16,777,216 different colours.\n",
    "\n",
    "<img src=\"./images/rgb_image.png\"/>\n",
    "\n",
    "There are other systems a computer can use to represent colours\n",
    "- For printers, they use the CMYK system to represent colours:\n",
    "  - __C__ for Cyan\n",
    "  - __M__ for Mageneta \n",
    "  - __Y__ or Yellow \n",
    "  - __K__ for Black \n",
    "- Another common one is Hexadecimal format.\n",
    "  - Each colour is represented by # followed by six characters #RRGGBB.\n",
    "  - Each RR (red), GG (green), and BB (blue) are hexadecimal integers between 00 and FF. \n",
    "  - For example, #0000FF displays blue since FF is the highest representation and 00 is the lowest.\n",
    "  - #CC5500 would represent a burnt orange colour can you see why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio\n",
    "\n",
    "Audio is a little more complicated; sound is an analog signal, which is made up of waves travelling through matter. The computer needs to convert this signal into a digital format to be machine readable.\n",
    "\n",
    "The sound card on your computer performs this process for you:\n",
    "\n",
    "- The sounds card has __four__ main processing components to perform this task.\n",
    "  - __analog-to-digital converter (ADC)__ - to process the incoming analog signal into a digital format, e.g. sound recorded by your microphone. \n",
    "  - __digital-to-analog converter (DAC)__ - converts the digital audio signal on your pc to an analog format so you can listen to it, e.g. converted to analog and output through the speakers. \n",
    "  - __PCI interface__ - to connect the sound card to the motherboard.\n",
    "  - __Input and output__ - for devices such as a microphone or speakers.\n",
    "\n",
    "Sound cards represent audio with the following process:\n",
    "- When an incoming audio is detected by the sound card it will take measurements (samples) of it at regular intervals.\n",
    "  - __Sampling rate__ is defined as the number of samples taken per second of the sound card.\n",
    "  - Sampling rate is measured in hertz (one hertz is one sample per second).\n",
    "  - The higher the hertz, the better quality of  the sound representation.\n",
    "- __Sampling resolution__ is the numbers of bits used to represent the audio.\n",
    "  - The higher the resolution, the better the representation of the sound.\n",
    "\n",
    "True sound (yellow), then visualisations of low and higher sampling rate:\n",
    "\n",
    "<img src=\"./images/sound_sampling.png\" height=\"600\" width=\"400\"/>\n",
    "\n",
    "Increasing sampling resolution:\n",
    "\n",
    "<img src=\"./images/sound_resolution.png\" height=\"600\" width=\"400\"/>\n",
    "\n",
    "Commonly, audio data is visualised as a spectrogram. A spectrogram shows time on the horizontal axis, and frequency on the vertical axis with brighter colors where that frequency is present.\n",
    "\n",
    "<img src=\"./images/spectrogram.png\" height=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We now understand the basic file formats of CSV, JSON, and YAML\n",
    "- We now know how to read them into pandas."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
