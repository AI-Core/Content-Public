{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "## Learning Outcomes:\n",
    "- Learn the structure of HTML\n",
    "- Learn how to use XPath to navigate HTML (via lxml)\n",
    "- Use Selenium to scrape data from websites\n",
    "\n",
    "One of the most common ways to obtain data is through the use of **web scraping**. Web scraping, as the name suggests, is about pulling information from websites in a programmatic fashion... (because copy and pasting would be way too much effort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge\n",
    "\n",
    "Let's say we wanted to build a model which would predict house prices given some features - for example, location, number of bedrooms, number of bathrooms. We need some way of obtaining this data - both the response and the target variables.\n",
    "\n",
    "To introduce you to the concept of web scraping, let's try and extract data for 100 houses:\n",
    "- **Sale Price**: Our response variable\n",
    "- Number of bedrooms\n",
    "- Square footage\n",
    "- Description\n",
    "- Address\n",
    "    \n",
    "[This URL shows houses listed for sale in London](https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list). Let's take a look at where the information that we want to extract is on the webpage.\n",
    "\n",
    "Before we look at solving this challenge, let's take a look at what websites and HTML actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Websites\n",
    "\n",
    "### What format does information on a website exist in?\n",
    "\n",
    "We know that websites don't just print data in a nice CSV or JSON format. \n",
    "They have content to display stuff to you in a way that makes sense, like buttons, on the page. \n",
    "This content is defined in a HTML file.\n",
    "\n",
    "They also have styling\n",
    "\n",
    "#### What is HTML?\n",
    "\n",
    "HTML stands for HyperText Markup Language. It consists of a tree structure of different types of web elements, like buttons, page divisions, images and more. This means that it is used to define what **content** is rendered on any webpage that you visit.\n",
    "\n",
    "HTML markdown contains elements/tags that may contain other elements/tags.\n",
    "\n",
    "\n",
    "[Let's play around with some HTML](https://code.sololearn.com/WoNr8gIeKYDr/)\n",
    "\n",
    "### How can we get the website HTML, which contains data that we want?\n",
    "\n",
    "When you search for a URL in a browser, here's what happens:\n",
    "- your browser makes a **GET request** to the computer (server) that serves requests from that URL endpoint\n",
    "- this computer knows what web content to send you back, so it sends it in a response to the request. This stuff includes the HTML of the page that you want to view.\n",
    "- Your browser gets the HTML, and knows how to present that type of data to you (it renders the webpage)\n",
    "\n",
    "The point here being that you can get the HTML, which defines the content for any site, by making a GET request to that website.\n",
    "\n",
    "Let's try that!\n",
    "\n",
    "We can use the requests library to get the HTML from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<style>\n",
      "img{\n",
      "\twidth:75px;\n",
      "}\n",
      "table{\n",
      "\twidth:50%;\n",
      "}\n",
      "td{\n",
      "\tmargin:10px;\n",
      "\tpadding:10px;\n",
      "}\n",
      ".wrapper{\n",
      "\twidth:800px;\n",
      "}\n",
      ".excitingNote{\n",
      "\tfont-style:italic;\n",
      "\tfont-weight:bold;\n",
      "}\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"wrapper\">\n",
      "<img src=\"../img/gifts/logo.jpg\" style=\"float:left;\">\n",
      "<h1>Totally Normal Gifts</h1>\n",
      "<div id=\"content\">Here is a collection of totally normal, totally reasonable gifts that your friends are sure to love! Our collection is\n",
      "hand-curated by well-paid, free-range Tibetan monks.<p>\n",
      "We haven't figured out how to make online shopping carts yet, but you can send us a check to:<br>\n",
      "123 Main St.<br>\n",
      "Abuja, Nigeria\n",
      "</br>We will then send your totally amazing gift, pronto! Please include an extra $5.00 for gift wrapping.</div>\n",
      "<table id=\"giftList\">\n",
      "<tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "\n",
      "<tr id=\"gift1\" class=\"gift\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\">\n",
      "</td></tr>\n",
      "\n",
      "<tr id=\"gift2\" class=\"gift\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\">\n",
      "</td></tr>\n",
      "\n",
      "<tr id=\"gift3\" class=\"gift\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\">\n",
      "</td></tr>\n",
      "\n",
      "<tr id=\"gift4\" class=\"gift\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\">\n",
      "</td></tr>\n",
      "\n",
      "<tr id=\"gift5\" class=\"gift\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\">\n",
      "</td></tr>\n",
      "</table>\n",
      "</p>\n",
      "<div id=\"footer\">\n",
      "&copy; Totally Normal Gifts, Inc. <br>\n",
      "+234 (617) 863-0736\n",
      "</div>\n",
      "\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests # import the requests library\n",
    "r = requests.get('http://pythonscraping.com/pages/page3.html') # make a HTTP GET request to this website\n",
    "html_string = r.text # the text attribute of this response is the HTML as a string\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we saw above only gives us the HTML, but we want to be able to extract the data from it. After requesting the data from the webpage, we obtain a string of HTML, but looking for some specific data is a bit of a pain. We can use the **BeautifulSoup** library to extract the data from the HTML looking for specific tags and their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <style>\n",
      "   img{\n",
      "\twidth:75px;\n",
      "}\n",
      "table{\n",
      "\twidth:50%;\n",
      "}\n",
      "td{\n",
      "\tmargin:10px;\n",
      "\tpadding:10px;\n",
      "}\n",
      ".wrapper{\n",
      "\twidth:800px;\n",
      "}\n",
      ".excitingNote{\n",
      "\tfont-style:italic;\n",
      "\tfont-weight:bold;\n",
      "}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <div id=\"wrapper\">\n",
      "   <img src=\"../img/gifts/logo.jpg\" style=\"float:left;\"/>\n",
      "   <h1>\n",
      "    Totally Normal Gifts\n",
      "   </h1>\n",
      "   <div id=\"content\">\n",
      "    Here is a collection of totally normal, totally reasonable gifts that your friends are sure to love! Our collection is\n",
      "hand-curated by well-paid, free-range Tibetan monks.\n",
      "    <p>\n",
      "     We haven't figured out how to make online shopping carts yet, but you can send us a check to:\n",
      "     <br/>\n",
      "     123 Main St.\n",
      "     <br/>\n",
      "     Abuja, Nigeria\n",
      "We will then send your totally amazing gift, pronto! Please include an extra $5.00 for gift wrapping.\n",
      "    </p>\n",
      "   </div>\n",
      "   <table id=\"giftList\">\n",
      "    <tr>\n",
      "     <th>\n",
      "      Item Title\n",
      "     </th>\n",
      "     <th>\n",
      "      Description\n",
      "     </th>\n",
      "     <th>\n",
      "      Cost\n",
      "     </th>\n",
      "     <th>\n",
      "      Image\n",
      "     </th>\n",
      "    </tr>\n",
      "    <tr class=\"gift\" id=\"gift1\">\n",
      "     <td>\n",
      "      Vegetable Basket\n",
      "     </td>\n",
      "     <td>\n",
      "      This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "      <span class=\"excitingNote\">\n",
      "       Now with super-colorful bell peppers!\n",
      "      </span>\n",
      "     </td>\n",
      "     <td>\n",
      "      $15.00\n",
      "     </td>\n",
      "     <td>\n",
      "      <img src=\"../img/gifts/img1.jpg\"/>\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr class=\"gift\" id=\"gift2\">\n",
      "     <td>\n",
      "      Russian Nesting Dolls\n",
      "     </td>\n",
      "     <td>\n",
      "      Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"!\n",
      "      <span class=\"excitingNote\">\n",
      "       8 entire dolls per set! Octuple the presents!\n",
      "      </span>\n",
      "     </td>\n",
      "     <td>\n",
      "      $10,000.52\n",
      "     </td>\n",
      "     <td>\n",
      "      <img src=\"../img/gifts/img2.jpg\"/>\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr class=\"gift\" id=\"gift3\">\n",
      "     <td>\n",
      "      Fish Painting\n",
      "     </td>\n",
      "     <td>\n",
      "      If something seems fishy about this painting, it's because it's a fish!\n",
      "      <span class=\"excitingNote\">\n",
      "       Also hand-painted by trained monkeys!\n",
      "      </span>\n",
      "     </td>\n",
      "     <td>\n",
      "      $10,005.00\n",
      "     </td>\n",
      "     <td>\n",
      "      <img src=\"../img/gifts/img3.jpg\"/>\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr class=\"gift\" id=\"gift4\">\n",
      "     <td>\n",
      "      Dead Parrot\n",
      "     </td>\n",
      "     <td>\n",
      "      This is an ex-parrot!\n",
      "      <span class=\"excitingNote\">\n",
      "       Or maybe he's only resting?\n",
      "      </span>\n",
      "     </td>\n",
      "     <td>\n",
      "      $0.50\n",
      "     </td>\n",
      "     <td>\n",
      "      <img src=\"../img/gifts/img4.jpg\"/>\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr class=\"gift\" id=\"gift5\">\n",
      "     <td>\n",
      "      Mystery Box\n",
      "     </td>\n",
      "     <td>\n",
      "      If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining.\n",
      "      <span class=\"excitingNote\">\n",
      "       Keep your friends guessing!\n",
      "      </span>\n",
      "     </td>\n",
      "     <td>\n",
      "      $1.50\n",
      "     </td>\n",
      "     <td>\n",
      "      <img src=\"../img/gifts/img6.jpg\"/>\n",
      "     </td>\n",
      "    </tr>\n",
      "   </table>\n",
      "   <div id=\"footer\">\n",
      "    © Totally Normal Gifts, Inc.\n",
      "    <br/>\n",
      "    +234 (617) 863-0736\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get('http://pythonscraping.com/pages/page3.html')\n",
    "html = page.text # Get the content of the webpage\n",
    "soup = BeautifulSoup(html, 'html.parser') # Convert that into a BeautifulSoup object that contains methods to make the tag searcg easier\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example using the following [URL](http://pythonscraping.com/pages/page3.html) `'http://pythonscraping.com/pages/page3.html'`\n",
    "\n",
    "In that webpage you will find a small list with a set of items. Let's say that you want to extract the data from the Fish Painting.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src='images/BS4_1.png' width=500>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your browser, you can see that the HTML for the page is in the `<body>` tag. Let's see how we can extract the data from this HTML. In the page, right-click on the `<body>` tag and select **Inspect Element**. There, you will see the HTML for the page, and you can see that the Fish Painting is in a `<tr>` tag.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src='images/BS4_2.png' width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find that tag using the method `find` that accepts the tag name, and the attributes of said tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = soup.find(name='tr', attrs={'id': 'gift3', 'class': 'gift'}) # If it doesn't find anything it returns None\n",
    "\n",
    "print(fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `tr` tag, you will find different `<td>` tags. You can find all the `<td>` tags using the method `find_all` that accepts the tag name and the attributes of said tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_row = fish.find_all('td') # This returns a list where each item corresponds to each td tag "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you obtained a list where each element correponds to the data for each column. Thus, you can index the list to get the data you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = fish_row[0].text\n",
    "description = fish_row[1].text\n",
    "price = fish_row[2].text\n",
    "\n",
    "print(title)\n",
    "print(description)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep looking for more data in the tree. For example, you can look for the parrot row taking into account that it is the sibling of the fish row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot = fish.find_next_sibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also find the parrot's children using the method `findChildren`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot_children = parrot.findChildren()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Method?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to apply what you have learned so far about BeautifulSoup. Go to the following page, and look information about the `Methods` section. [https://en.wikipedia.org/wiki/Python_(programming_language)](https://en.wikipedia.org/wiki/Python_(programming_language))\n",
    "\n",
    "You only need to extract the text from that section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src='images/BS4_3.png' width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tip_: The `p` tag containing the text does not have any attributes. Try looking at the `h3` tag before it, or the `a` child tag. From there, you can start moving around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=https://selenium-python.readthedocs.io/><p align=center><img src=images/selenium_logo.webp width=400></p></a>\n",
    "\n",
    "Selenium is a tool for programmatically controlling a browser. It's originally intended to be used for creating unit tests, but it can also be used to do anything that needs a browser to be controlled. Click the logo to go to the Selenium documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webdriving\n",
    "\n",
    "Selenium can \"drive\" a web browser. This means it can take full control of it and, find elements, click, scroll, execute js etc.\n",
    "\n",
    "You need to specify which browsers this webdriver will drive such as Chrome or Firefox. To drive a browser you need to have the driver installed. We'll use the chrome browser and download it's driver called Chromedriver.\n",
    "\n",
    "We'll have to install chromedriver to drive our chrome browser. You should ensure you have the correct version, which should be the same as the version of chrome which you wish to drive. \n",
    "\n",
    "[Check your chrome version here](https://help.zenplanner.com/hc/en-us/articles/204253654-How-to-Find-Your-Internet-Browser-Version-Number-Google-Chrome)\n",
    "\n",
    "[Download chromedriver from here](https://chromedriver.chromium.org/downloads)\n",
    "\n",
    "If you are using FireFox, you need to download the geckodriver. You can download it from [here](https://github.com/mozilla/geckodriver/releases)\n",
    "\n",
    "If you are using Edge, you need to download the MicrosoftWebDriver. You can download it from [here](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/)\n",
    "\n",
    "If you are using Safari, you can go to your browser, go to `Developer`, and set the \"Allow Remote Automation\" to \"Yes\".\n",
    "\n",
    "Once you download the driver, you can move it to the Python Path. This will make things easier when you have to work in different directories. To move it to the path, you can do the following command:\n",
    "\n",
    "1. Observe your `PATH` environment variable by running `echo $PATH`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my case, this is the PATH I get:\n",
    "<p align=center><img src=images/Path.png></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that Python will look into any of these paths to find the packages, dependencies... and the webdriver to execute selenium. You can tell apart the Paths because they are separated by a colon (:). So, all the paths in this example are:\n",
    "- `/Library/Frameworks/Python.framework/Versions/3.9/bin`\n",
    "- `/opt/miniconda3/bin`\n",
    "- `/opt/miniconda3/condabin`\n",
    "- `/usr/local/bin`\n",
    "- `/usr/bin`\n",
    "- `/bin`\n",
    "- `/usr/sbin`\n",
    "- `/sbin`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Move your driver file to any of the directories in your `PATH` environment variable. For example, if you are using `/usr/local/bin` as your `PATH` environment variable, you can move the driver to `/usr/local/bin` by running `mv chromedriver /usr/local/bin`. Make sure to replace `chromedriver` with the name of your driver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you need to install selenium, run this cell to install it, but make sure you are in the right environment! (In VSCode, if you are using a notebook, look at the top right, and if you are using a script, look at the bottom left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you are ready to use selenium! \n",
    "\n",
    "IMPORTANT! If you are reading this in a Google Colab notebook, you can still use Selenium, but you need to enable the `headless` mode (we will see that later). This essentially means that the browser will not open, and you are not going to see how Selenium is executing all the commands. For the sake of practice, we encourage you to follow these steps in a notebook in your local machine. Once you get more practice, you can start using selenium on the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tree elements within a HTMLElement using XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium finds the elements of a website by looking at its HTML code. You can navigate through this code by using XPaths. \n",
    "\n",
    "Xpath is a query language for selecting nodes/branches/elements within a tree-like data structure like HTML or XML.\n",
    "Below is a very simple xpath expression. This one finds all of the button elements in the html\n",
    "\n",
    "`//button`\n",
    "\n",
    "The `//` says \"anywhere in the tree\" and the button says find elements that have the tag type button. So this xpath expression says \"find button tags anywhere within the tree\"\n",
    "The xpath method of HTMLElement takes in an xpath expression returns a list of all elements in the tree that match it.\n",
    "Below are more examples of how to use xpath:\n",
    "\n",
    "- `/button` find direct children (not all) tags of type button, of the element\n",
    "- `//div/button` - finds all of the button tags inside div tags anywhere on the page\n",
    "- `//div[@id='custom_id']` - finds all div tags with the attribute (@) id equal to custom_id, anywhere on the page\n",
    "\n",
    "If any of these don't make sense, let us know after looking it up.\n",
    "Use the `//button` xpath expression as an argument to find the button on the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a taster, if you want to use selenium to find the element corresponding to the button xpath, you can write it like this:\n",
    "```\n",
    "from selenium import webdriver \n",
    "driver = webdriver.Chrome()\n",
    "driver.find_element_by_xpath('//button')\n",
    "```\n",
    "\n",
    "The first line import the webdriver library that contains the different types of webdriver\n",
    "\n",
    "The second line assign a chromedriver to a variable `driver`. This is the instance that will help us navigate through the HTML code in the website\n",
    "\n",
    "The last line will find the elements in the HTML code that correspond to that XPath. If there is no element with that XPath, selenium will throw an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the browser console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Modern browsers come with tools to maximise web developers productivity and help find bugs.\n",
    "\n",
    "The developer console has a lot of different tools. \n",
    "\n",
    "Open your element inspector by pressing `CTRL + SHIFT + C`.\n",
    "It should open on the right hand side of your screen as shown below.\n",
    "\n",
    "The elements tab of the developer console shows you the HTML and CSS that make up the website code (actually it shows the DOM. Read more about what exactly the DOM is [here](https://css-tricks.com/dom/)).\n",
    "\n",
    "You can always close the developer console by clicking the cross in the corner. \n",
    "\n",
    "Check out the zoopla website for yourself. Try using your selector to see the HTML structure of the page.\n",
    "<p align=center><img src=images/form_selector.png width=600></p>\n",
    "\n",
    "Now use your selector to find the location of the button as shown below.\n",
    "\n",
    "<p align=center><img src=images/button_selector.png width=600></p>\n",
    "\n",
    "As mentioned, the selector allows us to visualise the DOM and find elements within our webpage.\n",
    "\n",
    "\n",
    "### Challenge: How many HTML buttons are there on the homepage? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative XPaths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1> We can find elements, and then search for elements within them! </font>\n",
    "\n",
    "Elements returned from finding them by xpath also have the same search methods. For example, if you have the following HTML code:\n",
    "\n",
    "<p align=center><img src=images/HTML_example.png width=400></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xpath of the highlighted element is `//div[@id=\"__next\"]`. Once again, this xpath means:\n",
    "\n",
    "- `//` indicates that it will look into the whole tree\n",
    "- `div` indicates that it will look only for \"div\" tags\n",
    "- `[]` whatever we write inside, is going to correspond to the attributes of the tag we look for\n",
    "- `[@id=\"__next\"]` means that the tag we look for has an attribute whose value is \"__next\"\n",
    "\n",
    "Thus, the whole xpath means: In the whole tree, find a div tag whose id attribute is equal to \"__next\"\n",
    "\n",
    "So, let's say that we assign that xpath to a variable `my_path`\n",
    "```\n",
    "my_path = driver.find_element_by_xpath('//*[@id=\"__next\"]')\n",
    "```\n",
    "If, after that, we wanted to find the inner \"div\" tag, we don't need to specify the whole xpath. We can refer to `my_path` and start the search from that point. This is also known as \"relative xpath\"\n",
    "\n",
    "To start the search from a certain point, we just need to use a dot (`.`), so, to find the next \"div\" tag, we can write this:\n",
    "```\n",
    "new_path = my_path.find_element_by_xpath('./div')\n",
    "```\n",
    "And that's it!\n",
    "\n",
    "Notice that in this case, we only used a single slash. That means that we are going to look for that element only in the direct children (but not in the grandchildren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond just GETTING static HTML\n",
    "\n",
    "\n",
    "### Why might using requests to get the website content not work?\n",
    "\n",
    "Some elements on webpages are inserted or manipulated by javascript code that runs only after the HTML is rendered.\n",
    "\n",
    "Some information that you want may be shown only after interacting with certain elements.\n",
    "\n",
    "The GET requests to the website just get the HTML file. They don't actually run the javascript code, or interact with the page after it renders. So parsing them for our data won't work.\n",
    "\n",
    "Again, there is a way around this. We can Selenium to take control of a browser that can then be programatically instructed to fill in forms, click elements, and find data on any webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use selenium, we need to create an instance that is going to \"drive\" us through the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://zoopla.co.uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We see that we've navigated to the Zoopla.co.uk website. We can search for elements via `xpath` and can also send mouse and keyboard actions through Selenium as well. Let's recall the challenge we want to solve - extracting data for 50 houses:\n",
    "- **Sale Price**: Our response variable\n",
    "- Number of bedrooms\n",
    "- Square footage\n",
    "- Description\n",
    "- Address\n",
    "\n",
    "We'll focus our efforts just in the London area the next cell will take us to the URL corresponding to properties in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh... Looks like cookies are blocking us... We need to find a way to get around this 🤔. Let's start by using xpath to find the \"Accept All Cookies\" button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: The zoopla website has a frame in the website. The 'Accept Cookies' is in this frame, so we have to tell selenium to access the frame. Usually, if it doesn't have a frame, you can ignore the `switch_to_frame` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b34e9bb16874>:9: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)\n",
    "time.sleep(2) # Wait a couple of seconds, so the website doesn't suspect you are a bot\n",
    "try:\n",
    "    driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except AttributeError: # If you have the latest version of selenium, the code above won't run because the \"switch_to_frame\" is deprecated\n",
    "    driver.switch_to.frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except:\n",
    "    pass # If there is no cookies button, we won't find it, so we can pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, have you seen that? The webdriver went to the website and it clicked the button for us! So, analyze the methods we used:\n",
    "- `find_element_by_xpath()` To make the driver point to the element \n",
    "- `click()` To make the driver click on the element that was pointed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so it is time to start extracting the data we are interested on. Let's extract the price, address, number of bedrooms and the description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, observe the HTML code corresponding to a property:\n",
    "<p align=center><img src=images/Selenium_1.png width=900></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get the XPath of that property, it will look like this:\n",
    "\n",
    "`//*[@id=\"listing_60212639\"]`\n",
    "\n",
    "Which is fine if we want to find a single property, but not so great if we want to list all the properties in that page. We will focus on how to get all the properties shortly, for now, let's extract the URL of that property, and extract the information we need. \n",
    "\n",
    "__IMPORTANT! Zoopa is constantly adding new properties, it is likely that the Xpath changed, so make sure that you are following all the steps and using the correct XPath__\n",
    "\n",
    "Let's take a look again at the HTML code, you will notice that there are some `<a>` tags in the HTML code. Usually, these tags are used to include a hyper reference (`href`). Selenium allows us to get that href, but first we need to locate the `<a>` tag containing the href.\n",
    "\n",
    "So, if you expand one of the `<div>` tags corresponding to a property, you will see something like this:\n",
    "\n",
    "<p align=center><img src=images/Selenium_2.png width=900></p>\n",
    "\n",
    "Can you see the `<a>` tag? That is the tag that contains the URL we need. So, let's tell selenium to extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-08ba0b8dd794>:9: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zoopla.co.uk/new-homes/details/60212639/\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)\n",
    "time.sleep(2) # Wait a couple of seconds, so the website doesn't suspect you are a bot\n",
    "try:\n",
    "    driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except AttributeError: # If you have the latest version of selenium, the code above won't run because the \"switch_to_frame\" is deprecated\n",
    "    driver.switch_to.frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except:\n",
    "    pass\n",
    "time.sleep(2)\n",
    "property = driver.find_element_by_xpath('//*[@id=\"listing_60212639\"]') # Change this xpath with the xpath the current page has in their properties\n",
    "a_tag = property.find_element_by_tag_name('a')\n",
    "link = a_tag.get_attribute('href')\n",
    "print(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we can visit that link using selenium. Alternatively, you can also click on the `property` element (`property.click()`) and it will take you to the same page. But you will have to:\n",
    "- Click the element\n",
    "- Sleep\n",
    "- Extract the information\n",
    "- Go back\n",
    "- Sleep\n",
    "- Find the next property \n",
    "- Click\n",
    "- Sleep\n",
    "\n",
    "On the other hand, if you have the links, you can visit them like this:\n",
    "\n",
    "- Extract all the links\n",
    "- Iterate through the list, and for each iteration, visit the corresponding URL\n",
    "- Sleep\n",
    "- Extract the information of the property\n",
    "- Visit the next URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's up to you, but for many different websites, creating a list with links (which is usually called \"crawler\"), is much more efficient\n",
    "\n",
    "Enough talking (or writing), let's visit the link we extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it moved us to the webpage of that property\n",
    "\n",
    "<p align=center><img src=images/Selenium_3.png width=900></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, you can see the price, address, number of bedrooms, and the description. As always, let's take a look at the XPath corresponding to each property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center><img src=images/Selenium_4.png width=900></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is, if you do the same with the number of bedrooms, the address and the desciption, you should have something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£7,750,000\n",
      "West Heath Avenue, Hampstead, London NW11\n",
      "6 beds\n",
      "A striking contemporary home with an abundance of light and space.\n",
      "\n",
      "Location\n",
      "\n",
      "The property is ideally situated for public transport and the national road network. Golders Green Underground Station (Northern Line) and Bus Terminus is just 400 metres walk, whilst there is easy road access to Brent Cross Shopping Centre, the A406 North Circular Road, the A41/A1 arterial route and junction 1 of the M1 Motorway.\n",
      "\n",
      "Golders Hill Park is within 160 metres walk and offers beautiful plant displays, enhancing the peaceful setting of the Mediterranean and water gardens, while the park houses a popular café. There are also a variety of leisure facilities including tennis courts, croquet lawn, golf practice nets, butterfly house and a children's play area. In the park is also a free zoo, with a growing collection of rare and exotic birds and mammals such as laughing kookaburras, ring-tailed lemurs and ring-tailed coatis.\n",
      "\n",
      "\n",
      "\n",
      "A striking home set back behind gates and frontage. The property is full of natural light due to clever and inventive use of glazing and fenestration. The internal space is extremely flexible and not only offers 6 bedrooms with en suite bathrooms, there is also the ability to arrange two studies to suit working from home, as is more common place nowadays. The garden is extremely private and the garage holds two large or 3 smaller cars and the carriage drive could carry up to 4-5 cars.\n",
      "\n",
      "Square Footage: 7008 sq ft\n",
      "\n",
      "Acreage: 0.14 Acres\n"
     ]
    }
   ],
   "source": [
    "price = driver.find_element_by_xpath('//span[@data-testid=\"price\"]').text\n",
    "print(price)\n",
    "address = driver.find_element_by_xpath('//span[@data-testid=\"address-label\"]').text\n",
    "print(address)\n",
    "bedrooms = driver.find_element_by_xpath('//span[@data-testid=\"beds-label\"]').text\n",
    "print(bedrooms)\n",
    "div_tag = driver.find_element_by_xpath('//div[@data-testid=\"truncated_text_container\"]')\n",
    "span_tag = div_tag.find_element_by_xpath('.//span')\n",
    "description = span_tag.text\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a button, we can send a click action to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_properties = {'Price': [], 'Address': [], 'Bedrooms': [], 'Description': []}\n",
    "price = driver.find_element_by_xpath('//span[@data-testid=\"price\"]').text\n",
    "dict_properties['Price'].append(price)\n",
    "address = driver.find_element_by_xpath('//span[@data-testid=\"address-label\"]').text\n",
    "dict_properties['Address'].append(address)\n",
    "bedrooms = driver.find_element_by_xpath('//span[@data-testid=\"beds-label\"]').text\n",
    "dict_properties['Bedrooms'].append(bedrooms)\n",
    "div_tag = driver.find_element_by_xpath('//div[@data-testid=\"truncated_text_container\"]')\n",
    "span_tag = div_tag.find_element_by_xpath('.//span')\n",
    "description = span_tag.text\n",
    "dict_properties['Description'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Price': ['£7,750,000'],\n",
       " 'Address': ['West Heath Avenue, Hampstead, London NW11'],\n",
       " 'Bedrooms': ['6 beds'],\n",
       " 'Description': \"A striking contemporary home with an abundance of light and space.\\n\\nLocation\\n\\nThe property is ideally situated for public transport and the national road network. Golders Green Underground Station (Northern Line) and Bus Terminus is just 400 metres walk, whilst there is easy road access to Brent Cross Shopping Centre, the A406 North Circular Road, the A41/A1 arterial route and junction 1 of the M1 Motorway.\\n\\nGolders Hill Park is within 160 metres walk and offers beautiful plant displays, enhancing the peaceful setting of the Mediterranean and water gardens, while the park houses a popular café. There are also a variety of leisure facilities including tennis courts, croquet lawn, golf practice nets, butterfly house and a children's play area. In the park is also a free zoo, with a growing collection of rare and exotic birds and mammals such as laughing kookaburras, ring-tailed lemurs and ring-tailed coatis.\\n\\n\\n\\nA striking home set back behind gates and frontage. The property is full of natural light due to clever and inventive use of glazing and fenestration. The internal space is extremely flexible and not only offers 6 bedrooms with en suite bathrooms, there is also the ability to arrange two studies to suit working from home, as is more common place nowadays. The garden is extremely private and the garage holds two large or 3 smaller cars and the carriage drive could carry up to 4-5 cars.\\n\\nSquare Footage: 7008 sq ft\\n\\nAcreage: 0.14 Acres\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding links to a list: Creating a Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, it would be more efficient to create a list with all the links and then iterate through that list. Here, I am going to give a small teaser of what it looks like, but, ultimately, it will be your task to complete the whole scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, I am going to create a list with the accept cookies functionality, so we don't have to repeat myself so many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def load_and_accept_cookies() -> webdriver.Chrome:\n",
    "    '''\n",
    "    Open Zoopla and accept the cookies\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    driver: webdriver.Chrome\n",
    "        This driver is already in the Zoopla webpage\n",
    "    '''\n",
    "    driver = webdriver.Chrome() \n",
    "    URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "    driver.get(URL)\n",
    "    time.sleep(3) \n",
    "    try:\n",
    "        driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n",
    "        accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "        accept_cookies_button.click()\n",
    "        time.sleep(1)\n",
    "    except AttributeError: # If you have the latest version of selenium, the code above won't run because the \"switch_to_frame\" is deprecated\n",
    "        driver.switch_to.frame('gdpr-consent-notice') # This is the id of the frame\n",
    "        accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "        accept_cookies_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return driver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, let's use this function from now on, it will make our code much more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-502712965682>:18: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n"
     ]
    }
   ],
   "source": [
    "driver = load_and_accept_cookies() # In case it works, driver should be in the Zoopla webpage with the cookies button clicked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's observe the list of properties one more time. All the properties are in a container as we can see in this image:\n",
    "\n",
    "<p align=center><img src=images/Selenium_5.png width=900></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, each property is one `<div>` tag inside that container. For example, for the two first properties:\n",
    "\n",
    "<p align=center><img src=images/Selenium_7.png width=450><img src=images/Selenium_6.png width=450></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can find a way to iterate through ALL the properties in that list, and for each iteration, extract the link. We saw earlier that if you have the property, you can easily find the `<a>` tag that contains the `href` like this:\n",
    "```\n",
    "property = driver.find_element_by_xpath('//*[@id=\"listing_60212639\"]') # Change this xpath with the xpath the current page has in their properties\n",
    "a_tag = property.find_element_by_tag_name('a')\n",
    "link = a_tag.get_attribute('href')\n",
    "```\n",
    "Let's use something similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-502712965682>:18: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n"
     ]
    }
   ],
   "source": [
    "driver = load_and_accept_cookies()\n",
    "prop_container = driver.find_element_by_xpath('//*[@class=\"css-1anhqz4-ListingsContainer earci3d2\"]') # XPath corresponding to the Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `prop_container` is pointing to the list of properties in the website. We have to get ALL the `<div>` tags inside, but only those that are direct children. So, we have to use a relative xpath: `./div`\n",
    "- The dot represents that it is relative\n",
    "- The single slash represents direct children\n",
    "\n",
    "Also, take into account that we are looking for ALL occurence of this XPath, so we have to use the `find_elementS_by_xpath` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 properties in this page\n",
      "['https://www.zoopla.co.uk/new-homes/details/60214186/', 'https://www.zoopla.co.uk/new-homes/details/60214076/', 'https://www.zoopla.co.uk/new-homes/details/60213997/', 'https://www.zoopla.co.uk/new-homes/details/60213955/', 'https://www.zoopla.co.uk/new-homes/details/60213931/', 'https://www.zoopla.co.uk/new-homes/details/60213891/', 'https://www.zoopla.co.uk/new-homes/details/60213807/', 'https://www.zoopla.co.uk/new-homes/details/60213785/', 'https://www.zoopla.co.uk/new-homes/details/60213797/', 'https://www.zoopla.co.uk/new-homes/details/60213732/', 'https://www.zoopla.co.uk/new-homes/details/60213753/', 'https://www.zoopla.co.uk/new-homes/details/60213127/', 'https://www.zoopla.co.uk/new-homes/details/60213083/', 'https://www.zoopla.co.uk/new-homes/details/60213079/', 'https://www.zoopla.co.uk/new-homes/details/60212733/', 'https://www.zoopla.co.uk/new-homes/details/59458212/', 'https://www.zoopla.co.uk/new-homes/details/60212693/', 'https://www.zoopla.co.uk/new-homes/details/60212694/', 'https://www.zoopla.co.uk/new-homes/details/60212639/', 'https://www.zoopla.co.uk/new-homes/details/60212515/', 'https://www.zoopla.co.uk/new-homes/details/60212506/', 'https://www.zoopla.co.uk/new-homes/details/60209645/', 'https://www.zoopla.co.uk/new-homes/details/60208286/', 'https://www.zoopla.co.uk/new-homes/details/60208260/', 'https://www.zoopla.co.uk/new-homes/details/60208251/']\n"
     ]
    }
   ],
   "source": [
    "prop_list = prop_container.find_elements_by_xpath('./div')\n",
    "link_list = []\n",
    "\n",
    "for property in prop_list:\n",
    "    a_tag = property.find_element_by_tag_name('a')\n",
    "    link = a_tag.get_attribute('href')\n",
    "    link_list.append(link)\n",
    "    \n",
    "print(f'There are {len(link_list)} properties in this page')\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of the links of the properties in that page. How awesome is that?\n",
    "\n",
    "Next, we need to iterate through this list and start visiting each link to extract the data we were interested on (Price, Address, Number of Bedroom, Description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "This will finish the Zoopla practical that you have in the Portal. \n",
    "\n",
    "With the new acquired knowledge, extract the data from all the properties in 5 different Zoopla pages. This means that, once you finish scraping a page, you have to click the 'Next Page' button (you can also change the URL if you know how to tweak it). So, once you extract the 25 links, you can go to the next page by clicking 'Next':\n",
    "\n",
    "<p align=center><img src=images/Selenium_8.png width=450></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included a template you can use to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-c78b1fbe20c4>:18: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "def get_links(driver: webdriver.Chrome) -> list:\n",
    "    '''\n",
    "    Returns a list with all the links in the current page\n",
    "    Parameters\n",
    "    ----------\n",
    "    driver: webdriver.Chrome\n",
    "        The driver that contains information about the current page\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    link_list: list\n",
    "        A list with all the links in the page\n",
    "    '''\n",
    "\n",
    "    prop_container = driver.find_element_by_xpath('//*[@class=\"css-1anhqz4-ListingsContainer earci3d2\"]')\n",
    "    prop_list = prop_container.find_elements_by_xpath('./div')\n",
    "    link_list = []\n",
    "\n",
    "    for property in prop_list:\n",
    "        a_tag = property.find_element_by_tag_name('a')\n",
    "        link = a_tag.get_attribute('href')\n",
    "        link_list.append(link)\n",
    "\n",
    "    return link_list\n",
    "\n",
    "big_list = []\n",
    "driver = load_and_accept_cookies()\n",
    "\n",
    "for i in range(5): # The first 5 pages only\n",
    "    big_list.extend(get_links(driver)) # Call the function we just created and extend the big list with the returned list\n",
    "    ## TODO: Click the next button. Don't forget to use sleeps, so the website doesn't suspect\n",
    "    pass # This pass should be removed once the code is complete\n",
    "\n",
    "\n",
    "for link in big_list:\n",
    "    ## TODO: Visit all the links, and extract the data. Don't forget to use sleeps, so the website doesn't suspect\n",
    "    pass # This pass should be removed once the code is complete\n",
    "\n",
    "driver.quit() # Close the browser when you finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find a problem, use the 'Get Support' button in the portal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Navigating using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium will allow us to do many other things, such as scroll, click, and send keystrokes. For example, you can run the following cells one by one and observe the results.\n",
    "\n",
    "Let's see how to scroll down a page using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.python.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are in the official Python Webpage, let's scroll down to the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will look for the search bar and click it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_xpath('//*[@id=\"id-search-field\"]')\n",
    "search_bar.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you clicked it, you can send a keystroke to the search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(\"method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once you enter the text, you can 'Press Enter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you need to perform an action in Selenium, just think, what steps are you doing as a human being? If you can explain it with words, Selenium probably can do it, just look at the documentation, or google it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Make Selenium wait for an element to appear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On many ocassions, you will need for an element to appear to scrape it. As mentioned above, many websites are dynamic, meaning that its whole content is not available right after connecting to it. If that is the case, Selenium will try to find elements before the whole page is loaded, and therefore the scraper might fail if the element is not ready.\n",
    "\n",
    "To solve this problem, you can tell selenium to wait until the element you want to scrape appears. For example, in the Zoopla challenge, the frame containing the \"Accept Cookies\" button will not appear immediately, that is why we added a `time.sleep(3)` after telling the driver to get to that website:\n",
    "```\n",
    "    driver = webdriver.Chrome() \n",
    "    URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "    driver.get(URL)\n",
    "    time.sleep(3) \n",
    "    try:\n",
    "        driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n",
    "        accept_cookies_button = driver.find_element_by_xpath('//*[@id=\"save\"]')\n",
    "        accept_cookies_button.click()\n",
    "    ...\n",
    "```\n",
    "\n",
    "However, depending on the server and the user connection that number of seconds might vary. So, instead of using an arbitrary number like `3`, we might want to tell Selenium: \"Wait until this frame shows up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium has many capabilities, and luckily, one of them allows us to implement this functionality. Let's take a look at how to do so:\n",
    "\n",
    "First, let's import the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement it on the code we had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_accept_cookies() -> webdriver.Chrome:\n",
    "    '''\n",
    "    Open Zoopla and accept the cookies\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    driver: webdriver.Chrome\n",
    "        This driver is already in the Zoopla webpage\n",
    "    '''\n",
    "    driver = webdriver.Chrome() \n",
    "    URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "    driver.get(URL)\n",
    "    delay = 10\n",
    "    try:\n",
    "        WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"gdpr-consent-notice\"]')))\n",
    "        print(\"Frame Ready!\")\n",
    "        driver.switch_to.frame('gdpr-consent-notice')\n",
    "        accept_cookies_button = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"save\"]')))\n",
    "        print(\"Accept Cookies Button Ready!\")\n",
    "        accept_cookies_button.click()\n",
    "        time.sleep(1)\n",
    "    except TimeoutException:\n",
    "        print(\"Loading took too much time!\")\n",
    "\n",
    "    return driver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's happening here?\n",
    "\n",
    "1. As always, we define the driver and tell it to visit the URL\n",
    "```\n",
    "driver = webdriver.Chrome() \n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)\n",
    "```\n",
    "2. We set a variable named delay, which is the maximum time we allow selenium to wait.\n",
    "```\n",
    "delay = 10\n",
    "```\n",
    "3. Then, we use the WebDriverWait class to tell the driver to way a maximum of 10 seconds. Within those 10 seconds, if the element corresponding to the XPath whose value is `'//*[@id=\"gdpr-consent-notice\"]'` (which corresponds to the frame) appears, then, stop waiting, ans keep running the code.\n",
    "```\n",
    "WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"gdpr-consent-notice\"]')))\n",
    "```\n",
    "4. If the element appears before 10 seconds, we just go with the regular code to click the button. This code in turn has another WebDriverWait just in case the button appears after switching to frame\n",
    "```\n",
    "print(\"Frame Ready!\")\n",
    "driver.switch_to.frame('gdpr-consent-notice')\n",
    "accept_cookies_button = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"save\"]')))\n",
    "print(\"Accept Cookies Button Ready!\")\n",
    "accept_cookies_button.click()\n",
    "time.sleep(1)\n",
    "```\n",
    "5. However, if the element doesn't show up in less than 10 seconds, selenium throws a `TimeoutException` error, and the `except` clause is triggered\n",
    "```\n",
    "except TimeoutException:\n",
    "    print(\"Loading took too much time!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Ready!\n"
     ]
    }
   ],
   "source": [
    "driver = load_and_accept_cookies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Thanks to this, we don't have to worry about setting an arbitrary number of seconds to wait"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
