{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Testing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> ML models are only useful if they can __generalise__ and make good predictions on unseen data.\n",
    "\n",
    "To estimate the performance of a model on unseen data, the initial dataset is usually split into two sets: one for training and the other for testing.\n",
    "\n",
    "## The Test Set\n",
    "\n",
    "> The test set is used for evaluating if a model meets the desired requirements and for estimating its real-world performance. It is not employed for making choices about the model.\n",
    "\n",
    "To estimate how well a model will perform on unseen data, we split our initial dataset into two different sets. One is for training on, and the other is for testing on.\n",
    "\n",
    "> The testing set is used for evaluating whether a model meets our requirements and estimating real world performance. That is all. It is not for making choices about our model.\n",
    "\n",
    "Sklearn provides a method `train_test_split()` in it's `model_selection` module to split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(X)}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(\"Number of samples in:\")\n",
    "print(f\"    Training: {len(y_train)}\")\n",
    "print(f\"    Testing: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Validation Set\n",
    "\n",
    "The decision to choose between two models cannot be based on the testing set. If that were the case, the decisions would be biased, leaning towards our expectations. \n",
    "\n",
    "Making a decision based on the testing set is analogous to seeing the answers on a test.\n",
    "\n",
    "Instead, we create another set, called the __validation set__. This set is used for comparing models or different options for the same model, and the process is referred to as __cross validation.__\n",
    "\n",
    "> We make the validation set by further splitting the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_validation, y_test, y_validation = train_test_split(\n",
    "    X_test, y_test, test_size=0.3\n",
    ")\n",
    "\n",
    "print(\"Number of samples in:\")\n",
    "print(f\"    Training: {len(y_train)}\")\n",
    "print(f\"    Validation: {len(y_validation)}\")\n",
    "print(f\"    Testing: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation vs Test Sets\n",
    "\n",
    "People commonly misunderstand the difference between the validation set and the test set.\n",
    "\n",
    "The difference is that the validation set, not the test set, is employed to make choices about models.\n",
    "\n",
    "Such choices may include the following:\n",
    "\n",
    "- Should I deploy the linear regression model or the neural network?\n",
    "- Should I use the model which was trained on all the features of just the three I selected?\n",
    "- Which hyperparameters should I select (which you will learn about shortly)?\n",
    "\n",
    "Let's see that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ML algorithms you will later know, don't panic\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "models = [\n",
    "    DecisionTreeRegressor(splitter=\"random\"),\n",
    "    SVR(),\n",
    "    LinearRegression()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_validation_pred = model.predict(X_validation)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "    validation_loss = mean_squared_error(y_validation, y_validation_pred)\n",
    "    test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    print(\n",
    "        f\"{model.__class__.__name__}: \"\n",
    "        f\"Train Loss: {train_loss} | Validation Loss: {validation_loss} | \"\n",
    "        f\"Test Loss: {test_loss}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "As you can observe, the best validation loss is for linear regression. This is the model we should choose. Unfortunately, it occurs that on 'real' (test) data, it performs worse than the Decision Tree.\n",
    "\n",
    "Once again: usually we won't have information from test loss, but now you should know this technique is imperfect (we will see how to mitigate those effects later on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding\n",
    "\n",
    "In the code above, note the following line: `np.random.seed(2)`. This code line is important, and its role will be covered here.\n",
    "\n",
    "### Pseudo-random number generators\n",
    "\n",
    "Many ML algorithms employ random initialisation to, for example, instantiate the parameters of a linear regression model. Depending on the algorithm, it may have a more- or less-severe effect on the result.\n",
    "\n",
    "- Each time you run an algorithm randomly, the result may vary to some degree.\n",
    "- Random number generators employ a `seed`, which is a numerical value that determines what values will be generated.\n",
    "- For each run to be the same, (or to exhibit some phenomena similar to the case above), we should __always__ seed all functions using random numbers.\n",
    "\n",
    "The last one is quite easy in `numpy` and `sklearn` as it is a single line. Seeding via this approach is common in most frameworks.\n",
    "\n",
    "### Benefits of seed initialisation\n",
    "\n",
    "- To ensure the reproducibility of experiments, which is particularly important in ML.\n",
    "- To ensure an equal outcome for all runs.\n",
    "\n",
    "> Always set a random seed to make sure your results are repeatable when some part of the code involves random numbers being generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Leakage\n",
    "\n",
    "__Data leakage__ refers to a situation where a model has access to information about the testing sets. Definitely, in the real world, when working with new examples, the model will not know anything about the incoming data. This means that in training, the separation must be carefully preserved.\n",
    "\n",
    "> Never make any decisions about your model design using the test set.\n",
    "\n",
    "### Causes\n",
    "\n",
    "Data leakage can be caused by bad data splitting. These include the following cases:\n",
    "- Some samples are both in training and validation.\n",
    "- The model is evaluated based on its performance on the training data.\n",
    "\n",
    "Let's see an example in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(X_train, y_train, X_validation, y_validation):\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Without data leakage, train on train, validate on validation\n",
    "    model.fit(X_train, y_train)\n",
    "    y_validation_pred = model.predict(X_validation)\n",
    "    validation_loss = mean_squared_error(y_validation, y_validation_pred)\n",
    "\n",
    "    print(f\"Validation loss: {validation_loss}\")\n",
    "    \n",
    "# Without data leakage, train on train, validate on validation\n",
    "calculate_validation_loss(X_train, y_train, X_validation, y_validation)\n",
    "\n",
    "# With data leakage, 50 samples from validation added\n",
    "fail_X_train = np.concatenate((X_train, X_validation[:50]))\n",
    "fail_y_train = np.concatenate((y_train, y_validation[:50]))\n",
    "\n",
    "calculate_validation_loss(fail_X_train, fail_y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, as the model saw part of validation data and it __falsely__ performs better on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of\n",
    "\n",
    "- Validation set is used to find info about best algorithms, best set of arguments to algoirthms etc.\n",
    "- Test set is used to check how our algorithm performs on unseen data\n",
    "- __As we tune algorithms according to `validation` dataset we cannot use it to check performance__\n",
    "- `seed` is used to ensure reproducibility. Also multiple runs for experiments are good if our code depends on random initialization heavily (we can take mean results of experiments)\n",
    "- Data leakage is information from `validation` (or `test`) leaking into training\n",
    "- Data leakage leads to falsely good results and should be avoided\n",
    "- Rule of thumb: imagine you only have training dataset when doing preprocessing. Anything you calculate from it cannot be used in `validation` or `test`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06c1e258a470a687113bfba03f207c092b27379067ada2d83b8b31269ab641fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
