{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aecd92",
   "metadata": {},
   "source": [
    "# Querying\n",
    "\n",
    "> __Prometheus has a lot of querying capabilities (including it's own PromQL language!) which we will learn about today__\n",
    "\n",
    "- __Please start an instance of `node` & some docker containers Prometheus server (inside docker container) just like we did in previous lesson!__\n",
    "- __Go to `localhost:9090` to have query/expression prompt__ \n",
    "\n",
    "\n",
    "## Data types\n",
    "\n",
    "Only one of the four listed below are allowed:\n",
    "- `float64` (any scalar is a `float`!)\n",
    "- `string` (unused by `prometheus` currently)\n",
    "- __instant vectors__\n",
    "- __range vectors__\n",
    "\n",
    "## Instant Vector selectors\n",
    "\n",
    "> __Instant vectors are created via SELECTION based on some matching patterns (labels, metric names etc.)__\n",
    "\n",
    "__Easiest form is a simple `metric` name statement returning vector of values.__\n",
    "\n",
    "Try typing this in the expressions field on your Prometheus dashboard. Some of these metrics might appear differently depending on your operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b838fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cpu_seconds_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows \n",
    "windows_cpu_time_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15030a13",
   "metadata": {},
   "source": [
    "![](images/prometheus_vector_dtype_basic.png)\n",
    "\n",
    "We can further filter the metric by specific labels, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cpu_seconds_total{cpu=~\"0|1\", instance!=\"localhost:8081\", mode=\"user\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e028ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on windows\n",
    "windows_cpu_time_total{core=~\"0,0|0,1\", job=\"wmiexporter\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eed5f3",
   "metadata": {},
   "source": [
    "![](images/prometheus_node_query_matching.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9c1c9",
   "metadata": {},
   "source": [
    "### Matching\n",
    "\n",
    "> Prometheus supports different comparison operators __and regex matching__ (via [Google's RE2 syntax](https://github.com/google/re2/wiki/Syntax))\n",
    "\n",
    "__Comparison:__\n",
    "- `=` - labels which are equal to\n",
    "- `!=` - labels which __are not__ equal to\n",
    "- `=~` - labels which __regex match__ string\n",
    "- `!~` - labels which __regex UNmatch__ string\n",
    "\n",
    "Other than that, regex matching works pretty similar to how it usually does (check out specification linked above if in doubt).\n",
    "\n",
    "### __name__\n",
    "\n",
    "Similar to Python's `__name__` Prometheus also provides this `label` as an internal one. __It allows us to match on expressions__, for example:\n",
    "\n",
    "A quick way to match strings is using the `\".*\"` expression, the `.` signifies matching any character and the `*` signifies matching any number of characters afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "{__name__=~\"node.*_seconds\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{__name__=~\"windows.*_time_.*\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68073d87",
   "metadata": {},
   "source": [
    "![](images/prometheus_name_match.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376616b",
   "metadata": {},
   "source": [
    "One thing you have to keep in mind:\n",
    "\n",
    "> __Regex matching HAS TO MATCH something, YOUR EXPRESSION HAS TO BE VALID__\n",
    "\n",
    "\n",
    "For example (label matching every job __AND EMPTY JOB ALSO__ where job starts with wmi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "{job=~\"wmi.*\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1683c3f",
   "metadata": {},
   "source": [
    "While the `+` here will match any job that doesn't have an empty string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{job=~\".+\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67595f17",
   "metadata": {},
   "source": [
    "## Range vector selectors\n",
    "\n",
    "> __Range vectors are created by slicing timeseries based on time duration__\n",
    "\n",
    "Previously we used `{}` for instant selectors, time time we will use `[]`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cpu_seconds_total{cpu=~\"0|1\", mode=\"idle\"}[20s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "windows_cpu_time_total{core=~\"0,.*|0,.*\", job=\"wmiexporter\"}[20s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15812bb5",
   "metadata": {},
   "source": [
    "> Range vector __CANNOT BE GRAPHED__ (we have to transform them to instant vectors via some function) __BECAUSE THEY HAVE MULTIPLE VALUES FOR A SINGLE TIMESTAMP__\n",
    "\n",
    "![](images/prometheus_range_selector.png)\n",
    "\n",
    "We can see that __now we have a multidimensionally aggregated data__:\n",
    "- We get `4` values for each timeseries\n",
    "- `4` values for `20s` range __because data is scrapped every `5s`__\n",
    "\n",
    "Given that, we can perform some kind of operation on grouped data.\n",
    "\n",
    "To plot the above, we can summarize the data, for example using the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate(node_cpu_seconds_total{cpu=~\"0|1\", mode=\"idle\"}[5m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdafa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate(windows_cpu_time_total{core=~\"0,.*|0,.*\", mode=\"idle\"}[5m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc513f",
   "metadata": {},
   "source": [
    "![](images/prometheus_range_rate_cpus.png)\n",
    "\n",
    "There are a few available time units for our usage:\n",
    "\n",
    "- `ms` - milliseconds\n",
    "- `s` - seconds\n",
    "- `m` - minutes\n",
    "- `h` - hours\n",
    "- `d` - days - assuming a day has always 24h\n",
    "- `w` - weeks - assuming a week has always 7d\n",
    "- `y` - years - assuming a year has always 365d\n",
    "\n",
    "> One can mix the above __but they have to be ordered from largest to smallest unit__\n",
    "\n",
    "For example:\n",
    "- `1h30m`\n",
    "- `2d3h15m10s7ms`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcaa18e",
   "metadata": {},
   "source": [
    "### Offsets\n",
    "\n",
    "> __Offsets allow us to jump to specified point in time__\n",
    "\n",
    "For example, query below could return `5` minute rate of `http_requests` we had `1` week ago:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57832633",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate(http_requests_total[5m] offset 1w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843af46",
   "metadata": {},
   "source": [
    "## Operators\n",
    "\n",
    "> __Prometheus's language (PromQL) provides standard set of operators (logical, arithmetical etc.)__\n",
    "\n",
    "| Arithmetic        | Comparison          | Logical  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| + | == | and |\n",
    "| - | != | or |\n",
    "| / | > | unless (complement) |\n",
    "| \\% | <  | |\n",
    "| ^ | >=  | |\n",
    "|  | <=   | |\n",
    "\n",
    "\n",
    "Those follow standard broadcasting rules between scalars and vectors we already know from `numpy` or `pytorch`, __except matching between two `instant vectors`__: \n",
    "\n",
    "## Vector matching\n",
    "\n",
    "> Vector matching defines one `instant vector` can be matched to another one\n",
    "\n",
    "### One-to-one\n",
    "\n",
    "> One to one finds a unique pair of entries from each side of the operation.\n",
    "\n",
    "Here are the governing rules:\n",
    "- exact same set of labels\n",
    "- value types have to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf40643",
   "metadata": {},
   "outputs": [],
   "source": [
    "<vector expr> <op> ignoring(<label list>) <vector expr>\r\n",
    "<vector expr> <op> on(<label list>) <vector expr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa79e76",
   "metadata": {},
   "source": [
    "- __ignoring__ allows us to ignore label(s)\n",
    "- __on__ allows us to specify labels\n",
    "\n",
    "Let's assume we have the following two groups of timeseries:\n",
    "- `method_code:http_errors:rate5m` - `5m` rate of `http_errors` and their specific `code`\n",
    "- `method:http_requests:rate5m` - `5m` rate of `http_errors` for specific method\n",
    "\n",
    "Now, for specific `instant selectors` we might have (example values at a given timestamp are commented out on the right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bd692",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_code:http_errors:rate5m{method=\"get\", code=\"500\"}  # 24\r\n",
    "method_code:http_errors:rate5m{method=\"get\", code=\"404\"}  # 30\r\n",
    "method_code:http_errors:rate5m{method=\"put\", code=\"501\"}  # 3\r\n",
    "method_code:http_errors:rate5m{method=\"post\", code=\"500\"} # 6\r\n",
    "method_code:http_errors:rate5m{method=\"post\", code=\"404\"} # 21\r\n",
    "\r\n",
    "method:http_requests:rate5m{method=\"get\"}  # 600\r\n",
    "method:http_requests:rate5m{method=\"del\"}  # 34\r\n",
    "method:http_requests:rate5m{method=\"post\"} # 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaef5e5",
   "metadata": {},
   "source": [
    "Now, let's see what is the ratio of failed requests with `code=500` (internal server error rate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_code:http_errors:rate5m{code=\"500\"} / ignoring(code) method:http_requests:rate5m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d3ce4",
   "metadata": {},
   "source": [
    "This would match:\n",
    "- `method_code:http_errors:rate5m{method=\"get\", code=\"500\"}` with `method:http_requests:rate5m{method=\"get\"} ` (notice labels match, code doesn't __but we are ignoring it__), returning value `24 / 600 = 0.04`\n",
    "- `method_code:http_errors:rate5m{method=\"post\", code=\"500\"}` with `method:http_requests:rate5m{method=\"post\"} ` - same thing as above, returning value `6 / 120 = 0.05`\n",
    "\n",
    "Hence we would obtain two `instant vectors` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f31a9",
   "metadata": {},
   "source": [
    "### Many-to-one & one-to-many\n",
    "\n",
    "> __Each vector element on the \"one\"-side can match with multiple elements on the \"many\"-side.__\n",
    "\n",
    "This use case is advanced and given as an __mandatory__ exercise.\n",
    "\n",
    "__Note:__ You should use this approach only when absolutely necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3a0bc",
   "metadata": {},
   "source": [
    "## Aggregation operations\n",
    "\n",
    "> Prometheus provides basic operations for data aggregation\n",
    "\n",
    "Full list:\n",
    "\n",
    "- `sum` - calculate sum over dimensions\n",
    "- `min` - select minimum over dimensions\n",
    "- `max` - select maximum over dimensions\n",
    "- `avg` - calculate the average over dimensions\n",
    "- `group` - all values in the resulting vector are 1\n",
    "- `stddev` - calculate population standard deviation over dimensions\n",
    "- `stdvar` - calculate population standard variance over dimensions\n",
    "- `count` - count number of elements in the vector\n",
    "- `count_values` - count number of elements with the same value\n",
    "- `bottomk` - smallest k elements by sample value\n",
    "- `topk` - largest k elements by sample value\n",
    "- `quantile` - calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions\n",
    "\n",
    "Simplest form is:\n",
    "\n",
    "```\n",
    "<op>(<vector_expression>)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(node_cpu_scaling_frequency_hertz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77777424",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(windows_cpu_core_frequency_mhz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0598d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T16:07:04.540057Z",
     "start_time": "2021-04-17T16:07:04.436095Z"
    }
   },
   "source": [
    "![](images/prometheus_op_simple.png)\n",
    "\n",
    "In this case __minimum value for each timestep is taken across ALL OF THE LABELS__.\n",
    "\n",
    "To specify labels (dimensions) should the operation be run across, we have two modifiers:\n",
    "- `by` - specifies __by which label(s) the `min` is taken__ (all unspecified will be \"flattened\")\n",
    "- `without` - specifies __without which label(s) the `min` is taken__ (all specified will be \"flattened\")\n",
    "\n",
    "Their syntax is as folows:\n",
    "\n",
    "```\n",
    "<op> by (<label>) (<vector_expression>)\n",
    "```\n",
    "\n",
    "or:\n",
    "\n",
    "```\n",
    "<op> without (<label>) (<vector_expression>)\n",
    "```\n",
    "\n",
    "`min` taken for each `cpu` separately would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "min by (cpu) (node_cpu_scaling_frequency_hertz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b1e55",
   "metadata": {},
   "source": [
    "min by (core) (windows_cpu_core_frequency_mhz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2202e",
   "metadata": {},
   "source": [
    "![](images/prometheus_op_by.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84db38",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "> __Prometheus provides a set of functions one can use (full list [here](https://prometheus.io/docs/prometheus/latest/querying/functions/))__\n",
    "\n",
    "Currently this set is a little limited __and you cannot add your own new functions__ (at least without forking `prometheus` project).\n",
    "\n",
    "- Standard rules apply (e.g. some function have default arguments)\n",
    "- Some operate on range vectors, while others on instant vectors\n",
    "\n",
    "Here are some groups of functions:\n",
    "- `date` related (`minute`, `month`, `year`, `timestamp`, `day_of_month` etc.)\n",
    "- `math` related (`ln`, `exp`, `deriv`, `round`, `sgn` etc.)\n",
    "- `timeseries` related (`delta` (difference between consecutive values), `idelta` etc.)\n",
    "\n",
    "Below are a few examples with descriptions as comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d901f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T19:18:02.553046Z",
     "start_time": "2021-04-17T19:18:02.293568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: syntax error near unexpected token `node_hwmon_temp_celsius[10m]'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Monitored hardware temperature difference of `10m` intervals\n",
    "# First and last value from those intervals will be taken\n",
    "\n",
    "delta(node_hwmon_temp_celsius[10m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta(windows_net_packets_received_total[10m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bad415",
   "metadata": {},
   "source": [
    "![](images/prometheus_temp_delta.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d368aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates increase between last value in range vector and the first\r\n",
    "# Adjusted for monotonicity and smoothed out\r\n",
    "\r\n",
    "increase(node_hwmon_temp_celsius[10m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2999aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "increase(windows_net_packets_received_total[10m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b9702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T19:24:24.527053Z",
     "start_time": "2021-04-17T19:24:24.423094Z"
    }
   },
   "source": [
    "![](images/prometheus_increase_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e^temp exponential value\r\n",
    "# This one operates on instant vectors\r\n",
    "\r\n",
    "exp(node_hwmon_temp_celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18de7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(windows_cpu_time_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4f945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T19:26:54.252144Z",
     "start_time": "2021-04-17T19:26:54.148074Z"
    }
   },
   "source": [
    "![](images/prometheus_exp_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83197c5",
   "metadata": {},
   "source": [
    "### {op}_over_time\n",
    "\n",
    "Last set of provided Prometheus functions is given by the following scheme :\n",
    "\n",
    "```\n",
    "{op}_over_time(v range-vector)\n",
    "```\n",
    "\n",
    "where you put different `op`s like `avg`, `min` and the operation is carried across specified `range`s.\n",
    "\n",
    "Check out all possibilities [here](https://prometheus.io/docs/prometheus/latest/querying/functions/#aggregation_over_time) and an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation over range vector of the number of context switches\r\n",
    "# performed by the operating system\r\n",
    "\r\n",
    "stddev_over_time(node_context_switches_total{group=\"dev\"}[10s])"
   ],
   "outputs": [],
   "source": [
    "stddev_over_time(windows_system_context_switches_total[10s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72900f8d",
   "metadata": {},
   "source": [
    "![](images/prometheus_stddev_over_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3e75c",
   "metadata": {},
   "source": [
    "## Recording rules\n",
    "\n",
    "> __Recording rules allow us to precompute frequently used/expensive and save results as a new timeseries__\n",
    "\n",
    "__You should always try to create new rules instead of running ad-hoc commands__, as:\n",
    "- Faster, as they work on less data but on a regular basis\n",
    "- More readable for others\n",
    "- Easy to reuse\n",
    "- Easy to put in VCS systems like `git`\n",
    "\n",
    "Rules are usually writen in separate `.yml` file (`<name>.rules.yml` seems like a reasonable choice) __and included in `prometheus.yml` config__ we have seen in a previous lesson.\n",
    "\n",
    "Let's take a look at the `example.rules.yml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups: # High level grouping\r\n",
    "  - name: example # Name of the group of rules\r\n",
    "    interval: 30s # How often they should be evaluated (deafult: 1m)\r\n",
    "    rules: # Set of rules in this this group\r\n",
    "    - record: job:http_inprogress_requests:sum # Name of the rule\r\n",
    "      expr: sum by (job) (http_inprogress_requests) # Evaluated expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b0c40",
   "metadata": {},
   "source": [
    "### Groups\n",
    "\n",
    "> Rules within a group are run sequentially (as defined) in a regular interval\n",
    "\n",
    "Those should be grouped by:\n",
    "- semantic meaning\n",
    "- evaluation interval\n",
    "\n",
    "### Naming\n",
    "\n",
    "There a few guidelines you should stick to:\n",
    "- Recording rules should be of the general form `level:metric:operations`:\n",
    "    - `level` - labels of the rule output / aggregation level\n",
    "    - `metric` - name of the metric, e.g. `http_requests`\n",
    "    - `operations` - key operations creating the result\n",
    "    \n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "- record: instance_path:requests:rate5m\n",
    "  expr: rate(requests_total{job=\"myjob\"}[5m])\n",
    "\n",
    "- record: path:requests:rate5m\n",
    "  expr: sum without (instance)(instance_path:requests:rate5m{job=\"myjob\"})\n",
    "  \n",
    "- record: instance_path:request_failures:rate5m\n",
    "  expr: rate(request_failures_total{job=\"myjob\"}[5m])\n",
    "\n",
    "- record:  wmiexporter:windows_cpu_dpcs_total:sum \n",
    "  expr: sum by (job) (windows_cpu_dpcs_total)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d0683",
   "metadata": {},
   "source": [
    "### Including rules in prometheus.yml\n",
    "\n",
    "After we have our rule written down, __we have to include it in `prometheus.yml` server config__.\n",
    "\n",
    "There are two places where one can change related `recording rules` settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "global:\r\n",
    "  # How frequently to evaluate rules.\r\n",
    "  # Define on a per-group basis if needed\r\n",
    "  [ evaluation_interval: <duration> | default = 1m ]\r\n",
    "rule_files:\r\n",
    "  [ - <filepath_glob> ... ] # Path to rule files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876bc3c",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my global config\n",
    "global:\n",
    "  evaluation_interval: 5m # Evaluate rules every 15 seconds. The default is every 1 minute.\n",
    "\n",
    "# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.\n",
    "rule_files:\n",
    "   - \"windows.rules.yml\"\n",
    "   - \"docker.rules.yml\"\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d446cba",
   "metadata": {},
   "source": [
    "After those steps, your rules will run automatically and be available under the `record` name you specified!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6a511",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "\n",
    "### Assessment\n",
    "\n",
    "- Check out [best Prometheus practices](https://prometheus.io/docs/practices/) and do your best \n",
    "- Check out [more functions examples](https://prometheus.io/docs/prometheus/latest/querying/examples/) to get a better feel of what one can do with it\n",
    "- What is `@` modifier and how to use it? See [here](https://prometheus.io/docs/prometheus/latest/querying/basics/#modifier)\n",
    "- How to use `many-to-one` and `one-to-many`? Read [here](https://prometheus.io/docs/prometheus/latest/querying/operators/#many-to-one-and-one-to-many-vector-matches)\n",
    "\n",
    "### Non-assessment\n",
    "\n",
    "- What is Prometheus's `promtool`? How can it help you?\n",
    "- How to create [Alerting rules](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/)? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash [conda env:.conda-AiCore] *",
   "language": "bash",
   "name": "conda-env-.conda-AiCore-bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
