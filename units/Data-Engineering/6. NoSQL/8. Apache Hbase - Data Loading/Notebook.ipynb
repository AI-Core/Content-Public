{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache HBase - Data Loading\n",
    "\n",
    "Below are the steps required to load data into an HBase table. Make sure to have followed the previous steps to download, install and setup HBase before proceeding.\n",
    "\n",
    "#### 1. The first step is to download the Retail data CSV file\n",
    "\n",
    "You can [download it from here](https://aicore-files.s3.amazonaws.com/Data-Eng/retail.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The next step is to import the Retail data file into HBase.\n",
    "\n",
    "To do that, we need to first create a new Hbase table and specify the Column Family. To do this, type the below command from inside the `hbase shell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create 'retail_table',{NAME => 'cf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the table was created successfully, run the `list` command to see all available HBase tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list\n",
    "\n",
    "#Expected output:\n",
    "hbase(main):002:0> list\n",
    "retail_table                                                                         \t \n",
    "1 row(s) in 0.3180 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the table is created, we need to run the below command to copy the CSV file to HDFS, so we can import it into HBase:\n",
    "\n",
    "_Note: Ensure you are using your folder path where you saved the `retail.csv` file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop fs -put /YOURPATH/retail.csv /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to check that the file has been properly copied to HDFS, type the below command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop fs -ls /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop fs -ls /data\n",
    "\n",
    "# Expected output\n",
    "22/01/26 17:20:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "Found 1 items\n",
    "-rw-r--r--   1 hadoop supergroup   45580638 2022-01-26 17:20 /data/retail.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to load the `retail.csv` file into HBase. To do this, run the below command from the __terminal__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=',' -Dimporttsv.columns=HBASE_ROW_KEY,cf:description,cf:quantity,cf:price,cf:customer,cf:country retail_table /data/retail.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: You could of course write code to generate the column names if you have too many to write out by hand._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: If you get any errors, such as \"Bad Lines\" or \"Failed Map\", check that you didn't miss any characters from the above code and attempt to type it directly yourself instead of copy and pasting it._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works smoothly, you should see output similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2022-01-07 13:34:28,910 INFO  [main] mapreduce.Job: erations=0\n",
    "   \t HDFS: Number of bytes read=756\n",
    "   \t HDFS: Number of bytes written=0\n",
    "   \t HDFS: Number of read operations=2\n",
    "   \t HDFS: Number of large read operations=0\n",
    "   \t HDFS: Number of write operations=0\n",
    "    Job Counters\n",
    "   \t Launched map tasks=1\n",
    "   \t Data-local map tasks=1\n",
    "   \t Total time spent by all maps in occupied slots (ms)=5154\n",
    "   \t Total time spent by all reduces in occupied slots (ms)=0\n",
    "   \t Total time spent by all map tasks (ms)=5154\n",
    "   \t Total vcore-milliseconds taken by all map tasks=5154\n",
    "   \t Total megabyte-milliseconds taken by all map tasks=5277696\n",
    "    Map-Reduce Framework\n",
    "   \t Map input records=15\n",
    "   \t Map output records=15\n",
    "   \t Input split bytes=104\n",
    "   \t Spilled Records=0\n",
    "   \t Failed Shuffles=0\n",
    "   \t Merged Map outputs=0\n",
    "   \t GC time elapsed (ms)=77\n",
    "   \t CPU time spent (ms)=1600\n",
    "   \t Physical memory (bytes) snapshot=183992320\n",
    "   \t Virtual memory (bytes) snapshot=1874804736\n",
    "   \t Total committed heap usage (bytes)=137953280\n",
    "    ImportTsv\n",
    "   \t Bad Lines=0\n",
    "    File Input Format Counters\n",
    "   \t Bytes Read=652\n",
    "    File Output Format Counters\n",
    "   \t Bytes Written=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now, we need to go into the HBase shell and check that the data is correctly loaded. \n",
    "\n",
    "To do that, we'll use the `scan` command, which is similar to a SQL `SELECT`. It will scan over the entire table and retrieve the relevant data.\n",
    "\n",
    "For example, the below code will return the _first 5 rows_ of the Retail table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan 'retail_table', {'LIMIT', 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected output:\n",
    "Hbase::Table - retail_table\n",
    "hbase(main):009:0> scan 'retail_table', {'LIMIT', 5}\n",
    "ROW                \tCOLUMN+CELL                                               \t \n",
    " 1                 \tcolumn=cf:country, timestamp=1643213704999, value=United Kingdo\n",
    "                   \tm                                                         \t \n",
    " 1                 \tcolumn=cf:customer, timestamp=1643213704999, value=17850  \t \n",
    " 1                 \tcolumn=cf:description, timestamp=1643213704999, value=WHITE HAN\n",
    "                   \tGING HEART T-LIGHT HOLDER                                 \t \n",
    " 1                 \tcolumn=cf:price, timestamp=1643213704999, value=2.55      \t \n",
    " 1                 \tcolumn=cf:quantity, timestamp=1643213704999, value=6      \t \n",
    " 10                \tcolumn=cf:country, timestamp=1643213704999, value=United Kingdo\n",
    "                   \tm                                                         \t \n",
    " 10                \tcolumn=cf:customer, timestamp=1643213704999, value=13047  \t \n",
    " 10                \tcolumn=cf:description, timestamp=1643213704999, value=ASSORTED\n",
    "                   \tCOLOUR BIRD ORNAMENT                                      \t \n",
    " 10                \tcolumn=cf:price, timestamp=1643213704999, value=1.69      \t \n",
    " 10                \tcolumn=cf:quantity, timestamp=1643213704999, value=32     \t \n",
    " 100               \tcolumn=cf:country, timestamp=1643213704999, value=United Kingdo\n",
    "                   \tm                                                         \t \n",
    " 100               \tcolumn=cf:customer, timestamp=1643213704999, value=14688  \t \n",
    " 100               \tcolumn=cf:description, timestamp=1643213704999, value=60 TEATIM\n",
    "                   \tE FAIRY CAKE CASES                                        \t \n",
    " 100               \tcolumn=cf:price, timestamp=1643213704999, value=0.55      \t \n",
    " 100               \tcolumn=cf:quantity, timestamp=1643213704999, value=24     \t \n",
    " 1000              \tcolumn=cf:country, timestamp=1643213704999, value=United Kingdo\n",
    "                   \tm                                                         \t \n",
    " 1000              \tcolumn=cf:customer, timestamp=1643213704999, value=14729  \t \n",
    " 1000              \tcolumn=cf:description, timestamp=1643213704999, value=TOAST ITS\n",
    "                    \t- HAPPY BIRTHDAY                                         \t \n",
    " 1000              \tcolumn=cf:price, timestamp=1643213704999, value=1.25      \t \n",
    " 1000              \tcolumn=cf:quantity, timestamp=1643213704999, value=2      \t \n",
    " 10000             \tcolumn=cf:country, timestamp=1643213704999, value=United Kingdo\n",
    "                   \tm                                                         \t \n",
    " 10000             \tcolumn=cf:customer, timestamp=1643213704999, value=13174  \t \n",
    " 10000             \tcolumn=cf:description, timestamp=1643213704999, value=SET OF 2\n",
    "                   \tTINS VINTAGE BATHROOM                                     \t \n",
    " 10000             \tcolumn=cf:price, timestamp=1643213704999, value=4.25      \t \n",
    " 10000             \tcolumn=cf:quantity, timestamp=1643213704999, value=2      \t \n",
    "5 row(s) in 0.1360 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a detailed look at how the data is displayed in HBase as it may seem confusing at first.  Unlike a relational database which stores data in a row-based manner, HBase stores the data in a __column-based__ approach. \n",
    "\n",
    "Each line in HBase represents a column value and also includes an automatic timestamp. The __Row__ is a unique Rowkey identifier that tells HBase how each of the columns are connected to each other (i.e. if they are part of the same logical row or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying data in HBase\n",
    "\n",
    "You can of course, run more complex queries.\n",
    "\n",
    "To find out how many total rows we have in the table, we can use the `count` command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count `retail_table`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/hbase-count.png\" width=600>\n",
    "  <figcaption align=\"center\"><cite>Output of HBase Count Command</cite></figcaption>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do more advanced querying using filters (similar to SQL's WHERE command), we'll first need to import 3 HBase classes:\n",
    "\n",
    "- `SingleColumnValueFilter`\n",
    "- `CompareFilter`\n",
    "- `BinaryComparator`\n",
    "    \n",
    "These 3 classes work together to provide flexible filtering criteria.\n",
    "\n",
    "To achieve this, run the below 3 commands from inside the HBase shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required 3 classes \n",
    "import org.apache.hadoop.hbase.filter.SingleColumnValueFilter \n",
    "import org.apache.hadoop.hbase.filter.CompareFilter\n",
    "import org.apache.hadoop.hbase.filter.BinaryComparator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be similar to:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/hbase-filter-import.png\" width=600>\n",
    "  <figcaption align=\"center\"><cite>HBase Class Imports</cite></figcaption>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run queries with specific filters. First, let's query the table for all data that have the `country as United Kingdom`. The query would have the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan 'retail_table', { FILTER => SingleColumnValueFilter.new(Bytes.toBytes('cf'), Bytes.toBytes('country'), CompareFilter::CompareOp.valueOf('EQUAL'),BinaryComparator.new(Bytes.toBytes('United Kingdom')))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will look something like this:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/hbase-scan-filter.png\" width=600>\n",
    "  <figcaption align=\"center\"><cite>HBase Scan Command Output</cite></figcaption>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run a query to check how many products have a `price equal to 12.75`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan 'retail_table', { FILTER => SingleColumnValueFilter.new(Bytes.toBytes('cf'), Bytes.toBytes('price'), CompareFilter::CompareOp.valueOf('EQUAL'),BinaryComparator.new(Bytes.toBytes('12.75')))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `826 products` as indicated by the number of rows seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/hbase-filter-price.png\" width=600>\n",
    "  <figcaption align=\"center\"><cite>Filtered Scan Results</cite></figcaption>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the combination of above filters, we can use the below comparison operators inside the `CompareFilter::CompareOp.valueOf` on column values:\n",
    "\n",
    "- `EQUAL`\n",
    "- `GREATER`\n",
    "- `GREATER_OR_EQUAL`\n",
    "- `LESS`\n",
    "- `LESS_OR_EQUAL`\n",
    "- `NOT_EQUAL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HBase commands:\n",
    "\n",
    "Below are some of the typical commands you would be using to interact with data in HBase:\n",
    "\n",
    "- `put`\n",
    "    -   This command allows you to update the data in an already existing cell.\n",
    "\n",
    "- `get`\n",
    "    -   This command are used to read data from a table in HBase. It returns the values associated with a row of data at a time.\n",
    "\n",
    "- `delete`\n",
    "    -   This command allows you to delete a specific cell in an HBase table.\n",
    "\n",
    "- `deleteall`\n",
    "    -   This command deletes all of the cells in a table.\n",
    "\n",
    "- `scan`\n",
    "    -   This command is used to view the data stored in an HBase table.\n",
    "\n",
    "- `count`\n",
    "    -   This command is used to count the number of rows of a table.\n",
    "\n",
    "- `disable`\n",
    "    -   This command disables (turns off) a table so that it can be deleted.\n",
    "\n",
    "- `drop`\n",
    "    -   This commands deletes a disabled table.\n",
    "\n",
    "-   `truncate`\n",
    "    -   This commands does 3 things in sequence:\n",
    "        -   Disables a table\n",
    "        -   Drops a table\n",
    "        -   Recreates the table with the same name\n",
    "\n",
    "\n",
    "For a detailed explanation of HBase commands, check the following guide:\n",
    "-    [HBase Cheat Sheet](https://sparkbyexamples.com/hbase/hbase-shell-commands-cheat-sheet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Tables in HBase can be created using the `create` command.  Table querying can be done using `scan` and `get` commands, while inserting data can be done using the `put` command.\n",
    "- In order to delete an HBase table, we first need to `disable` the table and then `drop` the disabled table.  Alternatively, the `truncate` command can be used to implement all of these actions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
