{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big O Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software Engineers will spend a significant amount of his time improving the efficiency of the code: __a faster algorithm__ and with small space complexity.\n",
    "\n",
    "The search of this efficiency lead to the development of different methods and normalize that method to analyze every algorithm under the same conditions. \n",
    "\n",
    "This efficiency measurement is known as asymptotic analysis, and it will tell us the computational cost (or complexity) of an algorithm as a function of different parameters, for example its input size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Complexity\n",
    "\n",
    "Imagine a simple for loop that iterates through n elements:\n",
    "`for i in range(n)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](images/BigO_1.gif)\n",
    "\n",
    "Now, imagine a nested for loop:\n",
    "```\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "```\n",
    "\n",
    "![](images/BigO_2.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first graph means that the amount of time the code takes to run increases proportional to the number of inputs\n",
    "\n",
    "Second second graph means that the amount of time the code takes to run increases proportional to the square of the number of inputs.\n",
    "\n",
    "There is a shorthand to write this: Big O notation, which represents the time complexity in the worst case scenario. \n",
    "\n",
    "It looks like this: `O(n`<sup>`2`</sup>`)`, where n is the number of inputs, and n<sup>2</sup> is the time complexity. Thus for the first case we have `O(n)` and for the second case `O(n`<sup>`2`</sup>`)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst case scenario? What is the WCS for a for loop? Imagine we are looking for a specific number in the list. The WCS would be finding it at the end of it.\n",
    "\n",
    "_Same way we have big O, we also have big Ω for Best Case Scenario, and big θ for a combination of both. However we will focus solely on the big O_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how complexity increases in nested loops, you might think twice before using one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules to follow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know how to define big O notation let's look at some rules to follow when calculating Big O of an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <font size=+0.7> Rule 1: </font>\n",
    "\n",
    "If a function f(n) performs a sequence of steps n times then it takes O(f(n)) or O(n) in runtime to perform we have already seen this with iterating through a list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <font size=+0.7>Rule 2:</font>\n",
    "\n",
    "If a function takes f(n) steps to run and another function takes g(m) steps to run then we can add the complexities, we get O(F(n)+g(m)) or O(m + n) complexity.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "for x in range(n):\n",
    "    do something\n",
    "for y in range(m):\n",
    "    do something\n",
    "```\n",
    "\n",
    "Would give O(n+m) time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font size=+0.7> Rule 3:</font>\n",
    " \n",
    "If a function takes f(n) steps to run and another takes g(m) steps to run with g(m) > f(n) then the resulting complexity would be O(g(m)). In summary when adding complexities we drop the non dominant terms.\n",
    "\n",
    "For example: \n",
    "\n",
    "```\n",
    "for x in range(n):\n",
    "    do something\n",
    "\n",
    "for k in range(n):\n",
    "    do something\n",
    "    for j in range(n):\n",
    "        do something\n",
    "```\n",
    "\n",
    "Here you would expect the time complexity to be O(n + n<sup>2</sup>) but notice for very large values of n the n<sup>2</sup> term will dominate the n term. So we can remove the dominant terms resulting in a time complexity of O(n<sup>2</sup>).\n",
    "\n",
    "> **As a rule of thumb:** If you have function f(n) and g(n) and your algorithm is of the form 'do this then that' then you add the complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font size=+0.7> Rule 4: </font>\n",
    "\n",
    "If you have function f(n) and g(n) and your algorithm takes f(n) steps and for every step takes another g(n) steps then you multiply the complexities.\n",
    "\n",
    "For example our nested loops case:\n",
    "```\n",
    "for k in range(n):\n",
    "    do something\n",
    "    for j in range(n):\n",
    "        do something\n",
    "```\n",
    "\n",
    "The resultant complexity would be O(n * n) or O(n<sup>2</sup>).\n",
    "\n",
    "> **Another rule of thumb:**\n",
    "> If your algorithm is of the form 'Do this every time you do that' you multiply the complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font size=+0.7> Rule 5: </font>\n",
    "\n",
    "Finally rule 5 we drop the constants, big O measures the amount of times your input will be processed (in worst-case scenario). So if you have for example\n",
    "\n",
    "```\n",
    "for x in range(len(n)):\n",
    "    y = 3 * x\n",
    "```\n",
    "\n",
    "This would result in a complexity of not O(3n) but instead O(n) because once again the n term will dominate the constant for very large values of n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Fibonacci big O\n",
    "Let's see an classical example: Recursive Fibonacci vs Loop Fibonacci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_fibo(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return(recur_fibo(n-1) + recur_fibo(n-2))\n",
    "\n",
    "\n",
    "# check if the number of terms is valid\n",
    "def while_fib(n):\n",
    "    n1, n2 = 0, 1\n",
    "    count = 0\n",
    "    while count < n - 1:\n",
    "        nth = n1 + n2\n",
    "        # update values\n",
    "        n1 = n2\n",
    "        n2 = nth\n",
    "        count += 1\n",
    "    return nth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time each function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "n = 35\n",
    "t_0 = time.time()\n",
    "print(recur_fibo(n))\n",
    "print(f'Recursive Fib took {time.time() - t_0} s')\n",
    "\n",
    "\n",
    "t_0 = time.time()\n",
    "print(while_fib(n))\n",
    "print(f'While Fib took {time.time() - t_0} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra points to anyone who can tell me the big O of each algorithm. You can google it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We just talked about time complexity, but we should also consider space complexity. It can also be measured using the big O, and in essence measures the amount of memory allocated to run your program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, O(n) means that for each input processed, you will add one variable per processed input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through lists, dictionaries, sets or tuples usually has a linear Big O (`O(n)`) in terms of time complexity. But fetching specific items is speedy in dictionaries and sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4}\n",
    "my_list = ['One', 'Two', 'Three', 'Four']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we might not see a difference when checking if 'Three' exists for example, but for huge data inputs, dictionaries are much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators - A solution for Space complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing all information in a list will take `O(n)` in terms of space complexity. Thus, huge datasets takes huge data complexity. \n",
    "\n",
    "Instead, try using generators, since they take a `O(1)` (as long as we don't append its values in another list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "def my_gen(n):\n",
    "    for i in range(n):\n",
    "        yield i\n",
    "\n",
    "y = my_gen(20)\n",
    "s = next(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell multiple times to see that the generator is actually working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getsizeof(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we only have one variable for iterating through 20 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getsizeof(my_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through `my_list` will take the same time complexity, but we need a list with 20 memory allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Big O possibilites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big O can show many complexities, and as we progress in this Unit, we will see more them.\n",
    "\n",
    "![](images/BigO_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/BigO_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the above graph, it looks like if the input size is low, some algorithms are better. For example, O(n^2) looks better than O(n) at the beggining. But don't get fooled! That is only true if the input size is less than 1! In other cases, the input size doesn't have to be greater than 1 for that to be true, it will also depend on the operation.\n",
    "\n",
    "> <font size=+1> Complexity will differ from algorithm to algorithm, you should only compare complexities when they are used for the same purpose </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structures for improving Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, it is worth mentioning that there are many data structures in Python that can save a lot of time and space. Many of these structures are in the library named `collections`. Let's see an example, the `defaultdict`, and for doing so, let's see an example that you probably have come across many times: try to get the most frequent element in a list or in another structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_with_highest_count(counts: dict) -> int:\n",
    "    max_count = 0\n",
    "    for number, count in counts.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            number_with_highest_count = number\n",
    "    return number_with_highest_count\n",
    "\n",
    "\n",
    "def most_frequent(numbers: list) -> int:\n",
    "    counts = {}\n",
    "    for number in numbers:\n",
    "        if number in counts:\n",
    "            counts[number] += 1\n",
    "        else:\n",
    "            counts[number] = 1\n",
    "\n",
    "    return get_number_with_highest_count(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution works, but we can keep the code more concise using `defaultdict`, which will save you the work of checking if an element is already in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_number_with_highest_count(counts: dict) -> int:\n",
    "    max_count = 0\n",
    "    for number, count in counts.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            number_with_highest_count = number\n",
    "    return number_with_highest_count\n",
    "\n",
    "\n",
    "def most_frequent(numbers: list) -> int:\n",
    "    counts = defaultdict(int) # <-- If the key doesn't exist, defaultdict will create a new key whose value is an integera\n",
    "    for number in numbers:\n",
    "        counts[number] += 1\n",
    "\n",
    "    return get_number_with_highest_count(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is more concise, but we can even improve it more. The same `collections` library has a class named `Counter`, which, as the name suggests, counts the number of times an element appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5, 8: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 9: 1, 11: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "my_list = [1, 1, 2, 3, 4, 5, 6, 8, 8, 9, 1, 11, 1, 1, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "counts = Counter(my_list)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can implement a Counter inside our code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_number_with_highest_count(counts):\n",
    "    max_count = 0\n",
    "    for number, count in counts.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            number_with_highest_count = number\n",
    "    return number_with_highest_count\n",
    "\n",
    "\n",
    "def most_frequent(numbers):\n",
    "    counts = Counter(numbers)\n",
    "    return get_number_with_highest_count(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_with_highest_count(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our code can't improve further... But wait, there is more. What about the `get_number_with_highers_count` function? We could simply use the `max` function that is built in Python by default. The problem is that by default, applying `max` to a dictionary will return the maximum of the values of its keys. If you try to apply it to the values, yes, you will get the maximum value amongst the values, but you won't know to which key it would correspond. \n",
    "\n",
    "We can apply lambda functions for this. Remember that many functions, such as sort, filter, map... accepts a key that will define the rules to compare the values to find the max value from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_number_with_highest_count(counts):\n",
    "    '''\n",
    "    Get a dict and return the key whose value is the highest\n",
    "    '''\n",
    "    return max(\n",
    "        counts,\n",
    "        key=lambda number: counts[number] # maximize by value\n",
    "    )\n",
    "\n",
    "def most_frequent(numbers):\n",
    "    counts = Counter(numbers)\n",
    "    return get_number_with_highest_count(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a final check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like everything is working great, and with much fewer lines of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples were just that: examples. You have to bear in mind that these techniques don't come easily to you, but by practicing, you will develop a sense of detecting when your code can be improved. Additionally, we used two new classes we haven't seen before, and it's natural you didn't know them, no one expects you to know all Python libraries, the imporant thing is that you are not likely the first one to find a particular error, and the solution is out there, waiting for you to find it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for measuring Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that we need to improve time complexity and space complexity. But how do we know we are going in the right direction? Luckily, Python offers ways to measure both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`timeit` is a module that can be used in the CLI or in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command line, it would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m timeit \"total=sum(range(1000))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your code it would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "result = timeit(stmt='total=sum(range(1000))', number=5000)\n",
    "print(result/5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this tool to check how long it takes for snippets of your code to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check more metrics from your code such as how many times each piece of code was ran, how much time it spent on each part, and how long it took for each call. To check it out, download the following file, and run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://aicore-files.s3.amazonaws.com/Foundations/Software_Engineering/cpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cProfile --sort tottime cpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what is going on from start to end, all imports, all calls...\n",
    "\n",
    "This will help you identifying where your code presents a bottleneck: which part slows down the whole algorithm, and try to come up with a better algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Performance is a critical element to consider when developing your project\n",
    "- Designing will be an iterative process where you will improve small parts of your code, review, and redesign\n",
    "- Different data types have different complexities\n",
    "- Big O notation will help you see these key elements\n",
    "- You can, and should, use solutions that are already available. No need to reinvent the wheel! Check collections, itertools, and functools.\n",
    "- Python offers tools for measuring complexities. Make the most out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Big_O_notation)\n",
    "\n",
    "[Big O Notation](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)\n",
    "\n",
    "[Introduction to the theory of computation](http://fuuu.be/polytech/INFOF408/Introduction-To-The-Theory-Of-Computation-Michael-Sipser.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad8bebc098a042dc0df4e42fc2ecc8fff0bd7b8741641ce29007c29766dadbe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
