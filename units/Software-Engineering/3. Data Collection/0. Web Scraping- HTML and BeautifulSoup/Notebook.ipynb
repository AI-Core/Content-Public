{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping- HTML and Beautiful Soup\n",
    "\n",
    "> One of the most common ways to obtain data is through the use of _web scraping_. Web scraping, as the name suggests, is about pulling information from websites in a programmatic fashion (because copy and pasting would be way too much effort, especially for vast amounts of data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenge\n",
    "\n",
    "Let's say we wanted to build a model which would predict house prices given some features - for example, location, number of bedrooms, number of bathrooms. We need some way of obtaining this data - both the response and the target variables.\n",
    "\n",
    "To introduce you to the concept of web scraping, let's try and extract data for 100 houses:\n",
    "- **Sale Price**: Our response variable\n",
    "- Number of bedrooms\n",
    "- Square footage\n",
    "- Description\n",
    "- Address\n",
    "    \n",
    "[This URL shows houses listed for sale in London](https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list). Let's take a look at where the information that we want to extract is on the webpage.\n",
    "\n",
    "Before we look at solving this challenge, let's take a look at what websites and HTML actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Websites\n",
    "\n",
    "### What format does information on a website exist in?\n",
    "\n",
    "- We know that websites don't just print data in a nice CSV or JSON format\n",
    "- They have content to display information to you in a way that makes sense, like buttons, on the page\n",
    "- This content is defined in an HTML file\n",
    "- They also have styling\n",
    "\n",
    "#### What is HTML?\n",
    "\n",
    "> HTML stands for HyperText Markup Language. It consists of a tree structure of different types of web elements, like buttons, page divisions, images and more. \n",
    "\n",
    "This means that HTML is used to define what **content** is rendered on any webpage that you visit.\n",
    "\n",
    "HTML markdown contains elements/tags that may contain other elements/tags.\n",
    "\n",
    "\n",
    "[Let's play around with some HTML](https://code.sololearn.com/WoNr8gIeKYDr/)\n",
    "\n",
    "### How can we get the website HTML, which contains data that we want?\n",
    "\n",
    "When you search for a URL in a browser, here's what happens:\n",
    "- Your browser makes a **GET request** to the computer (server) that serves requests from that URL endpoint\n",
    "- This computer knows what web content to send you back, so it sends it in a response to the request. This stuff includes the HTML of the page that you want to view.\n",
    "- Your browser gets the HTML, and knows how to present that type of data to you (it renders the webpage)\n",
    "\n",
    "The point here being that you can get the HTML, which defines the content for any site, by making a GET request to that website.\n",
    "\n",
    "Let's try that!\n",
    "\n",
    "We can use the requests library to get the HTML from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import requests # import the requests library\n",
    "r = requests.get('http://pythonscraping.com/pages/page3.html') # make a HTTP GET request to this website\n",
    "html_string = r.text # the text attribute of this response is the HTML as a string\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we saw above only gives us the HTML, but we want to be able to extract the data from it. After requesting the data from the webpage, we obtain a string of HTML, but looking for some specific data is a bit of a pain. We can use the **BeautifulSoup** library to extract the data from the HTML looking for specific tags and their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get('http://pythonscraping.com/pages/page3.html')\n",
    "html = page.text # Get the content of the webpage\n",
    "soup = BeautifulSoup(html, 'html.parser') # Convert that into a BeautifulSoup object that contains methods to make the tag searcg easier\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example using the following [URL](http://pythonscraping.com/pages/page3.html) `'http://pythonscraping.com/pages/page3.html'`\n",
    "\n",
    "In that webpage you will find a small list with a set of items. Let's say that you want to extract the data from the Fish Painting.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src='images/BS4_1.png' width=500>\n",
    "  <figcaption align=\"center\"><cite>Sample Website</cite></figcaption>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your browser, you can see that the HTML for the page is in the `<body>` tag. Let's see how we can extract the data from this HTML. In the page, right-click on the `<body>` tag and select **Inspect Element**. There, you will see the HTML for the page, and you can see that the Fish Painting is in a `<tr>` tag.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src='images/BS4_2.png' width=500>\n",
    "  <figcaption align=\"center\"><cite>HTML Inspect Element Output</cite></figcaption>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find that tag using the method `find` that accepts the tag name, and the attributes of said tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = soup.find(name='tr', attrs={'id': 'gift3', 'class': 'gift'}) # If it doesn't find anything it returns None\n",
    "\n",
    "print(fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `tr` tag, you will find different `<td>` tags. You can find all the `<td>` tags using the method `find_all` that accepts the tag name and the attributes of said tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_row = fish.find_all('td') # This returns a list where each item corresponds to each td tag "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you obtained a list where each element correponds to the data for each column. Thus, you can index the list to get the data you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = fish_row[0].text\n",
    "description = fish_row[1].text\n",
    "price = fish_row[2].text\n",
    "\n",
    "print(title)\n",
    "print(description)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep looking for more data in the tree. For example, you can look for the parrot row taking into account that it is the sibling of the fish row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot = fish.find_next_sibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also find the parrot's children using the method `findChildren`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot_children = parrot.findChildren()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- _Web scraping_ is one of the most popular techniques used in industry to obtain data. It is about pulling information from websites in a programmatic manner.\n",
    "- A _website_ contains content stored typically in an HTML file format. Websites also have styling and useful interface items like buttons to make it easier for humans to interact with the data.\n",
    "- HTML stands of HyperText Markup Language. It is the standard format that websites store content in.\n",
    "- Browsers obtain information from a website using the `GET` command. The response is usually an HTML.\n",
    "- _BeautifulSoup_ is a Python library that is used to extract data from HTML information that is returned to our computer in response to a request\n",
    "- HTML information is stored in _tags_ such as `<body>` and `<tr>`. BeautifulSoup can parse these HTML tags and extract data based on the parameters we provide."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
