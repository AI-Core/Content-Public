{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    ">Once the model has been saved, it can easily be deployed to various services:\n",
    "- [locally](https://www.mlflow.org/docs/latest/models.html#deploy-mlflow-models) with REST API (either inside a `docker` container or a `conda` environment).\n",
    "- [Microsoft's Azure ML](https://www.mlflow.org/docs/latest/models.html#deploy-a-python-function-model-on-microsoft-azure-ml).\n",
    "- [Amazon SageMaker](https://www.mlflow.org/docs/latest/models.html#deploy-a-python-function-model-on-amazon-sagemaker).\n",
    "- [Apache UDF](https://www.mlflow.org/docs/latest/models.html#export-a-python-function-model-as-an-apache-spark-udf).\n",
    "- Other services, maintained by community-driven deployment plugins (e.g. `torchserve`). Check [here](https://www.mlflow.org/docs/latest/plugins.html#deployment-plugins) for more information.\n",
    "\n",
    "The `mlflow model` commands are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The build-docker Subcommand\n",
    "\n",
    "> This subcommand creates a docker image and places the model inside it.\n",
    "\n",
    "Thereafter, the model can be served by running the created image (by default, port `8080` is exposed; thus, it can easily be mapped).\n",
    "\n",
    "To view more information on this subcommand, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models build-docker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The default is `python_flavor`, and it is compatible with every specific integration__ (more details are provided [here](https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html)).\n",
    "\n",
    "## The serve Subcommand\n",
    "\n",
    "> This subcommand runs a basic web server (created via `flask`) which we can query (e.g. using `curl`).\n",
    "\n",
    "The following can be specified, amongst other things:\n",
    "- `--model-uri`: the model resource (mandatory).\n",
    "- `--workers`: the number of parallel workers handling requests.\n",
    "- `--port`: the port that the server listens to for requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models serve --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The predict Subcommand\n",
    "\n",
    "> This subcommand allows us to query the model with a file (`.csv` or `.json`) (__useful for testing__).\n",
    "\n",
    "To view the possibilities, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Deployed Models\n",
    "\n",
    "Once a model has been deployed (via `docker` or `flask` webserver), it can be queried (from other machines or `localhost`). \n",
    "\n",
    "Requests are made by sending `json` text strings to the `/invocations` endpoint. There are a few possibilities for sending the data:\n",
    "- JSON-serialised pandas DataFrames in the split orientation (`data = pandas_df.to_json(orient='split')`).\n",
    "- JSON-serialised pandas DataFrames in the record orientation (discouraged).\n",
    "- CSV-serialised pandas DataFrames (`data = pandas_df.to_csv()`).\n",
    "- Tensor input, formatted as described in TF Servingâ€™s API docs; here, the provided inputs will be cast to Numpy arrays.\n",
    "\n",
    "Each of the above can be observed below (please note the `content/type` specification for the different versions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split-oriented DataFrame input\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\n",
    "    \"columns\": [\"a\", \"b\", \"c\"],\n",
    "    \"data\": [[1, 2, 3], [4, 5, 6]]\n",
    "}'\n",
    "\n",
    "# record-oriented DataFrame input (fine for vector rows, loses ordering for JSON records)\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 1,\"b\": 2,\"c\": 3},\n",
    "    {\"a\": 4,\"b\": 5,\"c\": 6}\n",
    "]'\n",
    "\n",
    "# numpy/tensor input using TF serving's \"instances\" format\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\n",
    "    \"instances\": [\n",
    "        {\"a\": \"s1\", \"b\": 1, \"c\": [1, 2, 3]},\n",
    "        {\"a\": \"s2\", \"b\": 2, \"c\": [4, 5, 6]},\n",
    "        {\"a\": \"s3\", \"b\": 3, \"c\": [7, 8, 9]}\n",
    "    ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we could encode more complex data before sending the request (e.g. images could be encoded using `base64` and automatically decoded by MLFlow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record-oriented DataFrame input with binary column \"b\"\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 0, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAw\"},\n",
    "    {\"a\": 1, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAx\"},\n",
    "    {\"a\": 2, \"b\": \"dGVzdCBiaW5hcnkgZGF0YSAy\"}\n",
    "]'\n",
    "\n",
    "# record-oriented DataFrame input with datetime column \"b\"\n",
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"a\": 0, \"b\": \"2020-01-01T00:00:00Z\"},\n",
    "    {\"a\": 1, \"b\": \"2020-02-01T12:34:56Z\"},\n",
    "    {\"a\": 2, \"b\": \"2021-03-01T00:00:00Z\"}\n",
    "]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "At this point, you should have a good understanding of \n",
    "- MLFlow model deployment.\n",
    "- MLFlow model commands.\n",
    "- how to query deployed models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
