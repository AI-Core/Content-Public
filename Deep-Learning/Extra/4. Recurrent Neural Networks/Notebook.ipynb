{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "> __Recurrent neural networks are parameter efficient generalization of `nn.Linear` which allows us to work with temporal data structures__\n",
    "\n",
    "Due to their specific structure it allows us to work with:\n",
    "- text (appropriately represented)\n",
    "- timeseries (for example weather prediction)\n",
    "- video (together with `torch.nn.Conv2d` layers)\n",
    "\n",
    "Their specific features (when compared to `nn.Linear` or `nn.Conv{1,2,3}d`) include:\n",
    "- memory of previous timesteps\n",
    "- can dependent on next batches\n",
    "\n",
    "## RNN Cell\n",
    "\n",
    "> Main building block of recurrent neural network(s) is named __cell__ and __is a `torch.nn.Linear` layer__\n",
    "\n",
    "![rnn_cell](images/rnn_cell.png)\n",
    "\n",
    "\n",
    "Let's specify above diagram with some math/textual notation:\n",
    "\n",
    "$$\n",
    "h_{t-1} \\rightarrow \\text{hidden state at timestep t (used for current timestep)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_t \\rightarrow \\text{input at timestep t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "[h_{t-1}, x_t] \\rightarrow \\text{concatenation of previous timestep and current input}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{[h_{t-1}, x_t]} \\rightarrow \\text{Linear weights used to transform concatenated previous timestep and current input}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t \\rightarrow \\text{hidden state at timestep t (output from linear transformation)}\n",
    "$$\n",
    "\n",
    "\n",
    "__Keep information below in mind:__\n",
    "\n",
    "- `h_t` is initially a tensor filled with zeros (__no need to pass initial hidden state__)\n",
    "- `tanh` activation is applied to the `h_t` __but only when it is passed as initial hidden state to the next cell__\n",
    "\n",
    "Let's see how to use `torch.nn.RNNCell` with example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T12:42:18.813848Z",
     "start_time": "2021-06-08T12:42:17.101167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "features = 30\n",
    "batch_size = 64\n",
    "\n",
    "cell = torch.nn.RNNCell(input_size=30, hidden_size=50)\n",
    "\n",
    "data = torch.randn(batch_size, features)\n",
    "\n",
    "cell(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "Now that we know what single cell does, the whole recurrent neural network is:\n",
    "\n",
    "> Chain of cells each taking __previous hidden state__ and __current input__ and __outputting next hidden state__\n",
    "\n",
    "![rnn_classification](images/rnn_classification.png)\n",
    "\n",
    "Things to keep in mind about RNN layer:\n",
    "- each cell also outputs it's own hidden state\n",
    "- __By default input shape should be `[seq_len, batch, features]` but we can use `batch_first=True` argument to make it `[batch, seq_len, features]`!__\n",
    "- __`seq_len` and `batch` can be of variable length (no need to specify them!)__\n",
    "\n",
    "This time input and output from `RNN` layer is a little more complicated (check [documentation](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) if in doubt)\n",
    "\n",
    "## RNN Inputs\n",
    "\n",
    "> __Inputs are `data` and `initial_hidden`__\n",
    "\n",
    "There are two inputs, but __we almost always only pass our data__ because:\n",
    "- RNN's `initial_hidden` is comprised of zeros is left untouched\n",
    "- __When would we want to change that?__\n",
    "\n",
    "All in all we only need our data!\n",
    "\n",
    "## RNN Outputs\n",
    "\n",
    "> __Each time a `tuple` with two tensors is returned, NOT A SINGLE TENSOR__\n",
    "\n",
    "- `outputs` of shape `(seq_len, batch, num_directions * hidden_size)` (__`batch` might be first dimension if specified with `batch_first=True`)!__\n",
    "- `h_n` of shape `(num_layers * num_directions, batch, hidden_size)` (__`batch` might be first dimension if specified with `batch_first=True`)!__\n",
    "\n",
    "Now, let's analyze what those mean!\n",
    "\n",
    "### outputs\n",
    "\n",
    "> Outputs __from the last layer of RNN__ (we may specify multiple layers via `num_layers`) __FOR EACH TIMESTEP `t`__\n",
    "\n",
    "Using it we can get:\n",
    "- all hidden outputs (without activation)\n",
    "- no matter how many layers we specify\n",
    "- `reshape` data to obtain specifc parts of data (e.g. `output.reshape(seq_len, batch, num_directions, hidden_size)`)\n",
    "\n",
    "> __Use when you need data from each timestep (for example attention, transformers etc.)__\n",
    "\n",
    "### h_n\n",
    "\n",
    "> Tensor containing __LAST HIDDEN STATE `t_final`__ (also we can get last output __from each layer__)\n",
    "\n",
    "Using it we can:\n",
    "- get summarization of sequence in the last hidden state\n",
    "- perform classification of shorter documents\n",
    "\n",
    "> __Use for `seq2seq`, basic classification (without attention)__\n",
    "\n",
    "Let's see both in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T12:47:27.400568Z",
     "start_time": "2021-06-08T12:47:27.386094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([50, 30])\n",
      "1 torch.Size([50, 50])\n",
      "2 torch.Size([50])\n",
      "3 torch.Size([50])\n",
      "Direct Outputs: torch.Size([64, 15, 50]) | Hidden: torch.Size([1, 64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Batch first for easier usage\n",
    "rnn = torch.nn.RNN(input_size=30, hidden_size=50, batch_first=True)\n",
    "\n",
    "for i, param in enumerate(rnn.parameters()):\n",
    "    print(i, param.shape)\n",
    "\n",
    "\n",
    "data = torch.randn(64, 15, 30)\n",
    "outputs, h_n = rnn(data)\n",
    "\n",
    "print(f\"Direct Outputs: {outputs.shape} | Hidden: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent variations\n",
    "\n",
    "> Recurrent Neural networks have multiple shortcomings __that we will focus on in the next lessons__\n",
    "\n",
    "Some of them were fixed (or improved upon) by RNNs themselves, in other cases new architectures were introduced. The shortcomings are:\n",
    "- Dying gradients due to long sequences and `tanh` (__even `20` timesteps might be a problem!__)\n",
    "- Context only from the previous timesteps (__does not look into the future timesteps__)\n",
    "- __All of the history is summed in a single `hidden_state`!__\n",
    "- __No way to attend to a single influential timestep__ (next lesson and attention)\n",
    "\n",
    "### Bidirectional\n",
    "\n",
    "![bi_rnn_classification](images/bi_rnn_classification.png)\n",
    "\n",
    "Bidirectional RNNs are a simple modification which consists of:\n",
    "- One RNN going through the sequence __from the beggining towards the end__\n",
    "- Another RNN going through the sequence __from the end to the beginning__\n",
    "\n",
    "Pros:\n",
    "- Improved gradient vanishing if we sum the states together\n",
    "- Knowledge from next timesteps due to reversed RNN\n",
    "\n",
    "Cons:\n",
    "- A little slower\n",
    "- __Twice as many parameters__ (although RNNs are very parameter efficient)\n",
    "- __Still everything is summed into single hidden states__\n",
    "- __For longer sequences gradient might still die__\n",
    "\n",
    "> We can simply use `bidirectional=True` to turn on this behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T12:47:07.754416Z",
     "start_time": "2021-06-08T12:47:07.731894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([50, 30])\n",
      "1 torch.Size([50, 50])\n",
      "2 torch.Size([50])\n",
      "3 torch.Size([50])\n",
      "4 torch.Size([50, 30])\n",
      "5 torch.Size([50, 50])\n",
      "6 torch.Size([50])\n",
      "7 torch.Size([50])\n",
      "Direct Outputs: torch.Size([64, 15, 100]) | Hidden: torch.Size([2, 64, 50])\n",
      "Outputs after summation: torch.Size([64, 15, 50])\n",
      "Concatenated Last Hidden: torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = torch.nn.RNN(\n",
    "    input_size=30, hidden_size=50, batch_first=True, bidirectional=True\n",
    ")\n",
    "\n",
    "for i, param in enumerate(bidirectional_rnn.parameters()):\n",
    "    print(i, param.shape)\n",
    "\n",
    "\n",
    "# By default outputs are concatenated from both directions\n",
    "outputs, h_n = bidirectional_rnn(data)\n",
    "print(f\"Direct Outputs: {outputs.shape} | Hidden: {h_n.shape}\")\n",
    "\n",
    "# -1 because we don't know length of sequence beforehand\n",
    "summed_outputs = outputs.reshape(64, -1, 2, 50).sum(dim=2)\n",
    "print(f\"Outputs after summation: {summed_outputs.shape}\")\n",
    "\n",
    "# Concatenate last hidden for single layer\n",
    "concatenated_last_hidden = torch.cat((h_n[0], h_n[1]), dim=-1)\n",
    "print(f\"Concatenated Last Hidden: {concatenated_last_hidden.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple layers\n",
    "\n",
    "> __Unlike other PyTorch layers, RNNs have `num_layers` parameter in order for us to use multiple layers__\n",
    "\n",
    "Why the API changes?\n",
    "\n",
    "- __Each hidden timestep from a given layer is passed on to the next RNN layer__\n",
    "- No clear way to do that otherwise\n",
    "- Other approaches are in-efficient from the implementation POV\n",
    "\n",
    "__Pros:__\n",
    "- More representational power\n",
    "- We can access `last_hidden` __from any layer__\n",
    "- __Useful for harder language problems__\n",
    "\n",
    "__Let's see multiple bidirectional layers and how to use it's outputs!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T12:49:59.850744Z",
     "start_time": "2021-06-08T12:49:59.831080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Outputs: torch.Size([64, 15, 100]) | Hidden: torch.Size([6, 64, 50])\n",
      "After choosing last layer: torch.Size([2, 64, 50])\n",
      "After concatenating bidirectional: torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "bidirectional_multiple_layers = torch.nn.RNN(\n",
    "    input_size=30, hidden_size=50, batch_first=True, bidirectional=True, num_layers=3\n",
    ")\n",
    "\n",
    "# By default outputs are concatenated from both directions\n",
    "# Outputs are from last layer, hence we are fine in most cases\n",
    "outputs, h_n = bidirectional_multiple_layers(data)\n",
    "print(f\"Direct Outputs: {outputs.shape} | Hidden: {h_n.shape}\")\n",
    "\n",
    "h_n_last_layer = h_n.reshape(3, 2, 64, 50)[-1].squeeze(dim=0)\n",
    "print(f\"After choosing last layer: {h_n_last_layer.shape}\")\n",
    "h_n_concatenated = torch.cat((h_n_last_layer[0], h_n_last_layer[1]), dim=-1)\n",
    "print(f\"After concatenating bidirectional: {h_n_concatenated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "> __LSTMs are improvement over RNN neural networks which allow them to work with longer sequences (up to a `1000` timesteps)__\n",
    "\n",
    "\n",
    "### What is improved?\n",
    "\n",
    "> __Vanishing gradient__\n",
    "\n",
    "Let's see a sentence oriented example and see the dependency:\n",
    "\n",
    "> A patient with a rare sarcoma of soft tissue on the left thigh was presented to the hospital yesterday.\n",
    "\n",
    "In this case:\n",
    "- \"was presented\" depends on \"patient\" __and is separated by 11 tokens__\n",
    "- Gradient can be seen as influence of the past on the future\n",
    "- __In this case it is is large__ yet __due to `11` linear layers gradient (dependency) vanishes__\n",
    "\n",
    "Let's go over __new__ notation:\n",
    "\n",
    "\n",
    "### How is it done?\n",
    "\n",
    "Let's see how a single LSTM cell looks:\n",
    "\n",
    "![lstm_full](images/lstm_full.png)\n",
    "\n",
    "And let's go over content in this image step by step:\n",
    "\n",
    "- __Cell state__ $$c_{t-1}$$ runs through the cells in the network __retains important information through longer steps__\n",
    "- Incorporates __forget gate__ $$f_t$$ which decides:\n",
    "    - how much information we will throw away __from previous steps__ by `[0, 1]` element-wise multiplication\n",
    "    - `0` - \"reset\" previous information\n",
    "    - `1` - keep the information unchanged (anything in-between is possible)\n",
    "    - __It does this via learnable linear layer with `sigmoid` activation__\n",
    "- This create $$c_t$$ (current cell state)\n",
    "- __Next we add new information__ to cell state via:\n",
    "    - `input` gate (which decides how much data will be added due to `sigmoid` and `linear` layers)\n",
    "    - `candidate` gate (whether the addition is positive or negative)\n",
    "    - After multiplication of those two the information is added\n",
    "- Current concatenated `[h_t, x_t]` is pushed through `sigmoid` __and multiplied by `cell state`__ (squashed to `[-1, 1]` which activates/deactivates parts of the data)\n",
    "\n",
    "### Features\n",
    "\n",
    "- __Works a little similar to ResNet__ - only new information is added if needed (__but via learnable layers!__)\n",
    "- __Additive paths (unlike multiplicative) will not be punished with the vanishing gradient__\n",
    "\n",
    "Let's see how to use `torch.nn.LSTM` layer (there is also `torch.nn.LSTMCell`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T14:44:15.947573Z",
     "start_time": "2021-06-08T14:44:15.913621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: torch.Size([64, 15, 100]) | Hidden: torch.Size([6, 64, 50]) | Cell: torch.Size([6, 64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Same arguments can be used\n",
    "lstm = torch.nn.LSTM(\n",
    "    input_size=30, hidden_size=50, batch_first=True, bidirectional=True, num_layers=3\n",
    ")\n",
    "\n",
    "# By default outputs are concatenated from both directions\n",
    "# Outputs are from last layer, hence we are fine in most cases\n",
    "outputs, (h_n, c_n) = lstm(data)\n",
    "# We usually need `outputs` or `h_n` only\n",
    "# Rest is done the same as with the RNNs previously\n",
    "print(f\"Outputs: {outputs.shape} | Hidden: {h_n.shape} | Cell: {c_n.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word representation\n",
    "\n",
    "You have probably heard that `RNN`s are used for text classification, translation and other language related tasks.\n",
    "\n",
    "On the other hand we know that:\n",
    "- __Neural networks require numbers to work__\n",
    "- __Each sample has predefined number of features describing it__\n",
    "\n",
    "How could we obtain that with words?\n",
    "\n",
    "### Semantic text representation\n",
    "\n",
    "> __Each word is represented as `N`-dimensional vector__\n",
    "\n",
    "This representation has (usually) a few characteristics:\n",
    "- The more \"semantically related\" the word is, the closer they are in `N` dimensional space\n",
    "- Arithmetic on word representations gives us intuitively correct results (__result is closest distance-wise from all available words__)\n",
    "\n",
    "![word_repr](images/word_representation.png)\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\n",
    "\\text{king} + \\text{cap} = \\text{crown}\n",
    "$$\n",
    "\n",
    "> __These representations are learned in a self-supervised fashion, see first Assessment Challenge__\n",
    "\n",
    "We will use [`spacy`](https://spacy.io/usage/spacy-101) in order to load those (pretrained) representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T15:13:11.119717Z",
     "start_time": "2021-06-08T15:13:00.609887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: jinja2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (4.61.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (2.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: boto3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (1.17.84)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.84 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (1.20.84)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from botocore<1.21.0,>=1.20.84->boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.20.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.61.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: setuptools in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: jinja2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.2.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: boto3 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.17.84)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.84 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.20.84)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from botocore<1.21.0,>=1.20.84->boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3->smart-open<4.0.0,>=2.2.0->pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "# Load textual representations created by spacy (small version)\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T15:13:37.805227Z",
     "start_time": "2021-06-08T15:13:37.054279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN advcl\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with spacy\n",
    "\n",
    "In general, here are the required steps when working with `spacy` and neural networks:\n",
    "- Get a list of sentences you want to work on\n",
    "- Create a [pipeline](https://spacy.io/usage/processing-pipelines) __from batch of text data__ (see [`nlp.pipe`](https://spacy.io/api/language#pipe))\n",
    "- Iterate over pipeline(s) and, using __`vector` attribute__, __obtain semantic representations of each word__\n",
    "\n",
    "Let's see part of this pipeline below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T16:01:41.037277Z",
     "start_time": "2021-06-08T16:01:40.671736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 <class 'numpy.ndarray'> (96,) float32\n",
      "13 <class 'numpy.ndarray'> (96,) float32\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Each document is spacy.doc instance respectively for each word\n",
    "for doc in nlp.pipe(texts):\n",
    "    # Do something with the doc here\n",
    "    text_representation = [token.vector for token in doc]\n",
    "    print(\n",
    "        len(text_representation),\n",
    "        type(text_representation[0]),\n",
    "        text_representation[0].shape,\n",
    "        text_representation[0].dtype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "Let's analyze the output:\n",
    "- __Each sentence is of different length while batches of data CANNOT HAVE VARIABLE SIZE__\n",
    "- `np.ndarray` is returned, __we can transform it to PyTorch tensor easily__\n",
    "- Each has `96` element (number of features for this representation)\n",
    "\n",
    "First one would be a problem, __fortunately PyTorch provides [`torch.nn.utils.pack_sequence`](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence)__ which:\n",
    "- creates sequence and implicitly __pads it with zero-filled tokens__\n",
    "- __Special data structure USABLE ONLY FOR RNNs__.\n",
    "\n",
    "Let's see `pack_sequence` in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T16:11:16.022499Z",
     "start_time": "2021-06-08T16:11:15.990008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([3, 1, 6, 4, 2, 5]), batch_sizes=tensor([3, 2, 1]), sorted_indices=tensor([1, 0, 2]), unsorted_indices=tensor([1, 0, 2]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4, 5])\n",
    "c = torch.tensor([6])\n",
    "\n",
    "# If sequence is not sorted by length we have to use enforce_sorted=False\n",
    "packed = torch.nn.utils.rnn.pack_sequence([a, b, c], enforce_sorted=False)\n",
    "packed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little more realistic, just like our data above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T16:25:28.395723Z",
     "start_time": "2021-06-08T16:25:28.376436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(16, 96) # seq_len x features\n",
    "b = torch.randn(13, 96) # seq_len x features\n",
    "\n",
    "packed = torch.nn.utils.rnn.pack_sequence([a, b], enforce_sorted=False)\n",
    "\n",
    "module = torch.nn.LSTM(96, 128)\n",
    "\n",
    "_, (h_n, _) = module(packed)\n",
    "\n",
    "# We need to pad sequence if we want ALL OF THE TIMESTEP OUTPUTS\n",
    "# No need for h_n, we get out our tensor!\n",
    "h_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader's collate_fn\n",
    "\n",
    "> `collate_fn` argument to `torch.utils.data.DataLoader` allows to specify custom behaviour for __batch creation__\n",
    "\n",
    "Default `collate_fn`:\n",
    "\n",
    "- Prepends batch dimension\n",
    "- Transforms `np.array`s/Python scalars to `torch.Tensor`\n",
    "- Concatenates data and preserves structure (e.g. `dict` return values from `torch.utils.data.Dataset`)\n",
    "\n",
    "> By default it gets only a single argument (list of samples from `torch.utils.data.Dataset`)\n",
    "\n",
    "We will use it to:\n",
    "- transform `list` of texts to vectors via `nlp.pipe`\n",
    "- transform labels for classification task to `torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext\n",
    "\n",
    "> `torchtext` is PyTorch library used for working with text\n",
    "\n",
    "In our case, we will use it only to load data (rest of the pipeline will be done via `spacy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T15:35:09.196500Z",
     "start_time": "2021-06-08T15:35:05.628371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.9.1-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from torchtext) (1.8.1)\n",
      "Requirement already satisfied: requests in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from torchtext) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from torchtext) (4.61.0)\n",
      "Requirement already satisfied: numpy in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from torchtext) (1.20.2)\n",
      "Requirement already satisfied: typing_extensions in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests->torchtext) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests->torchtext) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/vyz/.conda/envs/AiCore/lib/python3.9/site-packages (from requests->torchtext) (4.0.0)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T16:02:05.356364Z",
     "start_time": "2021-06-09T16:02:05.279269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.datasets_utils._RawTextIterableDataset'>\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "train, test = torchtext.datasets.AG_NEWS(root='.data', split=('train', 'test'))\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Notice this dataset is iterable only and NON-INDEXABLE__\n",
    "\n",
    "This means we have to gather our samples in custom `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T16:01:49.314966Z",
     "start_time": "2021-06-09T16:01:49.307194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\")\n"
     ]
    }
   ],
   "source": [
    "for elem in train:\n",
    "    print(elem)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Build `LSTM` classification network.\n",
    "\n",
    "> __Most of the work will be about getting and processing textual data into correct form__\n",
    "\n",
    "To do that we have to:\n",
    "- Load `AG_NEWS` test (we will use it as a validation) and train splits\n",
    "- Implement `torch.utils.data.Dataset` which gets one of the above datasets and:\n",
    "    - saves all of the samples in `self.samples`\n",
    "    - saves all of the targets as `torch.Tensor` in `self.targets`\n",
    "    - __calculates total count of unique targets__ (we will later use for neural network) and saves it as `self.n_targets`\n",
    "    - uses `__getitem__` to return specific sample and respective label\n",
    "    - __SAMPLES ARE RETURNED AS `str` AND single `torch.Tensor` value respectively!__\n",
    "- Create `collate_fn` __FUNCTOR__ which:\n",
    "    - Inside `__init__` sets up `nlp` object creted via `spacy.load(\"en_core_web_sm\")` and assign to self\n",
    "    - Inside `__call__(self, batch)`:\n",
    "        - gets `[0]` elements from batch (all of the sentences)\n",
    "        - gets `[1]` elements from batch (all of the targets)\n",
    "        - Pushes sentences through pipeline (specify the same `batch_size` as number of sentences)\n",
    "            - Gets `token.vector` for each word in the sentence and transforms it to `torch.Tensor` instance\n",
    "            - Creates a list from these tokens (shape: `(seq_len, 96)`)\n",
    "            - Adds this list to another `list` (outside of loop) __which will keep all of the sentences representations__\n",
    "        - Given our `list` containing all sentences use `torch.nn.utils.rnn.pad_sequence` to pack all the sentences into `RNN` digestable form\n",
    "        - Return `padded_sequence` and concatenated `targets` (__remember to also transform them into `torch.Tensor` instance!__)\n",
    "- Create simple bidirectional `LSTM` model with a few layers (pack it in `torch.nn.Module`):\n",
    "    - Add `torch.nn.Linear` to project `hidden_size` to the targets we want (__use `dataset.n_targets` attribute here!__)\n",
    "    - `forward` has to select appropriate output (__reshapes and indexing needed!__) and push output from last recurrent step through `nn.ReLU` and `nn.Linear` defined previously\n",
    "- Once all of that is done create a simple training loop (or reuse the one you had previously) choosing `Adam` and appropriate loss (based on\n",
    "\n",
    "> __Good luck :)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "## Assessment\n",
    "\n",
    "- What is [Word2Vec](https://wiki.pathmind.com/word2vec) and how do we obtain semantic representation of words/characters?\n",
    "- What does the `teacher forcing` for recurrent neural networks do and why would we use it?\n",
    "- Read more about [spaCy pipelines](https://spacy.io/usage/processing-pipelines). What do they consist of?\n",
    "- What is [perplexity](https://towardsdatascience.com/perplexity-intuition-and-derivation-105dd481c8f3) metric and what does it measure?\n",
    "\n",
    "## Non-assessment\n",
    "\n",
    "- When would we feed `(h_n, c_n)` as input to `nn.LSTM` layer? What would it achieve?\n",
    "- What is [GRU Unit](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) and why would one want to use it instead of `nn.LSTM` layer?\n",
    "- How does the `BLEU` score work?\n",
    "- How to optimize data loading pipeline we have created?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-AiCore] *",
   "language": "python",
   "name": "conda-env-.conda-AiCore-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
