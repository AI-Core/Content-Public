{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As data scientists, we often find the need to make decisions based on the data we have collected. After obtaining our statistics, we can have a decent _feeling_ or _opinion_ on whether our data is valid and shows significant results. But how can we make more objective decisions based on our results?\n",
    "\n",
    "Thus arises the need for __statistical hypothesis testing__, also known as __confirmatory data analysis__. It provides us with a framework for using statistical and probabilistic methods on our data to be able to determine the significance of our results. \n",
    "\n",
    "We assume that you are already familiar with basic statistics terms, such as mean, standard deviation, or mean square error. Otherwise, refer to the Data Wrangling module in the Data Engineering content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null & Alternative Hypotheses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In hypothesis testing, we have to construct two opposing hypotheses. The first one is known as the __null hypothesis__ ($\\mathbf{H_{0}}$) and is the hypothesis you are trying to __reject__. The second one is known as the __alternative hypothesis__ ($\\mathbf{H_{A}}$), and is the hypothesis you are trying to __support__. Within this framework, we assume the null hypothesis is true, and use statistical methods to determine whether our evidence is conclusive __enough__ to reject the null hypothesis, and support the alternative hypothesis.\n",
    "\n",
    "This is a similar framework to the approach used in court cases. During a trial, the outlook is that a person is 'innocent until proven guilty'. This means that, in this case:\n",
    "- $\\mathbf{H_{0}}$: The person is innocent\n",
    "- $\\mathbf{H_{A}}$: The person is guilty\n",
    "\n",
    "And the prosecuting lawyers will use various pieces of evidence to reject $\\mathbf{H_{0}}$. \n",
    "\n",
    "In general, we can think of the null hypothesis as being 'your evidence _does not_ suggest what you think' and the alternative as being 'your evidence _does_ suggest what you think'. You assume your evidence _does not_ contribute anything new until you have statistical measures that suggest your evidence _does_ contribute to something new.\n",
    "\n",
    "As we will see later on, we will have different levels of statistical significance for our data. We can set thresholds to determine at which point of significance we reject our null hypothesis, but this threhsold depends on the context of the problem and is up for data scientists and statisticians to determine. How do we go about determining these thresholds? We will see that shortly, first, let's talk about some very important concepts regarding hypothesis testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Normal Distribution__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probability distribution is a function that maps values to probabilities. For example, we can see how likely it is that a person has a certain height.\n",
    "\n",
    "The __normal distribution__, often called Gaussian distribution, is an important continuous probability distribution that describes the probability of a random variable. \n",
    "\n",
    "The normal distribution is a bell-shaped curve that is centered around the mean ($\\mu$). Naming the standard deviation $\\sigma$, we know that the range between $\\mu - \\sigma$ and $\\mu + \\sigma$ takes up to 68.26% of the area under the curve. The range between $\\mu - 2\\sigma$ and $\\mu + 2\\sigma$ takes up to 95.44% of the area under the curve.\n",
    "\n",
    "<p align=center><img src=images/normal.png width=600></p>\n",
    "\n",
    "Thanks to these properties, we can get the probability of a random variable to happen given that the variable follows a normal distribution.\n",
    "\n",
    "We can normalize the samples we have to follow a normal distribution with a mean of 0 and a standard deviation of 1. This is called __standardization__. Standardization is very useful to calculate the aforementioned probabilities. We can standardize our data by subtracting the mean and dividing by the standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Let's say we have a sample of heights of people in a group. We can calculate the probability of a person having a certain height by standardizing the sample, and then using what we call Z value you obtained with the value above. There are many resources online that can help you relate Z values to probabilities.\n",
    "\n",
    "One example that you can find is the following one, where the table is giving you the probability of a person being under a certain height. Let's say that the mean of the sample is 170 cm and the standard deviation is 2.4 cm. You can calculate the probability of finding someone under 175 cm by standardizing the sample:\n",
    "\n",
    "$$\n",
    "Z = \\frac{175 - 170}{2.4} = 2.08\n",
    "$$\n",
    "\n",
    "Now, we take a look at the table:\n",
    "\n",
    "<p align=center><img src=images/z-table.png width=600></p>\n",
    "\n",
    "On the left hand side, we have to find the Z value up to the first decimal place, the number on the first row show the second decimal place. So, on the left hand side, we need to find 2.0, and in the first row, we have to find 0.08. That gives us 0.9812. Thus, we have a probability of 98.12% of finding someone under 175 cm.\n",
    "\n",
    "We can use the same metric to find the probability of finding someone over 175 cm, because the normal curve is symmetric.\n",
    "\n",
    "$$\n",
    "P = 1 - 0.9812 = 0.0188\n",
    "$$\n",
    "\n",
    "So, we have a 1.88% chance of finding someone over 175 cm.\n",
    "\n",
    "Notice that the values in the Z table are positive. There are other tables that also shows negative values:\n",
    "\n",
    "<p align=center><img src=images/z-negative.png width=600></p>\n",
    "\n",
    "Can you think of a way to calculate the probability of someone being between 150 and 175 cm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very similar distribution is the __t-distribution__. It also follows a bell-shaped curve, but the tails are wider and the peak is lower. This is because the t-distribution doesn't take into account the whole population, so it has a sample with its own mean and standard deviation, which in turn leads to a higher variance. \n",
    "\n",
    "If we increase the number of samples, the t-distribution moves towards the normal distribution.\n",
    "\n",
    "<p align=center><img src=images/t-distribution.png width=600></p>\n",
    "\n",
    "We are not going to cover how to calculate the t-value, and there are tables that can help you find the t-value, or even Python libraries that can help you find the t-value. \n",
    "\n",
    "We will mention, however, that you can use the t-value to find the statistical significance of the difference between the population mean and a hypothesized value (1-sample t) or between two distributions (2-sample t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Significance level (α)__\n",
    "\n",
    "The significance level, also denoted as alpha or α, is the probability of rejecting the null hypothesis given that the null hypothesis is true. Generally, we use the significance value of 0.05\n",
    "\n",
    "For example, if the significance level is 0.05, there is a 5% chance of rejecting the null hypothesis. Let's combine this with the normal distribution we saw above to set an example. \n",
    "\n",
    "For example, if the mean of the sample is 170 cm and the standard deviation is 2.4 cm, and we want to check if the mean height of another sample is different from the hypothesized mean. The second sample has a mean of 175 cm.\n",
    "\n",
    "<p align=center><img src=images/significance.png></p>\n",
    "\n",
    "The picture above shows a significance level of 0.05. The red areas adds up to a 5% under the curve, so we have a 5% chance of falling under that area. If we fall under it, we reject the null hypothesis.\n",
    "\n",
    "The Z value of a height of 175cm is 2.08, so that means that we can reject the null hypothesis with a 5% significance level.\n",
    "\n",
    "However, we can set a significance level of 0.01:\n",
    "\n",
    "<p align=center><img src=images/significance_2.png></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, 175 cm is not significantly different from 170 cm. So be vary careful when using this significance level!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### __p-Value__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is the probability of obtaining the test results considering the null hypothesis is true. In other words, it is the probability that the difference between the two values is just because of random chance. The smaller the p-value, the stronger the chances to reject the null hypothesis. If the p-value is lower than the significance level, we can reject the null hypothesis.\n",
    "\n",
    "In the example above, we can calculate the p-value as the shaded areas above 175 cm and its symetric counterpart.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center><img src=images/p_value.png></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a probability of 0.0188 at each side of the curve, so the total probability is 0.0376. This probability represents the likelihood of obtaining a sample mean that is at least as extreme as our sample mean in both tails of the distribution if the population mean is 260. That’s our p value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type I & Type II Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Statistical hypothesis testing is meant to help data scientists and statisticians to reach a more objective conclusion based on how statistically significant our results are. But the issue arises when we have to determine a given threshold for significance. For instance, when do we reject our null hypothesis? at 70% certainty? 95% certainty? 99.9% certainty? To choose an appropriate _threshold_ of certainty, we have to understand to context of our experiment.\n",
    "\n",
    "Let us go back to the analogy of a court case. Since in a court case, you can never have 100% certainty, there is always a probability of wrongully arresting an innocent person or letting a guilty person walk free. Consider the possibilities in the table below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "|                     | Court Case Outcomes |                     |\n",
    "|---------------------|---------------------|---------------------|\n",
    "|                     | Truly Innocent      | Truly Guilty        |\n",
    "| Determined Innocent | Correct             | Failed imprisonment |\n",
    "| Determined Guilty   | Wrongful arrest     | Correct             |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are two distinct types of mistakes that can happen in the decision process. When we arrest an innocent person, we have committed a __Type I error__, where we __wrongfully reject the null hypothesis (false positive)__. When we fail to arrest a guilty person, we have commited a __Type II error__, where we __wrongfully accept the null hypothesis (false negative)__. In general, when we aim to minimize the likelihood one type of error, the likelihood of the other error increases. In this case, if we are highly strict and demand a very high degree of certainty, we will minimize the number of wrongful arrests (Type I), but it also becomes more likely to not arrest someone who is guilty (Type II). On the other hand, if judges demand a lesser degree of certainty, we will arrest more guilty people, but are also more likely to wrongfully arrest an innocent person.\n",
    "\n",
    "In our modern judicial system, we believe that the accused is innocent until proven guilty, and that wrongful imprisionment is worse than letting a guilty person walk free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<p><img src='images/free.png' width=150><img src='images/balance.png' width=250><img src='images/arrested.png' width=250></p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we require a high degree of certainty to arrest someone, and put our efforts into minimizing the number of wrongful arrests. This principle applies to other contexts of hypothesis testing: given the context we use our best judgement to determine what type of errors we want to minimize, and set our parameters and hypotheses accordingly."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad8bebc098a042dc0df4e42fc2ecc8fff0bd7b8741641ce29007c29766dadbe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
