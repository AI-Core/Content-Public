{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient based optimisation\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Calculus\n",
    "- Linear Regression Introduction\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Understand the concepts behind gradient based optimisation and learning\n",
    "- Implement the stochastic gradient descent (SGD) algorithm from scratch in Python\n",
    "- Implement linear regression from scratch in Python\n",
    "\n",
    "## Intro\n",
    "\n",
    "Previously, we saw how we could optimise parameters of linear regression using it's analytical solutions. This technique had some fundamental flaws though...\n",
    "- It is available only for special cases of machine learning methods, hence __isn't general method__\n",
    "- Computationally infeasible for large datasets and a lot of features\n",
    "\n",
    "This notebook will walk through how we can use **gradient based optimisation** as another technique to find model parameterisations that perform well.\n",
    "\n",
    "Gradient based optimisation is not exclusively used in machine learning, it is a technique used for optimising all kinds of functions in all kinds of domains.\n",
    "\n",
    "> We are going to use gradient based optimisation to minimise the criterion of our ML algorithms\n",
    "\n",
    "To get your mind running, gradient based optimisation looks a bit like the following diagram. In our case, $f(w)$ would represent the criterion that we want to minimise, which varies with the model parameters ($w$ & $b$ for linear regression):\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is gradient based optimisation all about?\n",
    "\n",
    "Our loss is just a mathematical function that depends on the parameters of our model (for example, we used the mean squared error (MSE) loss function in the previous notebooks).\n",
    "We would like to move our parameters to the point where this loss is minimised.\n",
    "\n",
    "> If we were to evaluate the value of our loss for every possible different parameterisation of our model, we would produce a **loss surface**. \n",
    "\n",
    "We would like to find the lowest point on this surface. \n",
    "- At this point it will have a gradient (steepness) of zero with respect to the parameters.\n",
    "- As our parameters move away from that minima in some direction, the gradient will increase in that direction.\n",
    "\n",
    "To get back to the minima, we should hence __move our weights in the opposite direction to gradient__ (simply subtract it).\n",
    "\n",
    "![](./images/grad-based-optim.jpg)\n",
    "\n",
    "## Numerical example\n",
    "\n",
    "Below is an example that shows the direction to shift a parameter $W$, initialised as $w=4$, for a surface given by:\n",
    "\n",
    "$$\n",
    "L=(W-2)^2\n",
    "$$ \n",
    "\n",
    "At this point on the surface, the gradient of the loss with respect to this parameter is positive, so we should shift it in the negative direction to push it closer the the optima.\n",
    "\n",
    "![](images/sgd_numerical_example.jpg)\n",
    "\n",
    "Below is a more complex potential loss surface which has more than one parameter (vertical axis represents loss value, others represent parameter values). In reality, we will often have many more features, and we won't be able to visualise the loss surface as we would need more than 3 dimensions.\n",
    "\n",
    "<img style=\"height: 200px\" src='./images/comp-loss-surface.png'/>\n",
    "\n",
    "> **Note: because gradient based optimisation depends on us computing the gradient of the loss function, our loss function and model must be fully differentiable (they must be a smooth, continuous function).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Gradient descent is an iterative, gradient based optimisation technique. \n",
    "\n",
    "That is, it is a technique for finding the minima (or maxima) of a function, and it does so by iteratively moving the parameters downhill, in the opposite direction to the gradient of the surface.\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)\n",
    "\n",
    "### The learning rate, $\\alpha$\n",
    "\n",
    "We will update our parameters by shifting them in the opposite direction to the gradient. But by what amount should we shift them in that direction?\n",
    "\n",
    "> Learning rate $\\alpha$ (abbreviated often `lr` in source code) __multiplies gradient__ to decrease (usually) or increase it's magnitude\n",
    "\n",
    "`step_size` hence is `gradient` multiplied by our `lr`.\n",
    "\n",
    "#### Too small `lr`\n",
    "\n",
    "There are a few things that may happen if we get it wrong:\n",
    "- If `lr` is too small our convergence __might take a long time__\n",
    "- We might get stuck in local minimas or saddle points (will go over that in a second)\n",
    "\n",
    "![title](images/low-lr.jpg)\n",
    "\n",
    "#### Too large `lr`\n",
    "\n",
    "- If `lr` is too large, we may jump out of minimum\n",
    "- Instead of __converging__ we might __diverge__\n",
    "\n",
    "![title](images/high-lr.jpg)\n",
    "\n",
    "So we include the learning rate to scale up/down the size of the steps. \n",
    "\n",
    "> The learning rate should most likely be less than 1 though (see challenges for different example)\n",
    "\n",
    "You should play around with the learning rate and adjust it until your model converges.\n",
    "\n",
    "![title](images/convergence.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local optima\n",
    "\n",
    "Don't stress too much about it\n",
    "\n",
    "Yes, in the case where we are trying to minimise a function with respect to 1 or 2 parameters, gradient descent is prone to getting stuck in local optima.\n",
    "\n",
    "But most of the models that are useful in practice depend on many more parameters (neural networks can easily have millions).\n",
    "\n",
    "> As the number of parameters increase, it becomes exponentially unlikely that any parameterisation is at a minima, but is rather a saddle point, and so there is still an indication of how to improve.\n",
    "\n",
    "Furthermore, __in practice we often find that we don't need to find a global optima__\n",
    "Local optima can be good enough to reach our required performance.\n",
    "\n",
    "On top of this, we can attempt to counter getting stuck in local optima by using different optimisation algorithms, such as [gradient descent with (Nesterov) momentum](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "The diagrams shown above visualise how a single parameter affects the loss. \n",
    "\n",
    "A model with multiple parameters (such as a weight and a bias, or multiple weights) would be optimised in the same way - we would just have more of these functions. \n",
    "\n",
    "> We can think of each of the graphs as a cross section through a **loss surface**. \n",
    "\n",
    "A loss surface is shown below which visualises how the criterion of a model might vary with both parameters.\n",
    "\n",
    "$$\n",
    "L = w_1^4 + w_2^2\n",
    "$$\n",
    "\n",
    "<img style=\"height: 300px\" src='images/x2x4.png'/>\n",
    "\n",
    "![](images/multivariate_sgd.jpg)\n",
    "\n",
    "If we know the function that the loss is computed from and it is differentiable, then we can calculate the derivative of the loss with respect to our model parameters:\n",
    "- by hand (pretty tiring - but we're gonna do it)\n",
    "- using an automatic differentiation graph (what we're gonna do later when we get to deep learning)\n",
    "\n",
    "After that we can iteratively move each parameter in the direction of the opposite gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firstly, a helper function\n",
    "\n",
    "We'll use this code shortly to visualise how training is progressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(losses):\n",
    "    \"\"\"Helper function for plotting loss against epoch\"\"\"\n",
    "    plt.figure() # make a figure\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(losses) # plot costs\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data\n",
    "\n",
    "Run the cells below to get the data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aicore\n",
      "  Downloading aicore-0.0.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /home/ivanyingx/miniconda3/lib/python3.9/site-packages (from aicore) (1.21.4)\n",
      "Collecting scikit-learn>=0.23.2\n",
      "  Downloading scikit_learn-1.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7 MB 206 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /home/ivanyingx/miniconda3/lib/python3.9/site-packages (from scikit-learn>=0.23.2->aicore) (1.7.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 90.6 MB/s \n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn, aicore\n",
      "Successfully installed aicore-0.0.3 joblib-1.1.0 scikit-learn-1.0.1 threadpoolctl-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install aicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivanyingx/miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "from aicore.ml import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use `data.split` in order to split the data into train, validation, test\n",
    "(X_train, y_train), (X_validation, y_validation), (X_test, y_test) = data.split(\n",
    "    datasets.load_boston(return_X_y=True)\n",
    ")\n",
    "X_train, X_validation, X_test = data.standardize_multiple(X_train, X_validation, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The model\n",
    "\n",
    "Here's the same model we implemented before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, optimiser, n_features): # initalize parameters \n",
    "        self.w = np.random.randn(n_features) ## randomly initialise weight\n",
    "        self.b = np.random.randn() ## randomly initialise bias\n",
    "        self.optimiser = optimiser\n",
    "        \n",
    "    def predict(self, X): # how do we calculate output from an input in our model?\n",
    "        ypred = X @ self.w + self.b ## make a prediction using a linear hypothesis\n",
    "        return ypred # return prediction\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        all_costs = [] ## initialise empty list of costs to plot later\n",
    "        for epoch in range(self.optimiser.epochs): ## for this many complete runs through the dataset    \n",
    "\n",
    "            # MAKE PREDICTIONS AND UPDATE MODEL\n",
    "            predictions = self.predict(X) ## make predictions\n",
    "            new_w, new_b = self.optimiser.step(self.w, self.b, X, predictions, y) ## calculate updated params\n",
    "            self._update_params(new_w, new_b) ## update model weight and bias\n",
    "            \n",
    "            # CALCULATE LOSS FOR VISUALISING\n",
    "            cost = mse_loss(predictions, y) ## compute loss \n",
    "            all_costs.append(cost) ## add cost for this batch of examples to the list of costs (for plotting)\n",
    "\n",
    "        plot_loss(all_costs)\n",
    "        print('Final cost:', cost)\n",
    "        print('Weight values:', self.w)\n",
    "        print('Bias values:', self.b)\n",
    "\n",
    "    \n",
    "    def _update_params(self, new_w, new_b):\n",
    "        self.w = new_w ## set this instance's weights to the new weight value passed to the function\n",
    "        self.b = new_b ## do the same for the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The criterion\n",
    "\n",
    "Let's remind ourselves the formula:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    L_{mse} = \\frac{1}{N}\\sum_{i}^{N}(\\hat{y_i} - y_i)^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_hat, labels): # define our criterion (loss function)\n",
    "    errors = y_hat - labels ## calculate errors\n",
    "    squared_errors = errors ** 2 ## square errors\n",
    "    mean_squared_error = sum(squared_errors) / len(squared_errors) ## calculate mean \n",
    "    return mean_squared_error # return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The optimiser: Gradient descent\n",
    "\n",
    "With linear regression, you can swap out different optimisers and stick with the same model, data and criterion.\n",
    "\n",
    "### Implementing gradient descent from scratch\n",
    "\n",
    "Below is a derivation for computing the rate of change (gradient) of the loss with respect to our model parameters when using a linear model and the mean squared error loss function.\n",
    "![title](images/NN1_single_grad_calc.jpg)\n",
    "\n",
    "Complete the class below to return the derivative of our loss w.r.t the weight and bias by implementing the above equations in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGDOptimiser:\n",
    "    def __init__(self, lr, epochs):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _calc_deriv(self, features, predictions, labels):\n",
    "        m = len(labels) ## m = number of examples\n",
    "        diffs = predictions - labels ## calculate errors\n",
    "        dLdw = 2 * np.sum(features.T * diffs).T / m ## calculate derivative of loss with respect to weights\n",
    "        dLdb = 2 * np.sum(diffs) / m ## calculate derivative of loss with respect to bias\n",
    "        return dLdw, dLdb ## return rate of change of loss wrt w and wrt b\n",
    "\n",
    "    def step(self, w, b, features, predictions, labels):\n",
    "        dLdw, dLdb = self._calc_deriv(features, predictions, labels)\n",
    "        new_w = w - self.lr * dLdw\n",
    "        new_b = b - self.lr * dLdb\n",
    "        return new_w, new_b\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimiser = SGDOptimiser(lr=learning_rate, epochs=num_epochs)\n",
    "model = LinearRegression(optimiser=optimiser, n_features=X_train.shape[1])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn` example\n",
    "\n",
    "`sklearn` packs everything we just did above into it's simple [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_model = LinearRegression() ## instantiate the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "    return mse_loss(\n",
    "        model.predict(X),\n",
    "        y\n",
    "    )\n",
    "\n",
    "print(f\"Training loss before fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(\n",
    "    f\"Validation loss before fit: {calculate_loss(model, X_validation, y_validation)}\"\n",
    ")\n",
    "print(f\"Test loss before fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_regression_model.fit(X_train, y_train) ## fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do the same but fit the model for some epochs and see the loss after training, validation and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training loss after fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(f\"Validation loss after fit: {calculate_loss(model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss after fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look into the final parameters of the model when using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('final weights:', model.coef_)\n",
    "print('final bias:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why gradient based optimisation?\n",
    "\n",
    "> Gradient based optimisation uses __heuristics__ which indicate how to improve w.r.t. loss (e.g. to minimize it).\n",
    "\n",
    "There are other available options (like analytical solutions, sometimes), and we went through the shortcomings.\n",
    "\n",
    "We could also search parameters __randomly__, but\n",
    "\n",
    "- our search region may not contain an optimal parameterisation for our model. For example, if we allowed bias `[-10, 10]` we would never obtain the solution \n",
    "- exponential increase in runtime with each additional parameter\n",
    "- no feedback from the process (gradient is our feedback here)\n",
    "\n",
    "__There is still one question left unanswered__:\n",
    "\n",
    "> What should we do when our data does not fit into memory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not pass the whole dataset through each prediction?\n",
    "\n",
    "We know that to perform gradient based optimisation we need to pass inputs through the model (forward pass), and then compute the loss and find how it changes with respect to each of our model's parameters (backward pass). \n",
    "\n",
    "Modern datasets can be absolutely huge. This means that the forward pass can take a long time, as the function which our model represents has to be applied to each and every input given to it for a forward pass.\n",
    "\n",
    "> Passing the full dataset through the model at each pass is called **full batch gradient descent**.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Whole dataset may harm generalization and lead to overfitting\n",
    "- Might be slower (slower memory access, more cache misses)\n",
    "\n",
    "\n",
    "## Why not a single datapoint for each update?\n",
    "\n",
    "Let's assume we will pass a single example to our network and backpropagate based on that.\n",
    "Here is what will probably happen:\n",
    "- `gradient` will vary __A LOT__ - single example is usually uninformative for our whole task\n",
    "- `outliers` (special data points, which could as well be noise and are totally non-representative of the task) will affect our dataset way more\n",
    "\n",
    "Passing single examples through the model at each pass is called **online stochastic gradient descent**.\n",
    "\n",
    "What happens if, for some reason (memory constraints or examples come in as stream), we have to go with this approach?\n",
    "\n",
    "## Mini-batch gradient descent\n",
    "\n",
    "The modern way to do training is neither whole dataset nor fully stochastic (single datapoint). \n",
    "\n",
    "Instead we use mini-batch training:\n",
    "\n",
    "> Sample several (usually `64-2048`, depending on memory) datapoints to compute a sample of the gradient\n",
    "\n",
    "Most optimisation algorithms converge much faster if they are allowed to rapidly compute approximate gradients rather than slowly compute exact gradients. \n",
    "\n",
    "The size of the mini-batch is called the **batch size** and this technique is currently most widely used (especially in neural network).\n",
    "\n",
    "### Advantages of mini-batch gradient descent\n",
    "\n",
    "- We can adjust the size to fit memory on most machines\n",
    "- Is faster (easier to parallelize if multiple of `2`)\n",
    "- Improves generalization as each batch is a little noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why shuffle data?\n",
    "\n",
    "It is especially important for __large and more complex models__ (neural networks). If we didn't do that we might risk the following:\n",
    "\n",
    "- same updates are provided to the model at each batch. We want to estimate the total average, hence batches have to be different\n",
    "- model \"memorizes\" batch (happens in neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor conditioning\n",
    "\n",
    "Different features in different datasets can have different ranges\n",
    "- some features can be binary or between `[0, 1]`\n",
    "- others has values ranging in hundreds or even thousands\n",
    "\n",
    "This is problematic to most of machine learning models.\n",
    "\n",
    "### Why?\n",
    "\n",
    "When a small change in weight connected to feature with large values changes, the output changes significantly. This gives that weight, and hence that feature, more influence just because it is larger. \n",
    "\n",
    "This makes the loss function look like the example below, where it is very steep in one direction, and shallow in another.\n",
    "\n",
    "![](images/unnormalised.png)\n",
    "\n",
    "In the steep direction, the learning rate will need to be small enough to prevent a diverging optimisation, but because gradient signal in the other direction is so small, it wont make any progress in that direction.\n",
    "\n",
    "> If features are on different orders of magnitude, the maximum learning rate that works will be too small to make progress in every direction.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's take two weights `a` and `b` and single example `x` with two features:\n",
    "- first has value `0.1`\n",
    "- second has value `1000`\n",
    "\n",
    "Now, formula for linear regression would be the following:\n",
    "\n",
    "$$\n",
    "    \\hat{y} = 0.1a + 1000b\n",
    "$$\n",
    "\n",
    "Now, let's see impact of `a` and `b` on $\\hat{y}$:\n",
    "- $a = 10, b = 0.001$ - `a` and `b` have the same impact on $\\hat{y}$\n",
    "- $a = 1, b = 1$ - `b` has `10000` times (!!!) more impact on $\\hat{y}$\n",
    "\n",
    "It is unlikely `a` has `10000` times less impact on the value we want to predict (and is unlikely in real world).\n",
    "\n",
    "> We should assume all variables are __equally important unless we verify them__ via statistical testing or other measures\n",
    "\n",
    "The range of values __is not an important factor__, relative differences between values are.\n",
    "\n",
    "### Possible solution\n",
    "\n",
    "One idea would be that we can use a different learning rate for each weight. But this will mean we have to search for the correct learning rate as many times as we have parameters! In many cases, examples can have a large number of features (in images, each pixel is a feature!).\n",
    "\n",
    "### A better idea: normalisation or standardisation\n",
    "\n",
    "We can normalize our data, which means:\n",
    "\n",
    "> Normalization is a process of bringing features to the same value range\n",
    "\n",
    "This ensures that relative difference between values for each feature are important, not the scale.\n",
    "\n",
    "> We should always normalize our features (unless they are not continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization & standardization\n",
    "\n",
    "There are a lot of schemes to put values in the `[0, 1]` range. Here we will use `minmax` approach\n",
    "We can do this by subtracting the minimum then dividing by the range (feature normalisation).\n",
    "\n",
    "![title](images/normalisation.jpg)\n",
    "\n",
    "We can alternatively use a similar method called standardisation, where we subtract the mean then divide by the standard deviation.\n",
    "\n",
    "![](images/standardisation.jpg)\n",
    "\n",
    "Feature normalisation puts gradients of each different model parameter on the same order of magnitude. This converts loss surfaces that might look like *valleys* into loss surfaces that look like *bowls*. Feature normalisation means that we should be able to make progress with optimisation for all model parameters using the same learning rate.\n",
    "\n",
    "![](images/bowl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Always normalize and sanitize your input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation Gotchas\n",
    "\n",
    "### 1. Data Leakage\n",
    "\n",
    "Statistics computed from the unsplit dataset will contain information about every example.\n",
    "\n",
    "Normalising dataset splits based on such statistics will leak information about the test and validation sets.\n",
    "\n",
    "> Always split your data before normalising it. \n",
    "\n",
    "### 2. Training testing skew\n",
    "\n",
    "This is when your training data doesn't look like your testing data. One way to cause this skew is by normalising your validation or testing sets using their own mean and standard deviation, rather than the same ones which your training data was normalised with.  If the other sets have different statistics, your model may recieve inputs that look rather different to what it was trained to make predictions from.\n",
    "\n",
    "> All sets of data should be normalised using the same statistics.\n",
    "\n",
    "Normlise your validation and test sets using the mean and standard deviation from your training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Here's a function we can use to normalise our data. Notice how it will compute the statistics if they are not yet given (as it should for the training set), but will otherwise allow you to pass them int (as you should do for the other sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(dataset, mean=None, std=None):\n",
    "    if mean is None and std is None:\n",
    "        mean, std = np.mean(dataset, axis=0), np.std(\n",
    "            dataset, axis=0\n",
    "        )  ## get mean and standard deviation of dataset\n",
    "    standardized_dataset = (dataset - mean) / std\n",
    "    return standardized_dataset, (mean, std)\n",
    "\n",
    "X_train, (mean, std) = standardize_data(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- __Storchastic Gradient Descent (SGD)__ is a basic optimization technique which simply subtracts gradient from parameter's value __multiplied by `learning rate`__\n",
    "- __Learning rate (`lr`)__ decides the magnitude of step taken by optimizer and is present in most optimizers\n",
    "- __Mini-batch stochastic gradient descent__ is when you take parts of dataset and push through your model instead of single example or whole dataset at once. Saves memory and helps in generalization\n",
    "- __Shuffling is necessary for mini-batches__ as it better mimicks overall gradient of the dataset and makes model resistant to noise\n",
    "- Normalization or standardisation almost always improves our scores __sometimes our solution will diverge without it!__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
